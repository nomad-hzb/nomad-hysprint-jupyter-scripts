{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bc5c7b-4bc3-4fe2-8bcc-3515b837f1ea",
   "metadata": {},
   "source": [
    "# AbsPL (Absorption and Photoluminescence) Analysis\n",
    "\n",
    "## How to use this notebook:\n",
    "1. Select batches to analyze (only batches of type \"hysprint_batch\" are considered)\n",
    "2. The data will be loaded into a pandas DataFrame\n",
    "3. Use the plotting tools to visualize your data:\n",
    "   - Create scatter plots for comparing two parameters\n",
    "   - Use box plots to analyze parameter distributions\n",
    "4. Access advanced features for data table viewing and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c673a2c8-7465-457c-b2c8-ce11ccfc5168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from api_calls import get_ids_in_batch, get_sample_description, get_batch_ids,  get_all_eqe as get_all_trpl, get_all_batches_wth_data\n",
    "import batch_selection\n",
    "import plotting_utils\n",
    "import access_token\n",
    "\n",
    "url_base =\"https://nomad-hzb-se.de\"\n",
    "url = f\"{url_base}/nomad-oasis/api/v1\"\n",
    "token = access_token.get_token(url)\n",
    "access_token.log_notebook_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aaee6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "from functools import partial\n",
    "from scipy.interpolate import make_splrep, generate_knots\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import BSpline\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def fit_monotone_convex_spline_from_bspline(x, y, spl0,\n",
    "                                            n_grid=200,\n",
    "                                            tol_d1=0.0,\n",
    "                                            tol_d2=0.0,\n",
    "                                            constraint_tol=1e-6):\n",
    "    \"\"\"\n",
    "    Given data (x, y) and an initial BSpline spl0, refit the coefficients so that\n",
    "    the resulting spline is *approximately* monotone increasing (f' >= tol_d1)\n",
    "    and convex (f'' >= tol_d2) on [x.min(), x.max()].\n",
    "\n",
    "    Uses COBYLA. If constraints cannot be satisfied within `constraint_tol`,\n",
    "    falls back to the original spline `spl0` instead of raising.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Need at least a few points\n",
    "    t_spline = spl0.t\n",
    "    k = spl0.k\n",
    "    c0 = spl0.c\n",
    "    n_coeffs = c0.size\n",
    "\n",
    "    if x.size < k + 2:\n",
    "        # too few data points in region to meaningfully refit\n",
    "        return spl0\n",
    "\n",
    "    # --- Build design matrices ------------------------------------------------\n",
    "    def design_matrix(x_eval, nu=0):\n",
    "        A = np.empty((len(x_eval), n_coeffs))\n",
    "        for j in range(n_coeffs):\n",
    "            c = np.zeros(n_coeffs)\n",
    "            c[j] = 1.0\n",
    "            basis_j = BSpline(t_spline, c, k)\n",
    "            A[:, j] = basis_j(x_eval, nu=nu)\n",
    "        return A\n",
    "\n",
    "    # LSQ fit matrix on the constrained region\n",
    "    A_data = design_matrix(x, nu=0)\n",
    "\n",
    "    # Constraint grid on [x.min(), x.max()]\n",
    "    x_grid = np.linspace(x.min(), x.max(), n_grid)\n",
    "    A_d1 = design_matrix(x_grid, nu=1)   # first derivative\n",
    "    A_d2 = design_matrix(x_grid, nu=2)   # second derivative\n",
    "\n",
    "    # --- Objective: least squares on masked region ----------------------------\n",
    "    def objective(c):\n",
    "        r = A_data @ c - y\n",
    "        return 0.5 * np.dot(r, r)\n",
    "\n",
    "    # Start from LSQ on the same region\n",
    "    try:\n",
    "        c_ls, *_ = np.linalg.lstsq(A_data, y, rcond=None)\n",
    "    except Exception:\n",
    "        c_ls = c0.copy()\n",
    "\n",
    "    x0 = c_ls\n",
    "\n",
    "    # --- Inequality constraints (COBYLA: fun(c) >= 0 is feasible) -------------\n",
    "    def cons_d1_fun(c):\n",
    "        # f'(x_grid) - tol_d1 >= 0\n",
    "        return A_d1 @ c - tol_d1\n",
    "\n",
    "    def cons_d2_fun(c):\n",
    "        # f''(x_grid) - tol_d2 >= 0\n",
    "        return A_d2 @ c - tol_d2\n",
    "\n",
    "    constraints = [\n",
    "        {'type': 'ineq', 'fun': cons_d1_fun},\n",
    "        {'type': 'ineq', 'fun': cons_d2_fun},\n",
    "    ]\n",
    "\n",
    "    result = minimize(\n",
    "        objective,\n",
    "        x0,\n",
    "        method='COBYLA',\n",
    "        constraints=constraints,\n",
    "        options={\n",
    "            'maxiter': 2000,\n",
    "            'rhobeg': 1.0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    c_opt = result.x\n",
    "\n",
    "    # --- Check constraint violation ourselves --------------------------------\n",
    "    d1_vals = A_d1 @ c_opt\n",
    "    d2_vals = A_d2 @ c_opt\n",
    "\n",
    "    maxcv_d1 = max(0.0, tol_d1 - d1_vals.min())\n",
    "    maxcv_d2 = max(0.0, tol_d2 - d2_vals.min())\n",
    "    maxcv = max(maxcv_d1, maxcv_d2)\n",
    "\n",
    "    if maxcv > constraint_tol:\n",
    "        # Too much violation -> fall back gracefully\n",
    "        # You can uncomment this print if you want to see when it happens:\n",
    "        print(f\"Warning: monotone/convex constraints violated by {maxcv:.2e}, \"\n",
    "              f\"falling back to original spline.\")\n",
    "        return spl0\n",
    "\n",
    "    # Otherwise, return the constrained spline\n",
    "    return BSpline(t_spline, c_opt, k)\n",
    "\n",
    "def fit_convex_spline_from_bspline(x, y, spl0, n_grid=200, tol=0.0):\n",
    "    \"\"\"\n",
    "    Given data (x, y) and an initial BSpline spl0, refit the coefficients\n",
    "    so that the resulting spline is convex (f'' >= tol) on [x.min(), x.max()].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : 1D arrays\n",
    "        Data points.\n",
    "    spl0 : BSpline\n",
    "        Initial spline (provides knots and degree).\n",
    "    n_grid : int\n",
    "        Number of grid points on which convexity is enforced.\n",
    "    tol : float\n",
    "        Minimal allowed second derivative (0.0 for f'' >= 0).\n",
    "        Can set a tiny positive value to avoid borderline violations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spl_convex : BSpline\n",
    "        New convex spline with same knots/degree as spl0.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    t_spline = spl0.t\n",
    "    k = spl0.k\n",
    "    c0 = spl0.c\n",
    "    n_coeffs = c0.size\n",
    "\n",
    "    # Design matrix for data: A_data[i, j] = B_j(x[i])\n",
    "    def design_matrix(x_eval, nu=0):\n",
    "        A = np.empty((len(x_eval), n_coeffs))\n",
    "        for j in range(n_coeffs):\n",
    "            c = np.zeros(n_coeffs)\n",
    "            c[j] = 1.0\n",
    "            basis_j = BSpline(t_spline, c, k)\n",
    "            A[:, j] = basis_j(x_eval, nu=nu)\n",
    "        return A\n",
    "\n",
    "    # Data fit matrix\n",
    "    A_data = design_matrix(x, nu=0)\n",
    "\n",
    "    # Grid for enforcing convexity\n",
    "    x_grid = np.linspace(x.min(), x.max(), n_grid)\n",
    "    A_d2 = design_matrix(x_grid, nu=2)   # second derivative basis\n",
    "\n",
    "    # Objective: 0.5 * ||A_data c - y||^2\n",
    "    def objective(c):\n",
    "        r = A_data @ c - y\n",
    "        return 0.5 * np.dot(r, r)\n",
    "\n",
    "    # Gradient of objective\n",
    "    def objective_jac(c):\n",
    "        r = A_data @ c - y\n",
    "        return A_data.T @ r\n",
    "\n",
    "    # Inequality constraint: A_d2 @ c - tol >= 0  -> f''(x_grid) >= tol\n",
    "    def cons_fun(c):\n",
    "        return A_d2 @ c - tol\n",
    "\n",
    "    def cons_jac(c):\n",
    "        # derivative of A_d2 @ c is A_d2\n",
    "        return A_d2\n",
    "\n",
    "    cons = {\n",
    "        'type': 'ineq',\n",
    "        'fun': cons_fun,\n",
    "        'jac': cons_jac\n",
    "    }\n",
    "    result = minimize(\n",
    "        objective, c0,\n",
    "        jac=objective_jac,\n",
    "        constraints=cons,\n",
    "        method='SLSQP'\n",
    "    )\n",
    "\n",
    "    if not result.success:\n",
    "        raise RuntimeError(\"Convex spline fit failed: \" + result.message)\n",
    "\n",
    "    c_opt = result.x\n",
    "    return BSpline(t_spline, c_opt, k)\n",
    "\n",
    "# Analysis Functions\n",
    "def calculate_N0s(hc, spot_area, lambda_laser, thickness, bd_ratio, data):\n",
    "    \"\"\"Calculate N0s and fluences for each sample\"\"\"\n",
    "    photon_energy = hc / lambda_laser  # J\n",
    "    n0s = []\n",
    "    fluences = []\n",
    "    for i, row in data.iterrows():\n",
    "        p = row.laser_power\n",
    "        rep = row.repetition_rate\n",
    "        power_per_pulse = p / rep  # J\n",
    "        PowerDensity_per_pulse = power_per_pulse / spot_area\n",
    "        photons_per_pulse = PowerDensity_per_pulse / photon_energy  # m-2\n",
    "        fluences.append(photons_per_pulse)\n",
    "        pump_carrierDensity = photons_per_pulse / thickness  # m-3\n",
    "        pump_carrierDensity_cm = 1e-6 * pump_carrierDensity * bd_ratio  # cm-3 (includes the beamdump ratio)\n",
    "        n0s.append(pump_carrierDensity_cm)\n",
    "\n",
    "    n0s = np.array(n0s)\n",
    "    fluences = np.array(fluences)\n",
    "    return n0s, fluences\n",
    "\n",
    "def calculate_noise(counts, denoise_value):\n",
    "    \"\"\"Calculate noise from counts based on denoise parameter\"\"\"\n",
    "    noise = 0\n",
    "    if denoise_value < 0:  \n",
    "        noise = np.mean(np.trim_zeros(counts, trim='b')[denoise_value:]) \n",
    "    elif denoise_value > 0:\n",
    "        noise = np.mean(counts[:denoise_value])\n",
    "    return noise\n",
    "\n",
    "def rate_calculation_function(count, integration_time_seconds, binsize_seconds, reprate, tau_COUNT_APD=45e-9):\n",
    "    \"\"\"Calculate rate from count data\"\"\"\n",
    "    rate_measured = count / (binsize_seconds * integration_time_seconds * reprate)\n",
    "    return rate_measured\n",
    "\n",
    "def process_trpl_data(data, row_widgets, denoise_value, lambda_laser, spot_area, thickness, bd_ratio, bg, nc, nv, kt):\n",
    "    \"\"\"Process TRPL data and update the dataframe with calculated values\"\"\"\n",
    "    # Update data with widget values\n",
    "    data[\"repetition_rate\"] = [row_widget['rep_rate'].value for row_widget in row_widgets]\n",
    "    data[\"laser_power\"] = [row_widget['power'].value for row_widget in row_widgets]\n",
    "    data[\"nd\"] = [row_widget['nd'].value for row_widget in row_widgets]\n",
    "    data[\"integration_time\"] = [row_widget['integration_time'].value for row_widget in row_widgets]\n",
    "    \n",
    "    # Calculate noise for each sample\n",
    "    # data[\"noise\"] = [rate_calculation_function(calculate_noise(counts, denoise_value) for counts, int_time, rep_rate, ns_perB in zip(data[\"counts\"], data[\"integration_time\"], data[\"repetition_rate\"], data[\"integration_time\"],) ]\n",
    "    data[\"noise\"] = [calculate_noise(counts, denoise_value) for counts in data[\"counts\"]]\n",
    "    \n",
    "    # Process counts data\n",
    "    counts_no_noise_list = []\n",
    "    counts_no_noise_normalized_list = []\n",
    "    noise_new_list = []\n",
    "    counts_list = []\n",
    "    for i, row in data.iterrows():\n",
    "        counts_list.append(rate_calculation_function(np.array(row.counts), row.integration_time, row.ns_per_bin, row.repetition_rate))\n",
    "        counts_no_noise = np.array(row.counts) - row.noise\n",
    "        counts_no_noise = rate_calculation_function(counts_no_noise, row.integration_time, row.ns_per_bin, row.repetition_rate)\n",
    "        print(\"Before Noise:\", row.noise)\n",
    "        noise_new_list.append(rate_calculation_function(row.noise, row.integration_time, row.ns_per_bin, row.repetition_rate))\n",
    "        print(\"After Noise:\", rate_calculation_function(row.noise, row.integration_time, row.ns_per_bin, row.repetition_rate))\n",
    "        counts_no_noise_list.append(counts_no_noise)\n",
    "        counts_no_noise_normalized_list.append(counts_no_noise / np.amax(counts_no_noise))\n",
    "    \n",
    "    data[\"counts_no_noise\"] = counts_no_noise_list \n",
    "    data[\"counts_no_noise_normalized\"] = counts_no_noise_normalized_list \n",
    "    data[\"noise\"] = noise_new_list\n",
    "    data[\"counts\"] = counts_list\n",
    "    \n",
    "    # Calculate physical constants and N0s\n",
    "    hc = 1.98645E-25\n",
    "    ni = np.sqrt(nc * nv * np.exp(-bg / kt))\n",
    "    data[\"n0s\"], data[\"fluences\"] = calculate_N0s(hc, spot_area, lambda_laser, thickness, bd_ratio, data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot_trpl_results(data):\n",
    "    \"\"\"Create plot showing TRPL results for all samples\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        time_data = np.array(row['time'])\n",
    "        counts_normalized = np.array(row['counts_no_noise'])\n",
    "        sample_id = row['sample_id']\n",
    "\n",
    "        #including noise\n",
    "        sc = ax.scatter(time_data, row.counts, label=f'{sample_id}', marker='o', s=3)\n",
    "        ax.axhline(row.noise, linestyle = \"--\", color = sc.get_facecolors()[-1])\n",
    "        ax.axhline(np.average(row.counts[:50]), color = sc.get_facecolors()[-1])\n",
    "    \n",
    "    ax.set_xlabel('Time [ns]')\n",
    "    ax.set_ylabel('Counts [a.u.]')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('TRPL Analysis: Counts vs Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def fitfunc(x, *args):\n",
    "    \"\"\"\n",
    "    \n",
    "    Used for fitting of a multi (varying amount defined by len(args)) of exponential decay.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: evaluation points of function.\n",
    "    \n",
    "    *args : arguments for multiexponential decay. len(args) has to be 2n + 1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    f = arg[0] + arg[1]*exp(-arg[2]*x) + ... + arg[i]*exp(-arg[i+1]*x)\n",
    "    \n",
    "    \"\"\"\n",
    "    #print(args)\n",
    "    params = np.array([arg for arg in args])\n",
    "    #params = params[:-1]\n",
    "    \n",
    "    if ((len(params) == 1) or (len(params) > 30)):\n",
    "        print(\"Number of params is wrong n = \"+str(len(params))+\"\\n\")\n",
    "    \n",
    "    s = params[0]\n",
    "    for p1, p2 in zip(params[1::2], params[2::2]):\n",
    "        s = s + p1*np.exp(-p2*x)\n",
    "            \n",
    "    return s\n",
    "\n",
    "def fitfunc_2(x, *all_args):\n",
    "    \"\"\"\n",
    "    Multi-exponential decay with a fixed constant c at the end of all_args.\n",
    "\n",
    "    all_args = (p0, p1, p2, ..., p_{2n}, c_fixed)\n",
    "    \n",
    "    params (p0..p_{2n}) are fitted.\n",
    "    c_fixed is passed separately to curve_fit via its 'args' parameter\n",
    "    and is NOT fitted.\n",
    "    \"\"\"\n",
    "    params = np.array(all_args)\n",
    "    \n",
    "    # Original checks still apply to the variable params:\n",
    "    if ((len(params) == 1) or (len(params) > 30)):\n",
    "        print(\"Number of params is wrong n = \" + str(len(params)) + \"\\n\")\n",
    "    \n",
    "    # Your original multi-exponential structure:\n",
    "    s = 0\n",
    "    for p1, p2 in zip(params[0::2], params[1::2]):\n",
    "        s = s + p1 * np.exp(-p2 * x)\n",
    "            \n",
    "    # Add the fixed constant instead of global `noise`\n",
    "    return s\n",
    "\n",
    "def fit_difflifetimes(data, n_exp = None, l2 = None, noise = None):\n",
    "        \"\"\"\n",
    "        Calculates differential lifetime values, given a raw TRPL table, using a arbritrary amount of exponentials to fit the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time: time values, array like.\n",
    "        \n",
    "        TRPL_denoised : denoised TRPL values, array-like\n",
    "        \n",
    "        powers : Powers corresponding to the second dimension of TRPL_raw, array-like\n",
    "        \n",
    "        thickness : thickness of the samples, in cm.\n",
    "        \n",
    "        l2: number of data points considered for fitting.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        time_fit: x_axis considered for fit\n",
    "        densities2: the calculated carrier densities following n0*sqrt(data)\n",
    "        diff_taus: diffenrential lifetimes, tau_diff = -2*(dt/d(log(fit))). following Thomas Kirchartzs' work\n",
    "        \n",
    "        \"\"\"\n",
    "        if n_exp == None:\n",
    "            n_exp = 3\n",
    "        \n",
    "        diff_taus = []\n",
    "        densities2 = []\n",
    "        time_fit = []\n",
    "        print(\"Number of exponentials for fit used is = \"+str(n_exp)+\"\\n\")\n",
    "        f, ax = plt.subplots(3, len(data), figsize=(25,12))\n",
    "        i = 0 \n",
    "        for _, row in data.iterrows():\n",
    "            #t = time[i, (ns_raw[i, :] > 2*self.Noise[selection[0]]) & (time[i,:] > 0)]\n",
    "            t = np.array(row.time)\n",
    "            pl = np.array(row.counts_no_noise)\n",
    "            print(\"Noise Level:\", row.noise)\n",
    "            \n",
    "            pl_argmax = np.argmax(pl)\n",
    "            t = t[pl_argmax:] / 1e12\n",
    "            pl = pl[pl_argmax:]\n",
    "\n",
    "            t_min = t[0]\n",
    "            t = t - t_min\n",
    "        \n",
    "            p = [1, 1e4]*(n_exp[i])\n",
    "            lb = (1e-12,)*(2*n_exp[i])\n",
    "            ub = (np.inf,)*(2*n_exp[i])\n",
    "            \n",
    "            # fit_sav = savgol_filter(pl,51,3)\n",
    "            # s= 1e-5\n",
    "            # knots = list(generate_knots(t, fit_sav, s=s, k=3, nest=30))\n",
    "            # fit_knots = make_splrep(t,fit_sav,k=3, s=s, t=knots[-1])(t)\n",
    "\n",
    "            # 1) smooth with Savitzky‚ÄìGolay\n",
    "            fit_sav = savgol_filter(pl, 51, 3)\n",
    "            s = 1e-5\n",
    "            # 2) choose knots (your existing routine)\n",
    "            knots = list(generate_knots(t, fit_sav, s=s, k=3, nest=30))\n",
    "            # 3) unconstrained smoothing spline (just to get knots + initial coeffs)\n",
    "            spr0 = make_splrep(t, fit_sav, k=3, s=s, t=knots[-1])\n",
    "            fit_knots = make_splrep(t, fit_sav, k=3, s=s, t=knots[-1])(t)\n",
    "            mask = fit_knots > 10*row.noise\n",
    "            # 4) refit coefficients with convexity constraint f'' >= 0\n",
    "            # spl_convex = fit_monotone_convex_spline_from_bspline(t[fit_knots > 2*row.noise], fit_sav[fit_knots > 2*row.noise], spr0, n_grid=300, tol_d1=1e-6, tol_d2 = 1e-6)\n",
    "            spl_convex = fit_convex_spline_from_bspline(t[mask], fit_sav[mask], spr0, n_grid=300, tol = 0.0)\n",
    "            spl_convex = spl_convex(t[mask])\n",
    "        \n",
    "            p, _ = scipy.optimize.curve_fit(lambda x, *params: fitfunc_2(x, *params) + row.noise, 1e3*t[mask], pl[mask], maxfev = 100000, p0 = p, bounds = (lb, ub))\n",
    "            fit = (fitfunc_2(t*1e3, *p) + row.noise)\n",
    "            print(\"P =\", p)\n",
    "            t+= t_min\n",
    "            tau_diff = -2*(np.diff(t)/np.diff(np.log(fit)))\n",
    "            carrier_densities_fit = np.sqrt(fit/np.max(fit))*(row.n0s)\n",
    "            # print('{:.2e}'.format(row.n0s))\n",
    "\n",
    "            tau_diffSpline = -2*(np.diff(t[mask])/np.diff(np.log(spl_convex)))\n",
    "            carrier_densities_fitSpline = np.sqrt(spl_convex/np.max(spl_convex))*(row.n0s)\n",
    "            \n",
    "            #Plotting\n",
    "            sc = ax[0, i].scatter(1e9*t, pl, marker = 'x')\n",
    "            facecolors = sc.get_facecolors()\n",
    "            ax[0, i].axhline(row.noise, linestyle = \"--\", color = facecolors[-1])\n",
    "            ax[0, i].axhline(2*row.noise, color = 'red')\n",
    "            ax[0, i].plot(1e9*t[mask], np.abs(fit_knots[mask]), color = 'red')\n",
    "            ax[0, i].plot(1e9*t[:len(spl_convex)], np.abs(spl_convex), color = 'green')\n",
    "            ax[0, i].plot(1e9*t[:len(fit)], np.abs(fit), color = 'orange')\n",
    "            ax[0, i].set_yscale(\"log\")\n",
    "            ax[0, i].set_xlabel(\"time [ns]\")\n",
    "            ax[0, i].set_ylabel(\"PL counts [#]\")\n",
    "\n",
    "            ax[1, i].plot(1e9*t[:len(tau_diff)], tau_diff)\n",
    "            ax[1, i].plot(1e9*t[:len(tau_diffSpline)], tau_diffSpline, color = \"green\")\n",
    "            ax[1, i].set_xlim([min(1e9*t), max(1e9*t[:len(tau_diff)])])\n",
    "            ax[1, i].set_xlabel(\"time [ns]\")\n",
    "            ax[1, i].set_ylabel(\"Differential lifetime [s]\")\n",
    "            \n",
    "            ax[2, i].plot(carrier_densities_fit[1:], tau_diff)\n",
    "            ax[2, i].plot(carrier_densities_fitSpline[1:], tau_diffSpline, color = \"green\")\n",
    "            ax[2, i].set_xlabel(\"Carrier Concentration [cm-3]\")\n",
    "            ax[2, i].set_ylabel(\"Differential lifetime [s]\")\n",
    "            ax[2, i].set_xscale(\"log\")\n",
    "            ax[2, i].set_yscale(\"log\")\n",
    "        \n",
    "            densities2.append(carrier_densities_fit)\n",
    "            diff_taus.append(tau_diff)\n",
    "            time_fit.append(t[:len(fit)])\n",
    "            i+=1\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "        f = plt.figure()\n",
    "        for i, (b, c) in enumerate(zip(diff_taus, densities2)):\n",
    "            plt.plot(c[:-1], b)\n",
    "            #plt.plot(c[0:cut], savgol_filter(b[0:cut], 20, 7, mode = \"nearest\"))\n",
    "            \n",
    "        ax = f.gca()\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel(\"Carrier Density [cm-3]\")\n",
    "        ax.set_ylabel(\"Differential lifetime [s]\")\n",
    "        plt.legend(range(len(data)), loc = 'upper left')                                                                                                                               \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # return time_fit, densities2, diff_taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ca750b-956e-4633-834f-0722a1fa900f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e91d60ac344c0186bfaef40280af7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Select batches from all 215 available batches, or use the filter button below:</‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0901f05a9a44aa39de10e41b72af2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5750a8987c447929b1e38d2ec534c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warning_sign = \"\\u26A0\"\n",
    "\n",
    "out = widgets.Output()\n",
    "out2 = widgets.Output()\n",
    "read = widgets.Output()\n",
    "dynamic_content = widgets.Output()  # For dynamically updated content\n",
    "results_content = widgets.Output(layout={\n",
    "    # 'border': '1px solid black',  # Optional: adds a border to the widget\n",
    "    'max_height': '1000px',  # Set the height\n",
    "    'overflow': 'scroll',  # Adds a scrollbar if content overflows\n",
    "    })\n",
    "cell_edit = widgets.VBox() \n",
    "\n",
    "default_variables = widgets.Dropdown(\n",
    "    options=['sample name', 'batch',\"sample description\", 'custom'],\n",
    "    index=0,\n",
    "    description='name preset:',\n",
    "    disabled=False,\n",
    "    tooltip=\"Presets for how the samples will be named in the plot\"\n",
    ")\n",
    "data = None\n",
    "original_data = None  # To store original data for filter reset\n",
    "\n",
    "\n",
    "#this function takes sample ids and returns the eqe curves and parameters as Dataframes\n",
    "def get_trpl_data(try_sample_ids, variation):\n",
    "    #make api call, result has everything in json format\n",
    "    all_trpl = get_all_trpl(url, token, try_sample_ids, eqe_type=\"HySprint_TimeResolvedPhotoluminescence\")\n",
    "\n",
    "    existing_sample_ids = pd.Series(all_trpl.keys())\n",
    "\n",
    "    # Check if there's any EQE data\n",
    "    if len(existing_sample_ids) == 0:\n",
    "        return None  # Return None value to indicate no data\n",
    "\n",
    "    sample_params_list = []\n",
    "    for sample_id, sample_data in all_trpl.items():\n",
    "        for trpl_entry in sample_data:\n",
    "            df = pd.DataFrame()\n",
    "            df[\"counts\"] = [trpl_entry[0][\"trpl_properties\"][\"counts\"]]\n",
    "            df[\"time\"] = [trpl_entry[0][\"trpl_properties\"][\"time\"]]\n",
    "            df[\"ns_per_bin\"] = [trpl_entry[0][\"trpl_properties\"][\"ns_per_bin\"]]\n",
    "            df[\"sample_id\"] = sample_id\n",
    "            data_file = trpl_entry[0].get(\"data_file\")\n",
    "            if data_file:\n",
    "                data_file = \".\".join(data_file.split(\".\")[1:-2])\n",
    "            df[\"data_file\"] = data_file\n",
    "\n",
    "            df[\"variation\"] = variation.get(sample_id, '')\n",
    "            df[\"name\"] = trpl_entry[0].get(\"name\", '')\n",
    "            sample_params_list.append(df)\n",
    "    \n",
    "      \n",
    "    # Only try to concatenate if there's data\n",
    "    if sample_params_list:\n",
    "        return pd.concat(sample_params_list)\n",
    "    return None\n",
    "\n",
    "def on_load_data_clicked(batch_ids_selector):\n",
    "    #global dictionary to hold data\n",
    "    global data, original_data\n",
    "    dynamic_content.clear_output()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print(\"Loading Data\")\n",
    "\n",
    "        try_sample_ids = get_ids_in_batch(url, token, batch_ids_selector.value)\n",
    "\n",
    "        #extract EQE here\n",
    "        identifiers = get_sample_description(url, token, list(try_sample_ids))\n",
    "        data = get_trpl_data(try_sample_ids, identifiers)\n",
    "\n",
    "        # Check if EQE data was found\n",
    "        if data is None:\n",
    "            out.clear_output()\n",
    "            print(\"The batches selected don't contain any TRPL measurements\")\n",
    "            return\n",
    "\n",
    "        # Store original data for filter reset functionality\n",
    "        original_data = data.copy()\n",
    "        \n",
    "        out.clear_output()\n",
    "        print(\"Data Loaded\")\n",
    "            \n",
    "        # Create parameter widgets\n",
    "        with dynamic_content:\n",
    "            dynamic_content.clear_output()\n",
    "            \n",
    "            print(\"TRPL Analysis Parameters:\")\n",
    "            \n",
    "            # Float widgets\n",
    "            bg_widget = widgets.FloatText(\n",
    "                description='BG:',\n",
    "                tooltip='Background value',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            lambda_laser_widget = widgets.FloatText(\n",
    "                value=705e-9,\n",
    "                description='lambda_laser:',\n",
    "                tooltip='Laser wavelength',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            spot_diameter_widget = widgets.FloatText(\n",
    "                value=2.72e-04,\n",
    "                description='Spot Diameter [cm]:',\n",
    "                tooltip='Spot diameter',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            thickness_widget = widgets.FloatText(\n",
    "                description='Thickness [nm]:',\n",
    "                tooltip='Thickness value',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            nc_widget = widgets.FloatText(\n",
    "                value=2e18,\n",
    "                description='Nc:',\n",
    "                tooltip='Nc parameter',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            nv_widget = widgets.FloatText(\n",
    "                value=2e18,\n",
    "                description='Nv:',\n",
    "                tooltip='Nv parameter',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            kt_widget = widgets.FloatText(\n",
    "                value=27.7e-3,\n",
    "                description='kT:',\n",
    "                tooltip='kT parameter',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            bd_ratio_widget = widgets.FloatText(\n",
    "                value=0.21,\n",
    "                description='BD_ratio:',\n",
    "                tooltip='BD ratio parameter',\n",
    "                style={'description_width': '120px'}\n",
    "            )\n",
    "            \n",
    "            # Checkbox widgets\n",
    "            denoise_widget = widgets.IntText(\n",
    "                value=0,\n",
    "                description='denoise',\n",
    "                tooltip='Choose denoise'\n",
    "            )\n",
    "            \n",
    "            retime_widget = widgets.Checkbox(\n",
    "                value=True,\n",
    "                description='retime',\n",
    "                tooltip='Enable retiming'\n",
    "            )\n",
    "            \n",
    "            # Display widgets in a organized layout\n",
    "            float_widgets_box = widgets.VBox([\n",
    "                widgets.HTML(\"<h4>Float Parameters:</h4>\"),\n",
    "                bg_widget,\n",
    "                lambda_laser_widget,\n",
    "                spot_diameter_widget,\n",
    "                thickness_widget,\n",
    "                nc_widget,\n",
    "                nv_widget,\n",
    "                kt_widget,\n",
    "                bd_ratio_widget\n",
    "            ])\n",
    "            \n",
    "            checkbox_widgets_box = widgets.VBox([\n",
    "                widgets.HTML(\"<h4>Boolean Parameters:</h4>\"),\n",
    "                denoise_widget,\n",
    "                retime_widget\n",
    "            ])\n",
    "            \n",
    "            parameter_widgets = widgets.HBox([float_widgets_box, checkbox_widgets_box])\n",
    "            display(parameter_widgets)\n",
    "            \n",
    "            # Create sample-specific parameter table\n",
    "            print(\"\\nSample-specific Parameters:\")\n",
    "            rep_rate_default = 10000 # Default: 10 kHz\n",
    "            integration_time_default = 10 # Default: 10 seconds\n",
    "            power_default = 0.4 # Default: 0.4 uW\n",
    "            fitting_interval_default = 100 # Default: 100 data points\n",
    "            num_exponentials_default = 3 # Default: 3 exponentials\n",
    "            \n",
    "            # Global widgets to set all values at once\n",
    "            global_rep_rate_widget = widgets.FloatText(\n",
    "                value=rep_rate_default,  \n",
    "                description='Set all Rep. Rates:',\n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            global_power_widget = widgets.FloatText(\n",
    "                description='Set all Powers:',\n",
    "                value=power_default,  \n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            global_nd_widget = widgets.FloatText(\n",
    "                description='Set all ND:',\n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            global_integration_time_widget = widgets.FloatText(\n",
    "                description='Set all Int. Times:',\n",
    "                value=integration_time_default,  \n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            global_fitting_interval_widget = widgets.FloatText(\n",
    "                description='Set all Fitting Intervals:',\n",
    "                value=fitting_interval_default,  \n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            global_num_exponentials_widget = widgets.IntText(\n",
    "                description='Set all Num. Exponentials:',\n",
    "                value=num_exponentials_default,  \n",
    "                tooltip='Set this value to apply to all samples',\n",
    "                style={'description_width': '150px'}\n",
    "            )\n",
    "            \n",
    "            # Store individual widgets for each row\n",
    "            row_widgets = []\n",
    "            \n",
    "            # Create table header\n",
    "            header = widgets.HBox([\n",
    "                widgets.HTML(value=\"<b>Sample ID</b>\", layout=widgets.Layout(width='200px')),\n",
    "                widgets.HTML(value=\"<b>Data File</b>\", layout=widgets.Layout(width='300px')),\n",
    "                widgets.HTML(value=\"<b>Rep. Rate [kHz]</b>\", layout=widgets.Layout(width='120px')),\n",
    "                widgets.HTML(value=\"<b>Power [uW]</b>\", layout=widgets.Layout(width='120px')),\n",
    "                widgets.HTML(value=\"<b>ND</b>\", layout=widgets.Layout(width='120px')),\n",
    "                widgets.HTML(value=\"<b>Int. Time [s]</b>\", layout=widgets.Layout(width='120px')),\n",
    "                widgets.HTML(value=\"<b>Fitting Interval</b>\", layout=widgets.Layout(width='120px')),\n",
    "                widgets.HTML(value=\"<b>Num. Exponentials</b>\", layout=widgets.Layout(width='130px'))\n",
    "            ])\n",
    "            \n",
    "            # Create rows for each sample\n",
    "            table_rows = [header]\n",
    "            for idx, row in data.iterrows():\n",
    "                sample_id_label = widgets.HTML(\n",
    "                    value=str(row.get('sample_id', '')),\n",
    "                    layout=widgets.Layout(width='200px')\n",
    "                )\n",
    "                \n",
    "                data_file_label = widgets.HTML(\n",
    "                    value=str(row.get('data_file', '')),\n",
    "                    layout=widgets.Layout(width='300px')\n",
    "                )\n",
    "                \n",
    "                rep_rate_widget = widgets.FloatText(\n",
    "                    value=rep_rate_default,  \n",
    "                    layout=widgets.Layout(width='120px'),\n",
    "                    tooltip=f'Repetition rate for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                power_widget = widgets.FloatText(\n",
    "                    layout=widgets.Layout(width='120px'),\n",
    "                    value=power_default,  \n",
    "                    tooltip=f'Power for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                nd_widget = widgets.FloatText(\n",
    "                    layout=widgets.Layout(width='120px'),\n",
    "                    tooltip=f'ND for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                integration_time_widget = widgets.FloatText(\n",
    "                    value=integration_time_default,  \n",
    "                    layout=widgets.Layout(width='120px'),\n",
    "                    tooltip=f'Integration time for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                fitting_interval_widget = widgets.FloatText(\n",
    "                    value=fitting_interval_default,  \n",
    "                    layout=widgets.Layout(width='120px'),\n",
    "                    tooltip=f'Fitting interval for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                num_exponentials_widget = widgets.IntText(\n",
    "                    value=num_exponentials_default,  \n",
    "                    layout=widgets.Layout(width='130px'),\n",
    "                    tooltip=f'Number of exponentials for {row.get(\"sample_id\", \"\")}'\n",
    "                )\n",
    "                \n",
    "                row_widgets.append({\n",
    "                    'rep_rate': rep_rate_widget,\n",
    "                    'power': power_widget,\n",
    "                    'nd': nd_widget,\n",
    "                    'integration_time': integration_time_widget,\n",
    "                    'fitting_interval': fitting_interval_widget,\n",
    "                    'num_exponentials': num_exponentials_widget\n",
    "                })\n",
    "                \n",
    "                row_box = widgets.HBox([\n",
    "                    sample_id_label,\n",
    "                    data_file_label,\n",
    "                    rep_rate_widget,\n",
    "                    power_widget,\n",
    "                    nd_widget,\n",
    "                    integration_time_widget,\n",
    "                    fitting_interval_widget,\n",
    "                    num_exponentials_widget\n",
    "                ])\n",
    "                table_rows.append(row_box)\n",
    "            \n",
    "            # Functions to set all values at once\n",
    "            def set_all_rep_rates(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['rep_rate'].value = change['new']\n",
    "            \n",
    "            def set_all_powers(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['power'].value = change['new']\n",
    "            \n",
    "            def set_all_nds(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['nd'].value = change['new']\n",
    "            \n",
    "            def set_all_integration_times(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['integration_time'].value = change['new']\n",
    "            \n",
    "            def set_all_fitting_intervals(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['fitting_interval'].value = change['new']\n",
    "            \n",
    "            def set_all_num_exponentials(change):\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    for row_widget in row_widgets:\n",
    "                        row_widget['num_exponentials'].value = change['new']\n",
    "            \n",
    "            # Connect global widgets to update functions\n",
    "            global_rep_rate_widget.observe(set_all_rep_rates)\n",
    "            global_power_widget.observe(set_all_powers)\n",
    "            global_nd_widget.observe(set_all_nds)\n",
    "            global_integration_time_widget.observe(set_all_integration_times)\n",
    "            global_fitting_interval_widget.observe(set_all_fitting_intervals)\n",
    "            global_num_exponentials_widget.observe(set_all_num_exponentials)\n",
    "            \n",
    "            # Display global widgets\n",
    "            global_widgets_box = widgets.VBox([\n",
    "                widgets.HTML(\"<h4>Set All Values:</h4>\"),\n",
    "                global_rep_rate_widget,\n",
    "                global_power_widget,\n",
    "                global_nd_widget,\n",
    "                global_integration_time_widget,\n",
    "                global_fitting_interval_widget,\n",
    "                global_num_exponentials_widget\n",
    "            ])\n",
    "            display(global_widgets_box)\n",
    "            \n",
    "            # Display the table\n",
    "            table_widget = widgets.VBox(table_rows)\n",
    "            display(table_widget)\n",
    "            \n",
    "            # Create analysis button\n",
    "            analysis_button = widgets.Button(\n",
    "                description='Analysis',\n",
    "                button_style='success',\n",
    "                tooltip='Run TRPL analysis with current parameters',\n",
    "                layout=widgets.Layout(width='200px', height='40px')\n",
    "            )\n",
    "            \n",
    "            # Analysis output\n",
    "            analysis_output = widgets.Output()\n",
    "            \n",
    "            def run_analysis(b):\n",
    "                with analysis_output:\n",
    "                    analysis_output.clear_output()\n",
    "                    \n",
    "                    # Process the data using the new analysis functions\n",
    "                    spot_area = np.pi * (spot_diameter_widget.value / 2) ** 2\n",
    "                    processed_data = process_trpl_data(\n",
    "                        data=data,\n",
    "                        row_widgets=row_widgets,\n",
    "                        denoise_value=denoise_widget.value,\n",
    "                        lambda_laser=lambda_laser_widget.value,\n",
    "                        spot_area=spot_area,\n",
    "                        thickness=thickness_widget.value,\n",
    "                        bd_ratio=bd_ratio_widget.value,\n",
    "                        bg=bg_widget.value,\n",
    "                        nc=nc_widget.value,\n",
    "                        nv=nv_widget.value,\n",
    "                        kt=kt_widget.value\n",
    "                    )\n",
    "                    \n",
    "                    # Create the plot\n",
    "                    plot_trpl_results(processed_data)\n",
    "                    fit_difflifetimes(data, n_exp=[r.get(\"num_exponentials\").value for r in row_widgets], l2=[r.get(\"fitting_interval\").value for r in row_widgets],\n",
    "                                      noise = processed_data['noise'].to_numpy())\n",
    "                    \n",
    "                    print(\"Analysis completed successfully!\")\n",
    "            \n",
    "            # Connect button to analysis function\n",
    "            analysis_button.on_click(run_analysis)\n",
    "            \n",
    "            # Display button and output\n",
    "            display(analysis_button)\n",
    "            display(analysis_output)\n",
    "            \n",
    "# BATCH SELECTION WITH OPTIONAL FILTERING\n",
    "def create_batch_selection_with_optional_filtering():\n",
    "    \"\"\"\n",
    "    Create batch selection widget with optional filtering button\n",
    "    \"\"\"\n",
    "    # Create the original batch selection widget (fast)\n",
    "    original_batch_widget = batch_selection.create_batch_selection(url, token, on_load_data_clicked)\n",
    "    \n",
    "    # Get the batch selector from the original widget to count total batches\n",
    "    batch_selector = None\n",
    "    for child in original_batch_widget.children:\n",
    "        if isinstance(child, widgets.SelectMultiple):\n",
    "            batch_selector = child\n",
    "            break\n",
    "    \n",
    "    total_batches = len(batch_selector.options) if batch_selector else 0\n",
    "    \n",
    "    # Create filter button\n",
    "    filter_button = widgets.Button(\n",
    "        description=f\"üîç Filter to show only batches with AbsPL data\",\n",
    "        button_style='info',\n",
    "        tooltip=f'Click to filter {total_batches} batches (this may take a few minutes)',\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    # Create status output\n",
    "    filter_status = widgets.Output()\n",
    "    \n",
    "    # Filter function\n",
    "    def start_filtering(b):\n",
    "        filter_button.disabled = True\n",
    "        filter_button.description = \"üîÑ Filtering in progress...\"\n",
    "        \n",
    "        with filter_status:\n",
    "            filter_status.clear_output(wait=True)\n",
    "            print(\"Finding batches with TRPL data...\")\n",
    "            \n",
    "            # Get all batch IDs using the same filtering as the original batch_selection\n",
    "            batch_ids_list_tmp = list(get_batch_ids(url, token))\n",
    "            all_batch_ids = []\n",
    "            for batch in batch_ids_list_tmp:\n",
    "                if \"_\".join(batch.split(\"_\")[:-1]) in batch_ids_list_tmp:\n",
    "                    continue\n",
    "                all_batch_ids.append(batch)\n",
    "            \n",
    "            print(f\"Testing {len(all_batch_ids)} batches...\")\n",
    "            \n",
    "            valid_batches = get_all_batches_wth_data(url, token, \"HySprint_TimeResolvedPhotoluminescence\")\n",
    "            \n",
    "            \n",
    "            # Update the original widget's options\n",
    "            if batch_selector:\n",
    "                batch_selector.options = valid_batches\n",
    "            \n",
    "            # Show final results\n",
    "            filter_status.clear_output(wait=True)\n",
    "            print(\"=\"*60)\n",
    "            print(\"FILTERING COMPLETE\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"‚úÖ Found {len(valid_batches)} batches with TRPL data out of {total_batches} total\")\n",
    "            if len(valid_batches) > 0:\n",
    "                print(f\"Valid batches: {valid_batches}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No batches with TRPL data found!\")\n",
    "            \n",
    "            # Update button\n",
    "            filter_button.description = f\"‚úÖ Filtering complete - {len(valid_batches)} valid batches found\"\n",
    "            filter_button.disabled = True\n",
    "            \n",
    "            # Add info to the widget\n",
    "            info_html = widgets.HTML(\n",
    "                value=f\"<p><b>Showing {len(valid_batches)} of {total_batches} batches with confirmed AbsPL data</b></p>\"\n",
    "            )\n",
    "            original_batch_widget.children = (info_html,) + original_batch_widget.children\n",
    "    \n",
    "    # Connect the button\n",
    "    filter_button.on_click(start_filtering)\n",
    "    \n",
    "    # Create the complete widget\n",
    "    complete_widget = widgets.VBox([\n",
    "        widgets.HTML(f\"<p>Select batches from all {total_batches} available batches, or use the filter button below:</p>\"),\n",
    "        filter_button,\n",
    "        filter_status,\n",
    "        original_batch_widget\n",
    "    ])\n",
    "    \n",
    "    return complete_widget\n",
    "\n",
    "\n",
    "# Create and display the batch selection widget with optional filtering\n",
    "batch_widget = create_batch_selection_with_optional_filtering()\n",
    "display(batch_widget)\n",
    "\n",
    "display(out)\n",
    "display(dynamic_content)  # This will be updated dynamically with the variables menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc3a3d-664d-4887-9a1f-3bd0ca5f9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
