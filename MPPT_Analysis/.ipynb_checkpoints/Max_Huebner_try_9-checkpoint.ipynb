{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbec989-5d8a-471a-b5fb-c1d9873f8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Detected 12 files per sample.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea5e829e9ed4d66855e30968c261aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>‚û°Ô∏è Detected core level names:</b><br>Survey<br>Pb4f<br>N1s<br>C1s<br>VBM<br>Cs3d‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "import shutil  \n",
    "from datetime import datetime\n",
    "from ipywidgets import HTML, Button, VBox, Output, FloatRangeSlider\n",
    "from IPython.display import display\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "# === USER INPUT SECTION ===\n",
    "sample_folders = sorted(glob.glob(\"./samples/sample*/\"))  # Adjust if needed\n",
    "output_base_folder = \"./output_aligned/\"\n",
    "align_to = \"first\"  # or \"mean\"\n",
    "\n",
    "sample_files = [sorted(glob.glob(os.path.join(folder, \"*.xy\"))) for folder in sample_folders]\n",
    "num_files_per_sample = len(sample_files[0])\n",
    "assert all(len(files) == num_files_per_sample for files in sample_files), \"Mismatch in file count!\"\n",
    "\n",
    "print(f\"üß™ Detected {num_files_per_sample} files per sample.\")\n",
    "\n",
    "# Core level name extraction rule\n",
    "def extract_core_level_name(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split(\"_\")[::-1]  # Reverse for parsing from end\n",
    "    core_parts = []\n",
    "    found = False\n",
    "\n",
    "    for part in parts:\n",
    "        core_parts.insert(0, part)\n",
    "        if re.match(r'^[A-Za-z].*', part):  # Ends when finding first alpha-start part\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    return \"_\".join(core_parts) if found else base\n",
    "\n",
    "# Auto-detect core level names\n",
    "core_level_names = [extract_core_level_name(os.path.basename(f)) for f in sample_files[0]]\n",
    "\n",
    "# Display detected core levels\n",
    "output_area = Output()\n",
    "core_levels_display = HTML(value=f\"<b>‚û°Ô∏è Detected core level names:</b><br>{'<br>'.join(core_level_names)}\")\n",
    "confirm_button = Button(description=\"OK\", button_style='success')\n",
    "\n",
    "def on_confirm_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        print(\"‚úÖ Core levels set:\", core_level_names)\n",
    "        run_interface(core_level_names)\n",
    "\n",
    "confirm_button.on_click(on_confirm_clicked)\n",
    "display(VBox([core_levels_display, confirm_button, output_area]))\n",
    "\n",
    "# === Gaussian function ===\n",
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "# === MAIN PROCESSING ===\n",
    "def process_core_level(core_idx, core_name):\n",
    "    spectra_raw = []\n",
    "    for sample in sample_files:\n",
    "        path = sample[core_idx]\n",
    "        data = np.loadtxt(path)\n",
    "        x, y = data[:, 0], data[:, 1]\n",
    "        spectra_raw.append((x, y))\n",
    "\n",
    "    print(f\"\\nüîé Core Level: {core_name}\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for x, y in spectra_raw:\n",
    "        plt.plot(x, y)\n",
    "    plt.title(f\"Core Level: {core_name} ‚Äî Raw Spectra\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    x_all = np.concatenate([x for x, _ in spectra_raw])\n",
    "    x_min_slider = np.min(x_all)\n",
    "    x_max_slider = np.max(x_all)\n",
    "\n",
    "    interval_slider = FloatRangeSlider(\n",
    "        value=[x_min_slider + 0.1*(x_max_slider - x_min_slider), x_max_slider - 0.1*(x_max_slider - x_min_slider)],\n",
    "        min=x_min_slider,\n",
    "        max=x_max_slider,\n",
    "        step=0.1,\n",
    "        description='Peak range:',\n",
    "        continuous_update=False,\n",
    "        layout={\"width\": \"80%\"}\n",
    "    )\n",
    "\n",
    "    background_range_slider = widgets.IntRangeSlider(\n",
    "        value=[-20, -10],\n",
    "        min=-100,\n",
    "        max=0,\n",
    "        step=1,\n",
    "        description=\"Background Range (rel. to peak)\",\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width=\"60%\")\n",
    "    )\n",
    "\n",
    "    fit_slider = FloatRangeSlider(\n",
    "        value=[x_min_slider + 0.15*(x_max_slider - x_min_slider), x_max_slider - 0.15*(x_max_slider - x_min_slider)],\n",
    "        min=x_min_slider,\n",
    "        max=x_max_slider,\n",
    "        step=0.1,\n",
    "        description='Fit range:',\n",
    "        continuous_update=False,\n",
    "        layout={\"width\": \"80%\"}\n",
    "    )\n",
    "\n",
    "    display(background_range_slider)\n",
    "\n",
    "    out = Output()\n",
    "    run_button = Button(description=\"Align, Normalize & Fit\", button_style='success')\n",
    "\n",
    "    def on_click_run(b):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            x_min, x_max = interval_slider.value\n",
    "            fit_min, fit_max = fit_slider.value\n",
    "            bg_rel_min, bg_rel_max = background_range_slider.value\n",
    "\n",
    "            peak_positions = []\n",
    "            spectra_norm = []\n",
    "            background_values = []\n",
    "            peak_values = []\n",
    "            fit_areas = []\n",
    "\n",
    "            for x, y in spectra_raw:\n",
    "                mask_peak = (x >= x_min) & (x <= x_max)\n",
    "                peak_idx = np.argmax(y[mask_peak])\n",
    "                peak_x = x[mask_peak][peak_idx]\n",
    "                peak_y = y[mask_peak][peak_idx]\n",
    "                peak_positions.append(peak_x)\n",
    "                peak_values.append(peak_y)\n",
    "\n",
    "                bg_abs_min = peak_x + bg_rel_min\n",
    "                bg_abs_max = peak_x + bg_rel_max\n",
    "                mask_bg = (x >= bg_abs_min) & (x <= bg_abs_max)\n",
    "                bg_avg = np.mean(y[mask_bg])\n",
    "                background_values.append(bg_avg)\n",
    "\n",
    "                norm_y = (y - bg_avg) / (peak_y - bg_avg)\n",
    "                spectra_norm.append((x, norm_y))\n",
    "\n",
    "            ref_peak = peak_positions[0] if align_to == \"first\" else np.mean(peak_positions)\n",
    "\n",
    "            spectra_aligned = []\n",
    "            shifts_record = []\n",
    "            sample_names = [os.path.basename(os.path.normpath(folder)) for folder in sample_folders]\n",
    "\n",
    "            plt.figure(figsize=(7, 5))\n",
    "\n",
    "            for i, ((x, y), peak_x, sample_name) in enumerate(zip(spectra_norm, peak_positions, sample_names)):\n",
    "                x_shifted = x + (ref_peak - peak_x)\n",
    "                spectra_aligned.append((x_shifted, y))\n",
    "\n",
    "                shift_amount = ref_peak - peak_positions[i]\n",
    "                delta = peak_values[i] - background_values[i]\n",
    "\n",
    "                # Gaussian fit in fit range\n",
    "                fit_mask = (x_shifted >= fit_min) & (x_shifted <= fit_max)\n",
    "                x_fit = x_shifted[fit_mask]\n",
    "                y_fit = y[fit_mask]\n",
    "                try:\n",
    "                    popt, _ = curve_fit(gaussian, x_fit, y_fit, p0=[1, ref_peak, 1])\n",
    "                    A, mu, sigma = popt\n",
    "                    y_gauss = gaussian(x_fit, *popt)\n",
    "                    if x_fit[0] > x_fit[-1]:\n",
    "                        x_fit = x_fit[::-1]\n",
    "                        y_gauss = y_gauss[::-1]\n",
    "                    area = simpson(y_gauss, x_fit)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Fit failed for sample {sample_name}: {e}\")\n",
    "                    area = np.nan\n",
    "\n",
    "                fit_areas.append(area)\n",
    "\n",
    "                shifts_record.append({\n",
    "                    \"sample\": sample_name,\n",
    "                    \"core_level\": core_name,\n",
    "                    \"file\": os.path.basename(sample_files[i][core_idx]),\n",
    "                    \"x_shift_applied\": shift_amount,\n",
    "                    \"peak_value\": peak_values[i],\n",
    "                    \"background_value\": background_values[i],\n",
    "                    \"peak_minus_background\": delta,\n",
    "                    \"gaussian_area\": area\n",
    "                })\n",
    "\n",
    "                plt.plot(x_shifted, y, label=sample_name)\n",
    "                if not np.isnan(area):\n",
    "                    plt.plot(x_fit, y_gauss, \"--\", label=f\"{sample_name} fit\")\n",
    "\n",
    "                # Save aligned spectra\n",
    "                output_folder = os.path.join(output_base_folder, sample_name)\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                output_path = os.path.join(output_folder, f\"{core_name}.xy\")\n",
    "                np.savetxt(output_path, np.column_stack((x_shifted, y)), fmt=\"%.6f\")\n",
    "\n",
    "            plt.title(f\"{core_name} ‚Äì Aligned + Normalized with Gaussian Fits\")\n",
    "            plt.xlabel(\"x (shifted)\")\n",
    "            plt.ylabel(\"Normalized y\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Bar chart of peak - background\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sample_labels = [r[\"sample\"] for r in shifts_record]\n",
    "            delta_values = [r[\"peak_minus_background\"] for r in shifts_record]\n",
    "            plt.bar(sample_labels, delta_values, color=\"skyblue\")\n",
    "            plt.title(f\"{core_name} ‚Äì Peak Minus Background per Sample\")\n",
    "            plt.ylabel(\"Peak - Background\")\n",
    "            plt.xlabel(\"Sample\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(axis='y', linestyle=\"--\", alpha=0.6)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Save CSV\n",
    "            shifts_csv_path = os.path.join(output_base_folder, \"shifts.csv\")\n",
    "            backup_csv_path = os.path.join(output_base_folder, \"shifts_backup.csv\")\n",
    "\n",
    "            # Create DataFrame from new records and add timestamp\n",
    "            df_new = pd.DataFrame(shifts_record)\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            df_new[\"timestamp\"] = timestamp\n",
    "\n",
    "            # === 1. Update shifts.csv (deduplicated main record) ===\n",
    "            if os.path.exists(shifts_csv_path):\n",
    "                df_existing = pd.read_csv(shifts_csv_path)\n",
    "                mask = ~df_existing.set_index([\"sample\", \"core_level\", \"file\"]).index.isin(\n",
    "                    df_new.set_index([\"sample\", \"core_level\", \"file\"]).index\n",
    "                )\n",
    "                df_filtered = df_existing[mask]\n",
    "                df_combined = pd.concat([df_filtered, df_new.drop(columns=[\"timestamp\"])], ignore_index=True)\n",
    "            else:\n",
    "                df_combined = df_new.drop(columns=[\"timestamp\"])\n",
    "\n",
    "            df_combined.sort_values(by=[\"core_level\", \"sample\", \"file\"], inplace=True)\n",
    "            df_combined.to_csv(shifts_csv_path, index=False)\n",
    "            print(f\"üìÑ Updated main shifts file: {shifts_csv_path}\")\n",
    "\n",
    "            # === 2. Append all new entries (with timestamp) to persistent backup ===\n",
    "            if os.path.exists(backup_csv_path):\n",
    "                df_backup_existing = pd.read_csv(backup_csv_path)\n",
    "                df_backup_combined = pd.concat([df_backup_existing, df_new], ignore_index=True)\n",
    "            else:\n",
    "                df_backup_combined = df_new\n",
    "\n",
    "            df_backup_combined.sort_values(by=[\"core_level\", \"sample\", \"file\"], inplace=True)\n",
    "            df_backup_combined.to_csv(backup_csv_path, index=False)\n",
    "            print(f\"üóÇÔ∏è  Appended results (with timestamp) to backup: {backup_csv_path}\")\n",
    "\n",
    "\n",
    "    run_button.on_click(on_click_run)\n",
    "    display(VBox([interval_slider, fit_slider, run_button, out]))\n",
    "\n",
    "def run_interface(core_level_names):\n",
    "    for idx, core_name in enumerate(core_level_names):\n",
    "        print(f\"\\n==============================\")\n",
    "        print(f\" Core Level: {core_name}\")\n",
    "        print(f\"==============================\")\n",
    "        process_core_level(idx, core_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e61da4-2a3e-4fc4-88e1-a4830a91846b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359f231-d66e-4555-be4c-e7da5232d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27a7ac97-68a5-41da-9cdf-df588c314a2a",
   "metadata": {},
   "source": [
    "Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a0b7cd-96bd-4506-bbb0-9e96c3a3763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./samples/sample1/: 12 .xy files\n",
      "./samples/sample2/: 12 .xy files\n",
      "./samples/sample3/: 12 .xy files\n",
      "./samples/sample4/: 12 .xy files\n",
      "./samples/sample5/: 12 .xy files\n",
      "./samples/sample6/: 12 .xy files\n"
     ]
    }
   ],
   "source": [
    "for folder in sample_folders:\n",
    "    files = glob.glob(os.path.join(folder, \"*.xy\"))\n",
    "    print(f\"{folder}: {len(files)} .xy files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
