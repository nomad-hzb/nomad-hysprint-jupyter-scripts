{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608ac38e-4a46-4356-8436-bf0afa0745e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".analysis-header {\n",
       "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "    color: white;\n",
       "    padding: 20px;\n",
       "    border-radius: 10px;\n",
       "    margin-bottom: 20px;\n",
       "    text-align: center;\n",
       "    box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
       "}\n",
       ".section-header {\n",
       "    background: linear-gradient(90deg, #4facfe 0%, #00f2fe 100%);\n",
       "    color: white;\n",
       "    padding: 10px 15px;\n",
       "    border-radius: 5px;\n",
       "    margin: 15px 0 10px 0;\n",
       "    font-weight: bold;\n",
       "}\n",
       ".parameter-box {\n",
       "    border: 2px solid #e1e5e9;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px;\n",
       "    margin: 10px 0;\n",
       "    background: #f8f9fa;\n",
       "}\n",
       ".success-box {\n",
       "    background: #d4edda;\n",
       "    border: 1px solid #c3e6cb;\n",
       "    color: #155724;\n",
       "    padding: 10px;\n",
       "    border-radius: 5px;\n",
       "    margin: 10px 0;\n",
       "}\n",
       ".warning-box {\n",
       "    background: #fff3cd;\n",
       "    border: 1px solid #ffeaa7;\n",
       "    color: #856404;\n",
       "    padding: 10px;\n",
       "    border-radius: 5px;\n",
       "    margin: 10px 0;\n",
       "}\n",
       ".error-box {\n",
       "    background: #f8d7da;\n",
       "    border: 1px solid #f5c6cb;\n",
       "    color: #721c24;\n",
       "    padding: 10px;\n",
       "    border-radius: 5px;\n",
       "    margin: 10px 0;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"analysis-header\">\n",
       "    <h1>üî¨ Advanced Spectral Analysis Suite</h1>\n",
       "    <h3>Professional Time-Resolved Spectroscopy Analysis Platform</h3>\n",
       "    <p>Comprehensive peak fitting, temporal analysis, and data visualization for research laboratories</p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Initializing Advanced Spectral Analysis Suite...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57b1db354ed4d6dacc7d66afc1c16d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HTML(value='<div class=\"section-header\">üìÅ Data Loading</div>'), H‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f9c88960524558b3df71dc49881c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<h3>üß™ Quick Start</h3>'), Button(button_style='info', description='Load Example Dat‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced Spectral Analysis Suite is ready!\n",
      "\n",
      "üìã Features available:\n",
      "   ‚Ä¢ Multi-format data loading (Excel, CSV)\n",
      "   ‚Ä¢ Advanced preprocessing (smoothing, baseline correction)\n",
      "   ‚Ä¢ Intelligent peak detection\n",
      "   ‚Ä¢ Parallel multi-model fitting\n",
      "   ‚Ä¢ Real-time visualization\n",
      "   ‚Ä¢ Parameter evolution tracking\n",
      "   ‚Ä¢ Quality metrics assessment\n",
      "   ‚Ä¢ Animation creation and export\n",
      "   ‚Ä¢ Comprehensive data export\n",
      "   ‚Ä¢ Session save/load functionality\n",
      "\n",
      "üöÄ Upload your spectral data or click 'Load Example Data' to begin!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import io\n",
    "import base64\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scientific computing imports\n",
    "from scipy import signal, sparse\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fitting libraries\n",
    "from lmfit import Model, Parameters\n",
    "from lmfit.models import (GaussianModel, LorentzianModel, VoigtModel, \n",
    "                         PseudoVoigtModel, LinearModel, PolynomialModel,\n",
    "                         ExponentialModel, ExponentialGaussianModel,\n",
    "                         SkewedGaussianModel, SkewedVoigtModel)\n",
    "\n",
    "# Parallel processing\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import threading\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "# File handling\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom CSS for professional appearance\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    ".analysis-header {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    color: white;\n",
    "    padding: 20px;\n",
    "    border-radius: 10px;\n",
    "    margin-bottom: 20px;\n",
    "    text-align: center;\n",
    "    box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "}\n",
    ".section-header {\n",
    "    background: linear-gradient(90deg, #4facfe 0%, #00f2fe 100%);\n",
    "    color: white;\n",
    "    padding: 10px 15px;\n",
    "    border-radius: 5px;\n",
    "    margin: 15px 0 10px 0;\n",
    "    font-weight: bold;\n",
    "}\n",
    ".parameter-box {\n",
    "    border: 2px solid #e1e5e9;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    margin: 10px 0;\n",
    "    background: #f8f9fa;\n",
    "}\n",
    ".success-box {\n",
    "    background: #d4edda;\n",
    "    border: 1px solid #c3e6cb;\n",
    "    color: #155724;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    margin: 10px 0;\n",
    "}\n",
    ".warning-box {\n",
    "    background: #fff3cd;\n",
    "    border: 1px solid #ffeaa7;\n",
    "    color: #856404;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    margin: 10px 0;\n",
    "}\n",
    ".error-box {\n",
    "    background: #f8d7da;\n",
    "    border: 1px solid #f5c6cb;\n",
    "    color: #721c24;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    margin: 10px 0;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Display custom CSS\n",
    "display(HTML(custom_css))\n",
    "\n",
    "# Display header\n",
    "header_html = \"\"\"\n",
    "<div class=\"analysis-header\">\n",
    "    <h1>üî¨ Advanced Spectral Analysis Suite</h1>\n",
    "    <h3>Professional Time-Resolved Spectroscopy Analysis Platform</h3>\n",
    "    <p>Comprehensive peak fitting, temporal analysis, and data visualization for research laboratories</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(header_html))\n",
    "\n",
    "# =============================================================================\n",
    "# CORE DATA STRUCTURES AND UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "class SpectralData:\n",
    "    \"\"\"Enhanced data container for spectral analysis\"\"\"\n",
    "    def __init__(self):\n",
    "        self.raw_data = None\n",
    "        self.processed_data = None\n",
    "        self.wavelengths = None\n",
    "        self.timepoints = None\n",
    "        self.metadata = {}\n",
    "        self.baseline_points = []\n",
    "        self.peaks = {}\n",
    "        self.fit_results = {}\n",
    "        self.quality_metrics = {}\n",
    "        \n",
    "    def load_matrix(self, data, wavelengths=None, timepoints=None):\n",
    "        \"\"\"Load data from matrix format\"\"\"\n",
    "        self.raw_data = np.array(data)\n",
    "        self.processed_data = self.raw_data.copy()\n",
    "        self.wavelengths = wavelengths if wavelengths is not None else np.arange(data.shape[0])\n",
    "        self.timepoints = timepoints if timepoints is not None else np.arange(data.shape[1])\n",
    "        \n",
    "    def apply_preprocessing(self, method='none', **kwargs):\n",
    "        \"\"\"Apply preprocessing methods\"\"\"\n",
    "        if method == 'smooth_savgol':\n",
    "            window_length = kwargs.get('window_length', 5)\n",
    "            polyorder = kwargs.get('polyorder', 2)\n",
    "            for i in range(self.processed_data.shape[1]):\n",
    "                self.processed_data[:, i] = signal.savgol_filter(\n",
    "                    self.processed_data[:, i], window_length, polyorder)\n",
    "        elif method == 'smooth_gaussian':\n",
    "            sigma = kwargs.get('sigma', 1.0)\n",
    "            for i in range(self.processed_data.shape[1]):\n",
    "                self.processed_data[:, i] = gaussian_filter1d(self.processed_data[:, i], sigma)\n",
    "                \n",
    "    def detect_peaks(self, spectrum_idx=0, **kwargs):\n",
    "        \"\"\"Detect peaks in a spectrum\"\"\"\n",
    "        height = kwargs.get('height', None)\n",
    "        distance = kwargs.get('distance', 5)\n",
    "        prominence = kwargs.get('prominence', None)\n",
    "        width = kwargs.get('width', None)\n",
    "        \n",
    "        peaks, properties = signal.find_peaks(\n",
    "            self.processed_data[:, spectrum_idx],\n",
    "            height=height, distance=distance, prominence=prominence, width=width\n",
    "        )\n",
    "        \n",
    "        return peaks, properties\n",
    "\n",
    "class FittingEngine:\n",
    "    \"\"\"Advanced fitting engine with parallel processing\"\"\"\n",
    "    def __init__(self, n_workers=None):\n",
    "        self.n_workers = n_workers or mp.cpu_count() - 1\n",
    "        self.models = {\n",
    "            'Gaussian': GaussianModel,\n",
    "            'Lorentzian': LorentzianModel,\n",
    "            'Voigt': VoigtModel,\n",
    "            'PseudoVoigt': PseudoVoigtModel,\n",
    "            'Linear': LinearModel,\n",
    "            'Polynomial': PolynomialModel,\n",
    "            'Exponential': ExponentialModel,\n",
    "            'ExpGaussian': ExponentialGaussianModel,\n",
    "            'SkewedGaussian': SkewedGaussianModel,\n",
    "            'SkewedVoigt': SkewedVoigtModel\n",
    "        }\n",
    "        \n",
    "    def create_composite_model(self, model_configs):\n",
    "        \"\"\"Create composite model from configurations\"\"\"\n",
    "        composite_model = None\n",
    "        params = Parameters()\n",
    "        \n",
    "        for i, config in enumerate(model_configs):\n",
    "            model_type = config['type']\n",
    "            prefix = config.get('prefix', f'{model_type.lower()}_{i+1}_')\n",
    "            \n",
    "            if model_type in self.models:\n",
    "                model_class = self.models[model_type]\n",
    "                if model_type == 'Polynomial':\n",
    "                    degree = config.get('degree', 2)\n",
    "                    model = model_class(prefix=prefix, degree=degree)\n",
    "                else:\n",
    "                    model = model_class(prefix=prefix)\n",
    "                \n",
    "                if composite_model is None:\n",
    "                    composite_model = model\n",
    "                else:\n",
    "                    composite_model += model\n",
    "                    \n",
    "                # Add initial parameters\n",
    "                model_params = model.make_params()\n",
    "                for param_name, param_obj in model_params.items():\n",
    "                    if param_name in config.get('initial_params', {}):\n",
    "                        param_obj.value = config['initial_params'][param_name]\n",
    "                        if 'bounds' in config and param_name in config['bounds']:\n",
    "                            bounds = config['bounds'][param_name]\n",
    "                            param_obj.min = bounds[0]\n",
    "                            param_obj.max = bounds[1]\n",
    "                        if 'fixed' in config and param_name in config['fixed']:\n",
    "                            param_obj.vary = not config['fixed'][param_name]\n",
    "                \n",
    "                params.update(model_params)\n",
    "        \n",
    "        return composite_model, params\n",
    "    \n",
    "    def fit_single_spectrum(self, x_data, y_data, model_configs, initial_params=None):\n",
    "        \"\"\"Fit a single spectrum\"\"\"\n",
    "        try:\n",
    "            model, params = self.create_composite_model(model_configs)\n",
    "            \n",
    "            if initial_params:\n",
    "                for param_name, value in initial_params.items():\n",
    "                    if param_name in params:\n",
    "                        params[param_name].value = value\n",
    "            \n",
    "            result = model.fit(y_data, params, x=x_data)\n",
    "            \n",
    "            # Calculate quality metrics\n",
    "            r_squared = 1 - result.redchi / np.var(y_data, ddof=2)\n",
    "            aic = result.aic\n",
    "            bic = result.bic\n",
    "            rmse = np.sqrt(np.mean((y_data - result.best_fit)**2))\n",
    "            \n",
    "            quality_metrics = {\n",
    "                'r_squared': r_squared,\n",
    "                'aic': aic,\n",
    "                'bic': bic,\n",
    "                'rmse': rmse,\n",
    "                'reduced_chi_squared': result.redchi\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'result': result,\n",
    "                'quality_metrics': quality_metrics,\n",
    "                'best_fit': result.best_fit,\n",
    "                'components': result.eval_components(x=x_data) if hasattr(result, 'eval_components') else {},\n",
    "                'parameters': result.params\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'result': None,\n",
    "                'quality_metrics': None\n",
    "            }\n",
    "    \n",
    "    def fit_parallel(self, spectral_data, model_configs, progress_callback=None):\n",
    "        \"\"\"Fit multiple spectra in parallel\"\"\"\n",
    "        results = {}\n",
    "        x_data = spectral_data.wavelengths\n",
    "        \n",
    "        def fit_wrapper(args):\n",
    "            idx, y_data = args\n",
    "            # Use previous results for initial parameters if available\n",
    "            initial_params = None\n",
    "            if idx > 0 and (idx-1) in results and results[idx-1]['success']:\n",
    "                initial_params = {name: param.value for name, param \n",
    "                                in results[idx-1]['parameters'].items()}\n",
    "            \n",
    "            return idx, self.fit_single_spectrum(x_data, y_data, model_configs, initial_params)\n",
    "        \n",
    "        # Prepare data for parallel processing\n",
    "        spectrum_data = [(i, spectral_data.processed_data[:, i]) \n",
    "                        for i in range(spectral_data.processed_data.shape[1])]\n",
    "        \n",
    "        with ProcessPoolExecutor(max_workers=self.n_workers) as executor:\n",
    "            future_to_idx = {executor.submit(fit_wrapper, data): data[0] \n",
    "                           for data in spectrum_data}\n",
    "            \n",
    "            completed = 0\n",
    "            total = len(spectrum_data)\n",
    "            \n",
    "            for future in as_completed(future_to_idx):\n",
    "                idx, result = future.result()\n",
    "                results[idx] = result\n",
    "                completed += 1\n",
    "                \n",
    "                if progress_callback:\n",
    "                    progress_callback(completed, total)\n",
    "        \n",
    "        return results\n",
    "\n",
    "class AnimationEngine:\n",
    "    \"\"\"Animation engine for temporal peak evolution\"\"\"\n",
    "    def __init__(self, spectral_data, fit_results):\n",
    "        self.spectral_data = spectral_data\n",
    "        self.fit_results = fit_results\n",
    "        \n",
    "    def create_parameter_evolution_data(self, parameter_name):\n",
    "        \"\"\"Extract parameter evolution over time\"\"\"\n",
    "        values = []\n",
    "        errors = []\n",
    "        timepoints = []\n",
    "        \n",
    "        for i in sorted(self.fit_results.keys()):\n",
    "            if self.fit_results[i]['success']:\n",
    "                params = self.fit_results[i]['parameters']\n",
    "                if parameter_name in params:\n",
    "                    values.append(params[parameter_name].value)\n",
    "                    errors.append(params[parameter_name].stderr if params[parameter_name].stderr else 0)\n",
    "                    timepoints.append(self.spectral_data.timepoints[i])\n",
    "                else:\n",
    "                    values.append(np.nan)\n",
    "                    errors.append(np.nan)\n",
    "                    timepoints.append(self.spectral_data.timepoints[i])\n",
    "        \n",
    "        return np.array(timepoints), np.array(values), np.array(errors)\n",
    "    \n",
    "    def create_animated_fitting_plot(self, frame_range=None):\n",
    "        \"\"\"Create animated plot of fitting evolution\"\"\"\n",
    "        if frame_range is None:\n",
    "            frame_range = range(len(self.spectral_data.timepoints))\n",
    "        \n",
    "        frames = []\n",
    "        for i in frame_range:\n",
    "            if i in self.fit_results and self.fit_results[i]['success']:\n",
    "                frame_data = {\n",
    "                    'x': self.spectral_data.wavelengths,\n",
    "                    'y_raw': self.spectral_data.processed_data[:, i],\n",
    "                    'y_fit': self.fit_results[i]['best_fit'],\n",
    "                    'components': self.fit_results[i]['components'],\n",
    "                    'timepoint': self.spectral_data.timepoints[i],\n",
    "                    'quality': self.fit_results[i]['quality_metrics']\n",
    "                }\n",
    "                frames.append(frame_data)\n",
    "        \n",
    "        return frames\n",
    "\n",
    "# =============================================================================\n",
    "# USER INTERFACE COMPONENTS\n",
    "# =============================================================================\n",
    "\n",
    "class SpectralAnalysisInterface:\n",
    "    \"\"\"Main interface class for the spectral analysis suite\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spectral_data = SpectralData()\n",
    "        self.fitting_engine = FittingEngine()\n",
    "        self.animation_engine = None\n",
    "        self.current_model_configs = []\n",
    "        self.fit_results = {}\n",
    "        \n",
    "        # UI components\n",
    "        self.setup_ui_components()\n",
    "        self.setup_file_upload()\n",
    "        self.setup_preprocessing_controls()\n",
    "        self.setup_peak_detection()\n",
    "        self.setup_model_management()\n",
    "        self.setup_fitting_controls()\n",
    "        self.setup_visualization()\n",
    "        self.setup_export_controls()\n",
    "        \n",
    "    def setup_ui_components(self):\n",
    "        \"\"\"Initialize basic UI components\"\"\"\n",
    "        self.output = widgets.Output()\n",
    "        self.status_output = widgets.Output()\n",
    "        self.plot_output = widgets.Output()\n",
    "        \n",
    "        # Progress indicators\n",
    "        self.progress_bar = widgets.IntProgress(\n",
    "            value=0, min=0, max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info',\n",
    "            style={'bar_color': '#4facfe'},\n",
    "            orientation='horizontal'\n",
    "        )\n",
    "        \n",
    "        self.progress_label = widgets.Label('')\n",
    "        \n",
    "    def setup_file_upload(self):\n",
    "        \"\"\"Setup file upload interface\"\"\"\n",
    "        self.file_upload = widgets.FileUpload(\n",
    "            accept='.xlsx,.csv,.txt,.xls',\n",
    "            multiple=False,\n",
    "            description='Upload Data'\n",
    "        )\n",
    "        \n",
    "        self.data_format = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Excel Matrix (wavelengths √ó time)', 'excel_matrix'),\n",
    "                ('CSV Matrix (wavelengths √ó time)', 'csv_matrix'),\n",
    "                ('Individual Spectrum Files', 'individual_files')\n",
    "            ],\n",
    "            value='excel_matrix',\n",
    "            description='Data Format:'\n",
    "        )\n",
    "        \n",
    "        self.load_button = widgets.Button(\n",
    "            description='Load Data',\n",
    "            button_style='primary',\n",
    "            icon='upload'\n",
    "        )\n",
    "        \n",
    "        self.file_upload.observe(self.on_file_upload, names='value')\n",
    "        self.load_button.on_click(self.load_data)\n",
    "        \n",
    "    def setup_preprocessing_controls(self):\n",
    "        \"\"\"Setup preprocessing controls\"\"\"\n",
    "        self.preprocessing_method = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('None', 'none'),\n",
    "                ('Savitzky-Golay Smoothing', 'smooth_savgol'),\n",
    "                ('Gaussian Smoothing', 'smooth_gaussian'),\n",
    "                ('Background Subtraction', 'background_subtract')\n",
    "            ],\n",
    "            value='none',\n",
    "            description='Preprocessing:'\n",
    "        )\n",
    "        \n",
    "        # Smoothing parameters\n",
    "        self.smooth_window = widgets.IntSlider(\n",
    "            value=5, min=3, max=21, step=2,\n",
    "            description='Window Length:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        self.smooth_polyorder = widgets.IntSlider(\n",
    "            value=2, min=1, max=5,\n",
    "            description='Polynomial Order:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        self.smooth_sigma = widgets.FloatSlider(\n",
    "            value=1.0, min=0.1, max=5.0, step=0.1,\n",
    "            description='Gaussian Sigma:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        self.apply_preprocessing_button = widgets.Button(\n",
    "            description='Apply Preprocessing',\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        self.preprocessing_method.observe(self.on_preprocessing_method_change, names='value')\n",
    "        self.apply_preprocessing_button.on_click(self.apply_preprocessing)\n",
    "        \n",
    "    def setup_peak_detection(self):\n",
    "        \"\"\"Setup peak detection controls\"\"\"\n",
    "        self.peak_height = widgets.FloatText(\n",
    "            value=0.1,\n",
    "            description='Min Height:',\n",
    "            placeholder='Auto'\n",
    "        )\n",
    "        \n",
    "        self.peak_distance = widgets.IntSlider(\n",
    "            value=5, min=1, max=50,\n",
    "            description='Min Distance:'\n",
    "        )\n",
    "        \n",
    "        self.peak_prominence = widgets.FloatText(\n",
    "            value=0.05,\n",
    "            description='Min Prominence:',\n",
    "            placeholder='Auto'\n",
    "        )\n",
    "        \n",
    "        self.detect_peaks_button = widgets.Button(\n",
    "            description='Detect Peaks',\n",
    "            button_style='success',\n",
    "            icon='search'\n",
    "        )\n",
    "        \n",
    "        self.spectrum_selector = widgets.IntSlider(\n",
    "            value=0, min=0, max=0,\n",
    "            description='Spectrum #:'\n",
    "        )\n",
    "        \n",
    "        self.detect_peaks_button.on_click(self.detect_peaks)\n",
    "        \n",
    "    def setup_model_management(self):\n",
    "        \"\"\"Setup model management interface\"\"\"\n",
    "        self.model_type = widgets.Dropdown(\n",
    "            options=['Gaussian', 'Lorentzian', 'Voigt', 'PseudoVoigt', \n",
    "                    'Linear', 'Polynomial', 'Exponential'],\n",
    "            value='Gaussian',\n",
    "            description='Model Type:'\n",
    "        )\n",
    "        \n",
    "        self.model_prefix = widgets.Text(\n",
    "            value='peak_1_',\n",
    "            description='Prefix:',\n",
    "            placeholder='e.g., peak_1_'\n",
    "        )\n",
    "        \n",
    "        self.add_model_button = widgets.Button(\n",
    "            description='Add Model',\n",
    "            button_style='info',\n",
    "            icon='plus'\n",
    "        )\n",
    "        \n",
    "        self.clear_models_button = widgets.Button(\n",
    "            description='Clear All',\n",
    "            button_style='warning',\n",
    "            icon='trash'\n",
    "        )\n",
    "        \n",
    "        self.models_list = widgets.VBox([])\n",
    "        \n",
    "        self.add_model_button.on_click(self.add_model)\n",
    "        self.clear_models_button.on_click(self.clear_models)\n",
    "        \n",
    "    def setup_fitting_controls(self):\n",
    "        \"\"\"Setup fitting controls\"\"\"\n",
    "        self.fit_single_button = widgets.Button(\n",
    "            description='Fit Current Spectrum',\n",
    "            button_style='primary',\n",
    "            icon='target'\n",
    "        )\n",
    "        \n",
    "        self.fit_all_button = widgets.Button(\n",
    "            description='Fit All Spectra',\n",
    "            button_style='success',\n",
    "            icon='cogs'\n",
    "        )\n",
    "        \n",
    "        self.fit_range_start = widgets.IntText(\n",
    "            value=0,\n",
    "            description='Start Frame:'\n",
    "        )\n",
    "        \n",
    "        self.fit_range_end = widgets.IntText(\n",
    "            value=0,\n",
    "            description='End Frame:'\n",
    "        )\n",
    "        \n",
    "        self.parallel_workers = widgets.IntSlider(\n",
    "            value=mp.cpu_count() - 1,\n",
    "            min=1, max=mp.cpu_count(),\n",
    "            description='CPU Cores:'\n",
    "        )\n",
    "        \n",
    "        self.fit_single_button.on_click(self.fit_single_spectrum)\n",
    "        self.fit_all_button.on_click(self.fit_all_spectra)\n",
    "        \n",
    "    def setup_visualization(self):\n",
    "        \"\"\"Setup visualization controls\"\"\"\n",
    "        self.plot_type = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Heatmap + Spectrum', 'heatmap_spectrum'),\n",
    "                ('Parameter Evolution', 'parameter_evolution'),\n",
    "                ('Quality Metrics', 'quality_metrics'),\n",
    "                ('Peak Animation', 'animation')\n",
    "            ],\n",
    "            value='heatmap_spectrum',\n",
    "            description='Plot Type:'\n",
    "        )\n",
    "        \n",
    "        self.parameter_selector = widgets.Dropdown(\n",
    "            options=[],\n",
    "            description='Parameter:'\n",
    "        )\n",
    "        \n",
    "        self.animation_speed = widgets.FloatSlider(\n",
    "            value=2.0, min=0.1, max=10.0, step=0.1,\n",
    "            description='Animation Speed (fps):'\n",
    "        )\n",
    "        \n",
    "        self.update_plot_button = widgets.Button(\n",
    "            description='Update Plot',\n",
    "            button_style='info',\n",
    "            icon='refresh'\n",
    "        )\n",
    "        \n",
    "        self.plot_type.observe(self.on_plot_type_change, names='value')\n",
    "        self.update_plot_button.on_click(self.update_plots)\n",
    "        \n",
    "    def setup_export_controls(self):\n",
    "        \"\"\"Setup export controls\"\"\"\n",
    "        self.export_format = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Excel (.xlsx)', 'xlsx'),\n",
    "                ('CSV (.csv)', 'csv'),\n",
    "                ('JSON (.json)', 'json'),\n",
    "                ('Pickle (.pkl)', 'pkl')\n",
    "            ],\n",
    "            value='xlsx',\n",
    "            description='Export Format:'\n",
    "        )\n",
    "        \n",
    "        self.export_data_button = widgets.Button(\n",
    "            description='Export Results',\n",
    "            button_style='success',\n",
    "            icon='download'\n",
    "        )\n",
    "        \n",
    "        self.save_session_button = widgets.Button(\n",
    "            description='Save Session',\n",
    "            button_style='primary',\n",
    "            icon='save'\n",
    "        )\n",
    "        \n",
    "        self.load_session_button = widgets.Button(\n",
    "            description='Load Session',\n",
    "            button_style='info',\n",
    "            icon='upload'\n",
    "        )\n",
    "        \n",
    "        self.export_data_button.on_click(self.export_results)\n",
    "        self.save_session_button.on_click(self.save_session)\n",
    "        self.load_session_button.on_click(self.load_session)\n",
    "        \n",
    "    # =============================================================================\n",
    "    # EVENT HANDLERS\n",
    "    # =============================================================================\n",
    "    \n",
    "    def on_file_upload(self, change):\n",
    "        \"\"\"Handle file upload\"\"\"\n",
    "        if change['new']:\n",
    "            with self.output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"üìÅ File uploaded successfully!\")\n",
    "                \n",
    "                # Handle different upload formats\n",
    "                if isinstance(change['new'], dict):\n",
    "                    filename = list(change['new'].keys())[0]\n",
    "                elif isinstance(change['new'], (list, tuple)) and len(change['new']) > 0:\n",
    "                    filename = change['new'][0].name if hasattr(change['new'][0], 'name') else \"uploaded_file\"\n",
    "                else:\n",
    "                    filename = \"uploaded_file\"\n",
    "                    \n",
    "                print(f\"Filename: {filename}\")\n",
    "                \n",
    "    def load_data(self, button):\n",
    "        \"\"\"Load uploaded data\"\"\"\n",
    "        if not self.file_upload.value or (isinstance(self.file_upload.value, (list, tuple)) and len(self.file_upload.value) == 0):\n",
    "            self.show_message(\"Please upload a file first!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Handle different file upload formats\n",
    "            if isinstance(self.file_upload.value, dict):\n",
    "                # Standard format: {filename: {'content': bytes, 'metadata': dict}}\n",
    "                filename = list(self.file_upload.value.keys())[0]\n",
    "                content = self.file_upload.value[filename]['content']\n",
    "            elif isinstance(self.file_upload.value, tuple) and len(self.file_upload.value) > 0:\n",
    "                # Alternative format: (FileInfo, FileInfo, ...)\n",
    "                file_info = self.file_upload.value[0]\n",
    "                filename = file_info.name\n",
    "                content = file_info.content\n",
    "            elif hasattr(self.file_upload.value, 'name') and hasattr(self.file_upload.value, 'content'):\n",
    "                # Direct file object\n",
    "                filename = self.file_upload.value.name\n",
    "                content = self.file_upload.value.content\n",
    "            else:\n",
    "                self.show_message(\"Unsupported file upload format!\", \"error\")\n",
    "                return\n",
    "            \n",
    "            # Determine file type and load accordingly\n",
    "            if filename.endswith('.xlsx'):\n",
    "                df = pd.read_excel(io.BytesIO(content), index_col=0)\n",
    "            elif filename.endswith('.csv'):\n",
    "                df = pd.read_csv(io.StringIO(content.decode('utf-8')), index_col=0)\n",
    "            else:\n",
    "                self.show_message(\"Unsupported file format!\", \"error\")\n",
    "                return\n",
    "                \n",
    "            # Load into spectral data object\n",
    "            wavelengths = df.index.values\n",
    "            timepoints = df.columns.values.astype(float)\n",
    "            data_matrix = df.values\n",
    "            \n",
    "            self.spectral_data.load_matrix(data_matrix, wavelengths, timepoints)\n",
    "            \n",
    "            # Update UI components\n",
    "            self.spectrum_selector.max = len(timepoints) - 1\n",
    "            self.fit_range_end.value = len(timepoints) - 1\n",
    "            \n",
    "            self.show_message(f\"‚úÖ Data loaded successfully! Shape: {data_matrix.shape}\", \"success\")\n",
    "            self.update_plots()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error loading data: {str(e)}\", \"error\")\n",
    "            \n",
    "    def on_preprocessing_method_change(self, change):\n",
    "        \"\"\"Handle preprocessing method change\"\"\"\n",
    "        method = change['new']\n",
    "        \n",
    "        # Enable/disable relevant controls\n",
    "        if method == 'smooth_savgol':\n",
    "            self.smooth_window.disabled = False\n",
    "            self.smooth_polyorder.disabled = False\n",
    "            self.smooth_sigma.disabled = True\n",
    "        elif method == 'smooth_gaussian':\n",
    "            self.smooth_window.disabled = True\n",
    "            self.smooth_polyorder.disabled = True\n",
    "            self.smooth_sigma.disabled = False\n",
    "        else:\n",
    "            self.smooth_window.disabled = True\n",
    "            self.smooth_polyorder.disabled = True\n",
    "            self.smooth_sigma.disabled = True\n",
    "            \n",
    "    def apply_preprocessing(self, button):\n",
    "        \"\"\"Apply preprocessing to data\"\"\"\n",
    "        if self.spectral_data.raw_data is None:\n",
    "            self.show_message(\"Please load data first!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            method = self.preprocessing_method.value\n",
    "            \n",
    "            if method == 'smooth_savgol':\n",
    "                self.spectral_data.apply_preprocessing(\n",
    "                    method, \n",
    "                    window_length=self.smooth_window.value,\n",
    "                    polyorder=self.smooth_polyorder.value\n",
    "                )\n",
    "            elif method == 'smooth_gaussian':\n",
    "                self.spectral_data.apply_preprocessing(\n",
    "                    method,\n",
    "                    sigma=self.smooth_sigma.value\n",
    "                )\n",
    "            else:\n",
    "                # Reset to raw data\n",
    "                self.spectral_data.processed_data = self.spectral_data.raw_data.copy()\n",
    "                \n",
    "            self.show_message(f\"‚úÖ Preprocessing applied: {method}\", \"success\")\n",
    "            self.update_plots()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error in preprocessing: {str(e)}\", \"error\")\n",
    "            \n",
    "    def detect_peaks(self, button):\n",
    "        \"\"\"Detect peaks in current spectrum\"\"\"\n",
    "        if self.spectral_data.processed_data is None:\n",
    "            self.show_message(\"Please load data first!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            spectrum_idx = self.spectrum_selector.value\n",
    "            \n",
    "            kwargs = {}\n",
    "            if self.peak_height.value:\n",
    "                kwargs['height'] = self.peak_height.value\n",
    "            if self.peak_prominence.value:\n",
    "                kwargs['prominence'] = self.peak_prominence.value\n",
    "            kwargs['distance'] = self.peak_distance.value\n",
    "            \n",
    "            peaks, properties = self.spectral_data.detect_peaks(spectrum_idx, **kwargs)\n",
    "            \n",
    "            self.show_message(f\"‚úÖ Found {len(peaks)} peaks at wavelengths: {self.spectral_data.wavelengths[peaks]}\", \"success\")\n",
    "            \n",
    "            # Auto-generate models for detected peaks\n",
    "            self.auto_generate_models(peaks, spectrum_idx)\n",
    "            self.update_plots()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error in peak detection: {str(e)}\", \"error\")\n",
    "            \n",
    "    def auto_generate_models(self, peaks, spectrum_idx):\n",
    "        \"\"\"Auto-generate fitting models for detected peaks\"\"\"\n",
    "        self.current_model_configs = []\n",
    "        \n",
    "        for i, peak_idx in enumerate(peaks):\n",
    "            wavelength = self.spectral_data.wavelengths[peak_idx]\n",
    "            intensity = self.spectral_data.processed_data[peak_idx, spectrum_idx]\n",
    "            \n",
    "            # Estimate width (simple approach)\n",
    "            width_estimate = 5.0  # Default width\n",
    "            \n",
    "            config = {\n",
    "                'type': 'Gaussian',\n",
    "                'prefix': f'peak_{i+1}_',\n",
    "                'initial_params': {\n",
    "                    f'peak_{i+1}_center': wavelength,\n",
    "                    f'peak_{i+1}_amplitude': intensity,\n",
    "                    f'peak_{i+1}_sigma': width_estimate\n",
    "                },\n",
    "                'bounds': {\n",
    "                    f'peak_{i+1}_center': (wavelength - 20, wavelength + 20),\n",
    "                    f'peak_{i+1}_amplitude': (0, intensity * 2),\n",
    "                    f'peak_{i+1}_sigma': (0.5, 50)\n",
    "                }\n",
    "            }\n",
    "            self.current_model_configs.append(config)\n",
    "            \n",
    "        self.update_models_display()\n",
    "        \n",
    "    def add_model(self, button):\n",
    "        \"\"\"Add a model manually\"\"\"\n",
    "        config = {\n",
    "            'type': self.model_type.value,\n",
    "            'prefix': self.model_prefix.value,\n",
    "            'initial_params': {},\n",
    "            'bounds': {},\n",
    "            'fixed': {}\n",
    "        }\n",
    "        \n",
    "        self.current_model_configs.append(config)\n",
    "        self.update_models_display()\n",
    "        self.show_message(f\"‚úÖ Added {self.model_type.value} model\", \"success\")\n",
    "        \n",
    "    def clear_models(self, button):\n",
    "        \"\"\"Clear all models\"\"\"\n",
    "        self.current_model_configs = []\n",
    "        self.update_models_display()\n",
    "        self.show_message(\"üóëÔ∏è All models cleared\", \"warning\")\n",
    "        \n",
    "    def update_models_display(self):\n",
    "        \"\"\"Update the models display\"\"\"\n",
    "        model_widgets = []\n",
    "        \n",
    "        for i, config in enumerate(self.current_model_configs):\n",
    "            model_info = widgets.HTML(\n",
    "                value=f\"<div class='parameter-box'>\"\n",
    "                      f\"<strong>Model {i+1}:</strong> {config['type']} \"\n",
    "                      f\"(prefix: {config['prefix']})</div>\"\n",
    "            )\n",
    "            \n",
    "            remove_button = widgets.Button(\n",
    "                description=f'Remove Model {i+1}',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(width='150px')\n",
    "            )\n",
    "            \n",
    "            def make_remove_handler(idx):\n",
    "                def remove_model(btn):\n",
    "                    del self.current_model_configs[idx]\n",
    "                    self.update_models_display()\n",
    "                    self.show_message(f\"üóëÔ∏è Model {idx+1} removed\", \"warning\")\n",
    "                return remove_model\n",
    "            \n",
    "            remove_button.on_click(make_remove_handler(i))\n",
    "            \n",
    "            model_box = widgets.HBox([model_info, remove_button])\n",
    "            model_widgets.append(model_box)\n",
    "            \n",
    "        self.models_list.children = model_widgets\n",
    "        \n",
    "    def fit_single_spectrum(self, button):\n",
    "        \"\"\"Fit current spectrum\"\"\"\n",
    "        if not self.current_model_configs:\n",
    "            self.show_message(\"Please add at least one model!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        if self.spectral_data.processed_data is None:\n",
    "            self.show_message(\"Please load data first!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            spectrum_idx = self.spectrum_selector.value\n",
    "            x_data = self.spectral_data.wavelengths\n",
    "            y_data = self.spectral_data.processed_data[:, spectrum_idx]\n",
    "            \n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"üîÑ Fitting spectrum...\")\n",
    "            \n",
    "            result = self.fitting_engine.fit_single_spectrum(\n",
    "                x_data, y_data, self.current_model_configs\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                self.fit_results[spectrum_idx] = result\n",
    "                self.show_message(f\"‚úÖ Fit successful! R¬≤ = {result['quality_metrics']['r_squared']:.4f}\", \"success\")\n",
    "                \n",
    "                # Update parameter selector for visualization\n",
    "                param_names = list(result['parameters'].keys())\n",
    "                self.parameter_selector.options = param_names\n",
    "                \n",
    "                self.update_plots()\n",
    "            else:\n",
    "                self.show_message(f\"‚ùå Fit failed: {result['error']}\", \"error\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error in fitting: {str(e)}\", \"error\")\n",
    "            \n",
    "    def fit_all_spectra(self, button):\n",
    "        \"\"\"Fit all spectra in parallel\"\"\"\n",
    "        if not self.current_model_configs:\n",
    "            self.show_message(\"Please add at least one model!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        if self.spectral_data.processed_data is None:\n",
    "            self.show_message(\"Please load data first!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            start_frame = self.fit_range_start.value\n",
    "            end_frame = min(self.fit_range_end.value, self.spectral_data.processed_data.shape[1] - 1)\n",
    "            \n",
    "            # Update fitting engine workers\n",
    "            self.fitting_engine.n_workers = self.parallel_workers.value\n",
    "            \n",
    "            with self.status_output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"üîÑ Starting parallel fitting...\")\n",
    "                \n",
    "            def progress_callback(completed, total):\n",
    "                progress = int((completed / total) * 100)\n",
    "                self.progress_bar.value = progress\n",
    "                self.progress_label.value = f\"{completed}/{total} spectra completed\"\n",
    "                \n",
    "            # Create subset of spectral data for fitting range\n",
    "            subset_data = SpectralData()\n",
    "            subset_data.wavelengths = self.spectral_data.wavelengths\n",
    "            subset_data.timepoints = self.spectral_data.timepoints[start_frame:end_frame+1]\n",
    "            subset_data.processed_data = self.spectral_data.processed_data[:, start_frame:end_frame+1]\n",
    "            \n",
    "            results = self.fitting_engine.fit_parallel(\n",
    "                subset_data, self.current_model_configs, progress_callback\n",
    "            )\n",
    "            \n",
    "            # Store results with correct indices\n",
    "            for local_idx, result in results.items():\n",
    "                global_idx = start_frame + local_idx\n",
    "                self.fit_results[global_idx] = result\n",
    "                \n",
    "            successful_fits = sum(1 for r in results.values() if r['success'])\n",
    "            self.show_message(f\"‚úÖ Parallel fitting complete! {successful_fits}/{len(results)} fits successful\", \"success\")\n",
    "            \n",
    "            # Update parameter selector\n",
    "            if successful_fits > 0:\n",
    "                first_successful = next(r for r in results.values() if r['success'])\n",
    "                param_names = list(first_successful['parameters'].keys())\n",
    "                self.parameter_selector.options = param_names\n",
    "                \n",
    "            self.progress_bar.value = 100\n",
    "            self.update_plots()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error in parallel fitting: {str(e)}\", \"error\")\n",
    "            \n",
    "    def on_plot_type_change(self, change):\n",
    "        \"\"\"Handle plot type change\"\"\"\n",
    "        plot_type = change['new']\n",
    "        \n",
    "        # Show/hide relevant controls\n",
    "        if plot_type == 'parameter_evolution':\n",
    "            self.parameter_selector.layout.visibility = 'visible'\n",
    "        else:\n",
    "            self.parameter_selector.layout.visibility = 'hidden'\n",
    "            \n",
    "    def update_plots(self, button=None):\n",
    "        \"\"\"Update all plots\"\"\"\n",
    "        if self.spectral_data.raw_data is None:\n",
    "            return\n",
    "            \n",
    "        plot_type = self.plot_type.value\n",
    "        \n",
    "        with self.plot_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if plot_type == 'heatmap_spectrum':\n",
    "                self.create_heatmap_spectrum_plot()\n",
    "            elif plot_type == 'parameter_evolution':\n",
    "                self.create_parameter_evolution_plot()\n",
    "            elif plot_type == 'quality_metrics':\n",
    "                self.create_quality_metrics_plot()\n",
    "            elif plot_type == 'animation':\n",
    "                self.create_animation_controls()\n",
    "                \n",
    "    def create_heatmap_spectrum_plot(self):\n",
    "        \"\"\"Create heatmap and spectrum visualization\"\"\"\n",
    "        # Create subplot figure\n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=2,\n",
    "            subplot_titles=['Current Spectrum', 'Fit Components', 'Spectral Heatmap', '', 'Residuals', ''],\n",
    "            specs=[[{\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "                   [{\"type\": \"xy\", \"colspan\": 2}, None],\n",
    "                   [{\"type\": \"xy\"}, None]],\n",
    "            row_heights=[0.4, 0.4, 0.2],\n",
    "            vertical_spacing=0.08\n",
    "        )\n",
    "        \n",
    "        # Heatmap\n",
    "        heatmap = go.Heatmap(\n",
    "            z=self.spectral_data.processed_data,\n",
    "            x=self.spectral_data.timepoints,\n",
    "            y=self.spectral_data.wavelengths,\n",
    "            colorscale='Viridis',\n",
    "            name='Intensity'\n",
    "        )\n",
    "        fig.add_trace(heatmap, row=2, col=1)\n",
    "        \n",
    "        # Current spectrum\n",
    "        current_idx = self.spectrum_selector.value\n",
    "        spectrum_trace = go.Scatter(\n",
    "            x=self.spectral_data.wavelengths,\n",
    "            y=self.spectral_data.processed_data[:, current_idx],\n",
    "            mode='lines',\n",
    "            name='Spectrum',\n",
    "            line=dict(color='blue')\n",
    "        )\n",
    "        fig.add_trace(spectrum_trace, row=1, col=1)\n",
    "        \n",
    "        # Add fit if available\n",
    "        if current_idx in self.fit_results and self.fit_results[current_idx]['success']:\n",
    "            fit_result = self.fit_results[current_idx]\n",
    "            \n",
    "            # Best fit\n",
    "            fit_trace = go.Scatter(\n",
    "                x=self.spectral_data.wavelengths,\n",
    "                y=fit_result['best_fit'],\n",
    "                mode='lines',\n",
    "                name='Fit',\n",
    "                line=dict(color='red', dash='dash')\n",
    "            )\n",
    "            fig.add_trace(fit_trace, row=1, col=1)\n",
    "            \n",
    "            # Components\n",
    "            if fit_result['components']:\n",
    "                for comp_name, comp_data in fit_result['components'].items():\n",
    "                    comp_trace = go.Scatter(\n",
    "                        x=self.spectral_data.wavelengths,\n",
    "                        y=comp_data,\n",
    "                        mode='lines',\n",
    "                        name=comp_name.replace('_', ' ').title(),\n",
    "                        line=dict(dash='dot'),\n",
    "                        opacity=0.7\n",
    "                    )\n",
    "                    fig.add_trace(comp_trace, row=1, col=2)\n",
    "            \n",
    "            # Residuals\n",
    "            residuals = self.spectral_data.processed_data[:, current_idx] - fit_result['best_fit']\n",
    "            residual_trace = go.Scatter(\n",
    "                x=self.spectral_data.wavelengths,\n",
    "                y=residuals,\n",
    "                mode='lines',\n",
    "                name='Residuals',\n",
    "                line=dict(color='gray')\n",
    "            )\n",
    "            fig.add_trace(residual_trace, row=3, col=1)\n",
    "            \n",
    "            # Add quality metrics as annotation\n",
    "            metrics = fit_result['quality_metrics']\n",
    "            metrics_text = f\"R¬≤ = {metrics['r_squared']:.4f}<br>\"\n",
    "            metrics_text += f\"RMSE = {metrics['rmse']:.4f}<br>\"\n",
    "            metrics_text += f\"AIC = {metrics['aic']:.2f}\"\n",
    "            \n",
    "            fig.add_annotation(\n",
    "                text=metrics_text,\n",
    "                xref=\"x2\", yref=\"y2\",\n",
    "                x=0.95, y=0.95,\n",
    "                xanchor=\"right\", yanchor=\"top\",\n",
    "                showarrow=False,\n",
    "                bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                bordercolor=\"black\",\n",
    "                borderwidth=1,\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            title=f\"Spectral Analysis - Frame {current_idx}\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Wavelength (nm)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Intensity\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Wavelength (nm)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Intensity\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Wavelength (nm)\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Wavelength (nm)\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"Residuals\", row=3, col=1)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def create_parameter_evolution_plot(self):\n",
    "        \"\"\"Create parameter evolution visualization\"\"\"\n",
    "        if not self.fit_results or not self.parameter_selector.value:\n",
    "            print(\"No fitting results or parameter selected\")\n",
    "            return\n",
    "            \n",
    "        param_name = self.parameter_selector.value\n",
    "        \n",
    "        # Extract parameter evolution\n",
    "        timepoints = []\n",
    "        values = []\n",
    "        errors = []\n",
    "        \n",
    "        for idx in sorted(self.fit_results.keys()):\n",
    "            if self.fit_results[idx]['success']:\n",
    "                params = self.fit_results[idx]['parameters']\n",
    "                if param_name in params:\n",
    "                    timepoints.append(self.spectral_data.timepoints[idx])\n",
    "                    values.append(params[param_name].value)\n",
    "                    error = params[param_name].stderr if params[param_name].stderr else 0\n",
    "                    errors.append(error)\n",
    "        \n",
    "        if not values:\n",
    "            print(\"No data available for selected parameter\")\n",
    "            return\n",
    "            \n",
    "        # Create plot\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Main trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=timepoints,\n",
    "            y=values,\n",
    "            mode='lines+markers',\n",
    "            name=param_name.replace('_', ' ').title(),\n",
    "            line=dict(color='blue', width=2),\n",
    "            marker=dict(size=6)\n",
    "        ))\n",
    "        \n",
    "        # Error bars if available\n",
    "        if any(e > 0 for e in errors):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=timepoints + timepoints[::-1],\n",
    "                y=[v + e for v, e in zip(values, errors)] + [v - e for v, e in zip(values[::-1], errors[::-1])],\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                name='Error Band',\n",
    "                showlegend=True\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"Parameter Evolution: {param_name.replace('_', ' ').title()}\",\n",
    "            xaxis_title=\"Time\",\n",
    "            yaxis_title=\"Parameter Value\",\n",
    "            height=400\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def create_quality_metrics_plot(self):\n",
    "        \"\"\"Create quality metrics visualization\"\"\"\n",
    "        if not self.fit_results:\n",
    "            print(\"No fitting results available\")\n",
    "            return\n",
    "            \n",
    "        # Extract quality metrics\n",
    "        timepoints = []\n",
    "        r_squared = []\n",
    "        rmse = []\n",
    "        aic = []\n",
    "        \n",
    "        for idx in sorted(self.fit_results.keys()):\n",
    "            if self.fit_results[idx]['success']:\n",
    "                metrics = self.fit_results[idx]['quality_metrics']\n",
    "                timepoints.append(self.spectral_data.timepoints[idx])\n",
    "                r_squared.append(metrics['r_squared'])\n",
    "                rmse.append(metrics['rmse'])\n",
    "                aic.append(metrics['aic'])\n",
    "        \n",
    "        if not timepoints:\n",
    "            print(\"No successful fits available\")\n",
    "            return\n",
    "            \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['R-squared', 'RMSE', 'AIC', 'Fit Success Rate'],\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "        )\n",
    "        \n",
    "        # R-squared\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=timepoints, y=r_squared, mode='lines+markers', name='R¬≤'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # RMSE\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=timepoints, y=rmse, mode='lines+markers', name='RMSE', line=dict(color='red')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # AIC\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=timepoints, y=aic, mode='lines+markers', name='AIC', line=dict(color='green')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Success rate (rolling window)\n",
    "        window_size = min(10, len(timepoints))\n",
    "        success_rate = []\n",
    "        success_timepoints = []\n",
    "        \n",
    "        total_attempted = len(self.spectral_data.timepoints)\n",
    "        for i in range(len(timepoints)):\n",
    "            start_idx = max(0, i - window_size // 2)\n",
    "            end_idx = min(len(timepoints), i + window_size // 2)\n",
    "            window_success = end_idx - start_idx\n",
    "            window_total = min(window_size, total_attempted)\n",
    "            success_rate.append(window_success / window_total * 100)\n",
    "            success_timepoints.append(timepoints[i])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=success_timepoints, y=success_rate, mode='lines+markers', \n",
    "                      name='Success Rate (%)', line=dict(color='purple')),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600, title=\"Fitting Quality Metrics\")\n",
    "        fig.update_xaxes(title_text=\"Time\")\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def create_animation_controls(self):\n",
    "        \"\"\"Create animation controls and preview\"\"\"\n",
    "        if not self.fit_results:\n",
    "            print(\"No fitting results available for animation\")\n",
    "            return\n",
    "            \n",
    "        # Animation controls\n",
    "        play_button = widgets.Button(description=\"‚ñ∂ Play\", button_style='success')\n",
    "        pause_button = widgets.Button(description=\"‚è∏ Pause\", button_style='warning')\n",
    "        stop_button = widgets.Button(description=\"‚èπ Stop\", button_style='danger')\n",
    "        \n",
    "        frame_slider = widgets.IntSlider(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=len(self.spectral_data.timepoints) - 1,\n",
    "            description='Frame:',\n",
    "            continuous_update=False\n",
    "        )\n",
    "        \n",
    "        speed_slider = widgets.FloatSlider(\n",
    "            value=2.0,\n",
    "            min=0.1,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            description='Speed (fps):',\n",
    "            continuous_update=False\n",
    "        )\n",
    "        \n",
    "        export_gif_button = widgets.Button(\n",
    "            description=\"Export GIF\",\n",
    "            button_style='info',\n",
    "            icon='download'\n",
    "        )\n",
    "        \n",
    "        # Animation output\n",
    "        animation_output = widgets.Output()\n",
    "        \n",
    "        # Animation state\n",
    "        self.animation_playing = False\n",
    "        self.animation_thread = None\n",
    "        \n",
    "        def play_animation(button):\n",
    "            self.animation_playing = True\n",
    "            self.start_animation_thread(frame_slider, speed_slider, animation_output)\n",
    "            \n",
    "        def pause_animation(button):\n",
    "            self.animation_playing = False\n",
    "            \n",
    "        def stop_animation(button):\n",
    "            self.animation_playing = False\n",
    "            frame_slider.value = 0\n",
    "            \n",
    "        def update_frame(change):\n",
    "            if not self.animation_playing:\n",
    "                self.update_animation_frame(change['new'], animation_output)\n",
    "                \n",
    "        def export_gif(button):\n",
    "            self.export_animation_gif(speed_slider.value)\n",
    "            \n",
    "        play_button.on_click(play_animation)\n",
    "        pause_button.on_click(pause_animation)\n",
    "        stop_button.on_click(stop_animation)\n",
    "        frame_slider.observe(update_frame, names='value')\n",
    "        export_gif_button.on_click(export_gif)\n",
    "        \n",
    "        # Layout\n",
    "        controls = widgets.HBox([\n",
    "            play_button, pause_button, stop_button,\n",
    "            frame_slider, speed_slider, export_gif_button\n",
    "        ])\n",
    "        \n",
    "        animation_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>üé¨ Peak Evolution Animation</h3>\"),\n",
    "            controls,\n",
    "            animation_output\n",
    "        ])\n",
    "        \n",
    "        display(animation_box)\n",
    "        \n",
    "        # Initial frame\n",
    "        self.update_animation_frame(0, animation_output)\n",
    "        \n",
    "    def start_animation_thread(self, frame_slider, speed_slider, output):\n",
    "        \"\"\"Start animation in separate thread\"\"\"\n",
    "        def animate():\n",
    "            frame = frame_slider.value\n",
    "            while self.animation_playing and frame < frame_slider.max:\n",
    "                time.sleep(1.0 / speed_slider.value)\n",
    "                if self.animation_playing:\n",
    "                    frame = (frame + 1) % (frame_slider.max + 1)\n",
    "                    frame_slider.value = frame\n",
    "                    self.update_animation_frame(frame, output)\n",
    "                    \n",
    "        if self.animation_thread and self.animation_thread.is_alive():\n",
    "            self.animation_playing = False\n",
    "            self.animation_thread.join()\n",
    "            \n",
    "        self.animation_thread = threading.Thread(target=animate)\n",
    "        self.animation_thread.start()\n",
    "        \n",
    "    def update_animation_frame(self, frame_idx, output):\n",
    "        \"\"\"Update animation frame\"\"\"\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Create animation frame plot\n",
    "            fig = make_subplots(\n",
    "                rows=1, cols=2,\n",
    "                subplot_titles=[f'Spectrum at Frame {frame_idx}', 'Parameter Evolution'],\n",
    "                column_widths=[0.6, 0.4]\n",
    "            )\n",
    "            \n",
    "            # Current spectrum\n",
    "            spectrum_trace = go.Scatter(\n",
    "                x=self.spectral_data.wavelengths,\n",
    "                y=self.spectral_data.processed_data[:, frame_idx],\n",
    "                mode='lines',\n",
    "                name='Spectrum',\n",
    "                line=dict(color='blue', width=2)\n",
    "            )\n",
    "            fig.add_trace(spectrum_trace, row=1, col=1)\n",
    "            \n",
    "            # Add fit if available\n",
    "            if frame_idx in self.fit_results and self.fit_results[frame_idx]['success']:\n",
    "                fit_result = self.fit_results[frame_idx]\n",
    "                \n",
    "                # Best fit\n",
    "                fit_trace = go.Scatter(\n",
    "                    x=self.spectral_data.wavelengths,\n",
    "                    y=fit_result['best_fit'],\n",
    "                    mode='lines',\n",
    "                    name='Fit',\n",
    "                    line=dict(color='red', dash='dash', width=2)\n",
    "                )\n",
    "                fig.add_trace(fit_trace, row=1, col=1)\n",
    "                \n",
    "                # Components\n",
    "                colors = ['orange', 'green', 'purple', 'brown', 'pink']\n",
    "                for i, (comp_name, comp_data) in enumerate(fit_result['components'].items()):\n",
    "                    comp_trace = go.Scatter(\n",
    "                        x=self.spectral_data.wavelengths,\n",
    "                        y=comp_data,\n",
    "                        mode='lines',\n",
    "                        name=comp_name.replace('_', ' ').title(),\n",
    "                        line=dict(color=colors[i % len(colors)], dash='dot'),\n",
    "                        opacity=0.7\n",
    "                    )\n",
    "                    fig.add_trace(comp_trace, row=1, col=1)\n",
    "            \n",
    "            # Parameter evolution (if parameter selected)\n",
    "            if self.parameter_selector.value and self.fit_results:\n",
    "                param_name = self.parameter_selector.value\n",
    "                \n",
    "                # Get parameter history up to current frame\n",
    "                hist_timepoints = []\n",
    "                hist_values = []\n",
    "                \n",
    "                for idx in sorted(self.fit_results.keys()):\n",
    "                    if idx <= frame_idx and self.fit_results[idx]['success']:\n",
    "                        params = self.fit_results[idx]['parameters']\n",
    "                        if param_name in params:\n",
    "                            hist_timepoints.append(self.spectral_data.timepoints[idx])\n",
    "                            hist_values.append(params[param_name].value)\n",
    "                \n",
    "                if hist_timepoints:\n",
    "                    # Historical trace\n",
    "                    hist_trace = go.Scatter(\n",
    "                        x=hist_timepoints,\n",
    "                        y=hist_values,\n",
    "                        mode='lines+markers',\n",
    "                        name=param_name.replace('_', ' ').title(),\n",
    "                        line=dict(color='blue', width=2),\n",
    "                        marker=dict(size=4)\n",
    "                    )\n",
    "                    fig.add_trace(hist_trace, row=1, col=2)\n",
    "                    \n",
    "                    # Current point\n",
    "                    if hist_timepoints:\n",
    "                        current_trace = go.Scatter(\n",
    "                            x=[hist_timepoints[-1]],\n",
    "                            y=[hist_values[-1]],\n",
    "                            mode='markers',\n",
    "                            name='Current',\n",
    "                            marker=dict(color='red', size=10, symbol='diamond')\n",
    "                        )\n",
    "                        fig.add_trace(current_trace, row=1, col=2)\n",
    "            \n",
    "            fig.update_layout(\n",
    "                height=400,\n",
    "                title=f\"Frame {frame_idx} - Time: {self.spectral_data.timepoints[frame_idx]:.2f}\",\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            fig.update_xaxes(title_text=\"Wavelength (nm)\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Intensity\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Time\", row=1, col=2)\n",
    "            fig.update_yaxes(title_text=\"Parameter Value\", row=1, col=2)\n",
    "            \n",
    "            fig.show()\n",
    "            \n",
    "    def export_animation_gif(self, fps):\n",
    "        \"\"\"Export animation as GIF\"\"\"\n",
    "        try:\n",
    "            if not self.fit_results:\n",
    "                self.show_message(\"No fitting results available for animation\", \"error\")\n",
    "                return\n",
    "                \n",
    "            self.show_message(\"üé¨ Creating animation... This may take a while.\", \"info\")\n",
    "            \n",
    "            # Create matplotlib animation\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            \n",
    "            frames_with_fits = [idx for idx in sorted(self.fit_results.keys()) \n",
    "                              if self.fit_results[idx]['success']]\n",
    "            \n",
    "            if not frames_with_fits:\n",
    "                self.show_message(\"No successful fits available for animation\", \"error\")\n",
    "                return\n",
    "            \n",
    "            def animate_frame(frame_num):\n",
    "                frame_idx = frames_with_fits[frame_num]\n",
    "                \n",
    "                ax1.clear()\n",
    "                ax2.clear()\n",
    "                \n",
    "                # Spectrum plot\n",
    "                ax1.plot(self.spectral_data.wavelengths, \n",
    "                        self.spectral_data.processed_data[:, frame_idx], \n",
    "                        'b-', label='Spectrum', linewidth=2)\n",
    "                \n",
    "                fit_result = self.fit_results[frame_idx]\n",
    "                ax1.plot(self.spectral_data.wavelengths, \n",
    "                        fit_result['best_fit'], \n",
    "                        'r--', label='Fit', linewidth=2)\n",
    "                \n",
    "                # Components\n",
    "                colors = ['orange', 'green', 'purple', 'brown', 'pink']\n",
    "                for i, (comp_name, comp_data) in enumerate(fit_result['components'].items()):\n",
    "                    ax1.plot(self.spectral_data.wavelengths, comp_data, \n",
    "                            '--', color=colors[i % len(colors)], \n",
    "                            label=comp_name.replace('_', ' ').title(), alpha=0.7)\n",
    "                \n",
    "                ax1.set_xlabel('Wavelength (nm)')\n",
    "                ax1.set_ylabel('Intensity')\n",
    "                ax1.set_title(f'Frame {frame_idx} - Time: {self.spectral_data.timepoints[frame_idx]:.2f}')\n",
    "                ax1.legend()\n",
    "                ax1.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Parameter evolution\n",
    "                if self.parameter_selector.value:\n",
    "                    param_name = self.parameter_selector.value\n",
    "                    \n",
    "                    hist_timepoints = []\n",
    "                    hist_values = []\n",
    "                    \n",
    "                    for idx in frames_with_fits[:frame_num+1]:\n",
    "                        if self.fit_results[idx]['success']:\n",
    "                            params = self.fit_results[idx]['parameters']\n",
    "                            if param_name in params:\n",
    "                                hist_timepoints.append(self.spectral_data.timepoints[idx])\n",
    "                                hist_values.append(params[param_name].value)\n",
    "                    \n",
    "                    if hist_timepoints:\n",
    "                        ax2.plot(hist_timepoints, hist_values, 'b-o', linewidth=2, markersize=4)\n",
    "                        ax2.plot(hist_timepoints[-1], hist_values[-1], 'ro', markersize=8)\n",
    "                        \n",
    "                    ax2.set_xlabel('Time')\n",
    "                    ax2.set_ylabel('Parameter Value')\n",
    "                    ax2.set_title(param_name.replace('_', ' ').title())\n",
    "                    ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Create animation\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, animate_frame, frames=len(frames_with_fits),\n",
    "                interval=int(1000/fps), repeat=True, blit=False\n",
    "            )\n",
    "            \n",
    "            # Save as GIF\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"spectral_animation_{timestamp}.gif\"\n",
    "            \n",
    "            writer = animation.PillowWriter(fps=fps)\n",
    "            anim.save(filename, writer=writer, dpi=100)\n",
    "            \n",
    "            plt.close(fig)\n",
    "            \n",
    "            self.show_message(f\"‚úÖ Animation saved as {filename}\", \"success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error creating animation: {str(e)}\", \"error\")\n",
    "            \n",
    "    def export_results(self, button):\n",
    "        \"\"\"Export fitting results\"\"\"\n",
    "        if not self.fit_results:\n",
    "            self.show_message(\"No results to export!\", \"error\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            export_format = self.export_format.value\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            \n",
    "            # Prepare data for export\n",
    "            export_data = {}\n",
    "            \n",
    "            # Parameters table\n",
    "            param_names = set()\n",
    "            for result in self.fit_results.values():\n",
    "                if result['success']:\n",
    "                    param_names.update(result['parameters'].keys())\n",
    "            \n",
    "            param_names = sorted(list(param_names))\n",
    "            \n",
    "            params_df = pd.DataFrame(index=sorted(self.fit_results.keys()), columns=param_names)\n",
    "            quality_df = pd.DataFrame(index=sorted(self.fit_results.keys()), \n",
    "                                    columns=['r_squared', 'aic', 'bic', 'rmse', 'reduced_chi_squared'])\n",
    "            \n",
    "            for idx, result in self.fit_results.items():\n",
    "                if result['success']:\n",
    "                    for param_name in param_names:\n",
    "                        if param_name in result['parameters']:\n",
    "                            params_df.loc[idx, param_name] = result['parameters'][param_name].value\n",
    "                    \n",
    "                    for metric_name in quality_df.columns:\n",
    "                        if metric_name in result['quality_metrics']:\n",
    "                            quality_df.loc[idx, metric_name] = result['quality_metrics'][metric_name]\n",
    "            \n",
    "            # Add timepoints\n",
    "            params_df['timepoint'] = [self.spectral_data.timepoints[idx] for idx in params_df.index]\n",
    "            quality_df['timepoint'] = [self.spectral_data.timepoints[idx] for idx in quality_df.index]\n",
    "            \n",
    "            if export_format == 'xlsx':\n",
    "                filename = f\"spectral_analysis_results_{timestamp}.xlsx\"\n",
    "                with pd.ExcelWriter(filename) as writer:\n",
    "                    params_df.to_excel(writer, sheet_name='Parameters')\n",
    "                    quality_df.to_excel(writer, sheet_name='Quality_Metrics')\n",
    "                    \n",
    "                    # Add metadata sheet\n",
    "                    metadata_df = pd.DataFrame([\n",
    "                        ['Analysis Date', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "                        ['Total Spectra', len(self.spectral_data.timepoints)],\n",
    "                        ['Successful Fits', len([r for r in self.fit_results.values() if r['success']])],\n",
    "                        ['Models Used', ', '.join([config['type'] for config in self.current_model_configs])],\n",
    "                        ['Wavelength Range', f\"{self.spectral_data.wavelengths[0]:.2f} - {self.spectral_data.wavelengths[-1]:.2f} nm\"],\n",
    "                        ['Time Range', f\"{self.spectral_data.timepoints[0]:.2f} - {self.spectral_data.timepoints[-1]:.2f}\"]\n",
    "                    ], columns=['Parameter', 'Value'])\n",
    "                    metadata_df.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "                    \n",
    "            elif export_format == 'csv':\n",
    "                params_filename = f\"spectral_parameters_{timestamp}.csv\"\n",
    "                quality_filename = f\"spectral_quality_{timestamp}.csv\"\n",
    "                params_df.to_csv(params_filename)\n",
    "                quality_df.to_csv(quality_filename)\n",
    "                filename = f\"{params_filename}, {quality_filename}\"\n",
    "                \n",
    "            elif export_format == 'json':\n",
    "                filename = f\"spectral_analysis_results_{timestamp}.json\"\n",
    "                export_data = {\n",
    "                    'parameters': params_df.to_dict('index'),\n",
    "                    'quality_metrics': quality_df.to_dict('index'),\n",
    "                    'metadata': {\n",
    "                        'analysis_date': datetime.now().isoformat(),\n",
    "                        'total_spectra': len(self.spectral_data.timepoints),\n",
    "                        'successful_fits': len([r for r in self.fit_results.values() if r['success']]),\n",
    "                        'models_used': [config['type'] for config in self.current_model_configs]\n",
    "                    }\n",
    "                }\n",
    "                with open(filename, 'w') as f:\n",
    "                    json.dump(export_data, f, indent=2, default=str)\n",
    "                    \n",
    "            elif export_format == 'pkl':\n",
    "                filename = f\"spectral_analysis_session_{timestamp}.pkl\"\n",
    "                export_data = {\n",
    "                    'spectral_data': self.spectral_data,\n",
    "                    'fit_results': self.fit_results,\n",
    "                    'model_configs': self.current_model_configs,\n",
    "                    'parameters_df': params_df,\n",
    "                    'quality_df': quality_df\n",
    "                }\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(export_data, f)\n",
    "            \n",
    "            self.show_message(f\"‚úÖ Results exported to {filename}\", \"success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error exporting results: {str(e)}\", \"error\")\n",
    "            \n",
    "    def save_session(self, button):\n",
    "        \"\"\"Save current session\"\"\"\n",
    "        try:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"spectral_analysis_session_{timestamp}.pkl\"\n",
    "            \n",
    "            session_data = {\n",
    "                'spectral_data': self.spectral_data,\n",
    "                'fit_results': self.fit_results,\n",
    "                'model_configs': self.current_model_configs,\n",
    "                'ui_state': {\n",
    "                    'spectrum_selector': self.spectrum_selector.value,\n",
    "                    'preprocessing_method': self.preprocessing_method.value,\n",
    "                    'plot_type': self.plot_type.value,\n",
    "                    'parameter_selector': self.parameter_selector.value\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(session_data, f)\n",
    "                \n",
    "            self.show_message(f\"‚úÖ Session saved as {filename}\", \"success\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.show_message(f\"Error saving session: {str(e)}\", \"error\")\n",
    "            \n",
    "    def load_session(self, button):\n",
    "        \"\"\"Load a previous session\"\"\"\n",
    "        # Note: In a real Voil√† app, you'd use a file dialog widget\n",
    "        # For now, this is a placeholder that shows how to load\n",
    "        self.show_message(\"Session loading requires manual file selection. Upload a .pkl session file.\", \"info\")\n",
    "        \n",
    "    def show_message(self, message, msg_type=\"info\"):\n",
    "        \"\"\"Display status message\"\"\"\n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if msg_type == \"success\":\n",
    "                css_class = \"success-box\"\n",
    "            elif msg_type == \"error\":\n",
    "                css_class = \"error-box\"\n",
    "            elif msg_type == \"warning\":\n",
    "                css_class = \"warning-box\"\n",
    "            else:\n",
    "                css_class = \"parameter-box\"\n",
    "                \n",
    "            display(HTML(f'<div class=\"{css_class}\">{message}</div>'))\n",
    "            \n",
    "    def display_interface(self):\n",
    "        \"\"\"Display the complete interface\"\"\"\n",
    "        \n",
    "        # File Upload Section\n",
    "        file_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üìÅ Data Loading</div>'),\n",
    "            widgets.HBox([self.data_format, self.file_upload, self.load_button]),\n",
    "            self.status_output\n",
    "        ])\n",
    "        \n",
    "        # Preprocessing Section\n",
    "        preprocessing_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üîß Preprocessing</div>'),\n",
    "            self.preprocessing_method,\n",
    "            widgets.HBox([self.smooth_window, self.smooth_polyorder, self.smooth_sigma]),\n",
    "            self.apply_preprocessing_button\n",
    "        ])\n",
    "        \n",
    "        # Peak Detection Section\n",
    "        peak_detection_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üîç Peak Detection</div>'),\n",
    "            widgets.HBox([self.spectrum_selector]),\n",
    "            widgets.HBox([self.peak_height, self.peak_distance, self.peak_prominence]),\n",
    "            self.detect_peaks_button\n",
    "        ])\n",
    "        \n",
    "        # Model Management Section\n",
    "        model_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üéØ Model Management</div>'),\n",
    "            widgets.HBox([self.model_type, self.model_prefix]),\n",
    "            widgets.HBox([self.add_model_button, self.clear_models_button]),\n",
    "            self.models_list\n",
    "        ])\n",
    "        \n",
    "        # Fitting Section\n",
    "        fitting_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">‚öôÔ∏è Fitting Controls</div>'),\n",
    "            widgets.HBox([self.fit_single_button, self.fit_all_button]),\n",
    "            widgets.HBox([self.fit_range_start, self.fit_range_end, self.parallel_workers]),\n",
    "            self.progress_bar,\n",
    "            self.progress_label\n",
    "        ])\n",
    "        \n",
    "        # Visualization Section\n",
    "        viz_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üìä Visualization</div>'),\n",
    "            widgets.HBox([self.plot_type, self.parameter_selector]),\n",
    "            self.update_plot_button,\n",
    "            self.plot_output\n",
    "        ])\n",
    "        \n",
    "        # Export Section\n",
    "        export_section = widgets.VBox([\n",
    "            widgets.HTML('<div class=\"section-header\">üíæ Export & Session</div>'),\n",
    "            widgets.HBox([self.export_format, self.export_data_button]),\n",
    "            widgets.HBox([self.save_session_button, self.load_session_button])\n",
    "        ])\n",
    "        \n",
    "        # Main layout\n",
    "        left_panel = widgets.VBox([\n",
    "            file_section,\n",
    "            preprocessing_section,\n",
    "            peak_detection_section,\n",
    "            model_section,\n",
    "            fitting_section,\n",
    "            export_section\n",
    "        ])\n",
    "        \n",
    "        right_panel = widgets.VBox([\n",
    "            viz_section\n",
    "        ])\n",
    "        \n",
    "        main_interface = widgets.HBox([\n",
    "            left_panel,\n",
    "            right_panel\n",
    "        ], layout=widgets.Layout(width='100%'))\n",
    "        \n",
    "        # Display everything\n",
    "        display(main_interface)\n",
    "        \n",
    "        # Initial status\n",
    "        self.show_message(\"üöÄ Spectral Analysis Suite ready! Upload your data to begin.\", \"info\")\n",
    "\n",
    "# =============================================================================\n",
    "# ADVANCED FEATURES AND UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "class AdvancedAnalysis:\n",
    "    \"\"\"Advanced analysis tools for spectral data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def perform_pca(spectral_data, n_components=5):\n",
    "        \"\"\"Perform Principal Component Analysis\"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(spectral_data.processed_data.T)\n",
    "        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        return {\n",
    "            'components': pca.components_,\n",
    "            'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "            'transformed_data': pca_result,\n",
    "            'scaler': scaler,\n",
    "            'pca_model': pca\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_outliers(spectral_data, method='isolation_forest'):\n",
    "        \"\"\"Detect outlier spectra\"\"\"\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        # Prepare data\n",
    "        data = spectral_data.processed_data.T\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(data)\n",
    "        \n",
    "        if method == 'isolation_forest':\n",
    "            clf = IsolationForest(contamination=0.1, random_state=42)\n",
    "            outliers = clf.fit_predict(scaled_data)\n",
    "            outlier_indices = np.where(outliers == -1)[0]\n",
    "        else:\n",
    "            # Statistical outlier detection based on spectrum intensity\n",
    "            mean_intensities = np.mean(data, axis=1)\n",
    "            z_scores = np.abs((mean_intensities - np.mean(mean_intensities)) / np.std(mean_intensities))\n",
    "            outlier_indices = np.where(z_scores > 3)[0]\n",
    "        \n",
    "        return outlier_indices\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_peak_metrics(fit_results, spectral_data):\n",
    "        \"\"\"Calculate advanced peak metrics\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Extract all parameter names\n",
    "        all_params = set()\n",
    "        for result in fit_results.values():\n",
    "            if result['success']:\n",
    "                all_params.update(result['parameters'].keys())\n",
    "        \n",
    "        # Group by peak\n",
    "        peak_groups = {}\n",
    "        for param in all_params:\n",
    "            if '_' in param:\n",
    "                peak_name = '_'.join(param.split('_')[:-1])\n",
    "                if peak_name not in peak_groups:\n",
    "                    peak_groups[peak_name] = []\n",
    "                peak_groups[peak_name].append(param)\n",
    "        \n",
    "        for peak_name, params in peak_groups.items():\n",
    "            peak_metrics = {}\n",
    "            \n",
    "            # Extract time series for each parameter\n",
    "            for param in params:\n",
    "                values = []\n",
    "                timepoints = []\n",
    "                \n",
    "                for idx in sorted(fit_results.keys()):\n",
    "                    if (fit_results[idx]['success'] and \n",
    "                        param in fit_results[idx]['parameters']):\n",
    "                        values.append(fit_results[idx]['parameters'][param].value)\n",
    "                        timepoints.append(spectral_data.timepoints[idx])\n",
    "                \n",
    "                if values:\n",
    "                    peak_metrics[param] = {\n",
    "                        'mean': np.mean(values),\n",
    "                        'std': np.std(values),\n",
    "                        'min': np.min(values),\n",
    "                        'max': np.max(values),\n",
    "                        'trend': np.polyfit(timepoints, values, 1)[0] if len(values) > 1 else 0,\n",
    "                        'stability': np.std(values) / np.mean(values) if np.mean(values) != 0 else np.inf\n",
    "                    }\n",
    "            \n",
    "            metrics[peak_name] = peak_metrics\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "class BaselineCorrection:\n",
    "    \"\"\"Advanced baseline correction tools\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def asymmetric_least_squares(y, lam=1e4, p=0.01, niter=10):\n",
    "        \"\"\"Asymmetric Least Squares baseline correction\"\"\"\n",
    "        L = len(y)\n",
    "        D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L-2))\n",
    "        w = np.ones(L)\n",
    "        \n",
    "        for i in range(niter):\n",
    "            W = sparse.spdiags(w, 0, L, L)\n",
    "            Z = W + lam * D.dot(D.transpose())\n",
    "            z = sparse.linalg.spsolve(Z, w*y)\n",
    "            w = p * (y > z) + (1-p) * (y < z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    @staticmethod\n",
    "    def polynomial_baseline(x, y, degree=2):\n",
    "        \"\"\"Polynomial baseline correction\"\"\"\n",
    "        coeffs = np.polyfit(x, y, degree)\n",
    "        baseline = np.polyval(coeffs, x)\n",
    "        return baseline\n",
    "    \n",
    "    @staticmethod\n",
    "    def rolling_ball_baseline(y, ball_radius=100):\n",
    "        \"\"\"Rolling ball baseline correction\"\"\"\n",
    "        from scipy.ndimage import minimum_filter, maximum_filter\n",
    "        \n",
    "        # Minimum filter (rolling ball)\n",
    "        baseline = minimum_filter(y, size=ball_radius)\n",
    "        \n",
    "        # Smooth the baseline\n",
    "        baseline = maximum_filter(baseline, size=ball_radius//2)\n",
    "        \n",
    "        return baseline\n",
    "\n",
    "class QualityAssessment:\n",
    "    \"\"\"Tools for assessing fit quality and data integrity\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_information_criteria(residuals, n_params, n_points):\n",
    "        \"\"\"Calculate AIC, BIC, and other information criteria\"\"\"\n",
    "        n = n_points\n",
    "        k = n_params\n",
    "        \n",
    "        # Sum of squared residuals\n",
    "        ssr = np.sum(residuals**2)\n",
    "        \n",
    "        # Log-likelihood (assuming normal distribution)\n",
    "        log_likelihood = -n/2 * np.log(2*np.pi) - n/2 * np.log(ssr/n) - ssr/(2*(ssr/n))\n",
    "        \n",
    "        # Information criteria\n",
    "        aic = 2*k - 2*log_likelihood\n",
    "        bic = k*np.log(n) - 2*log_likelihood\n",
    "        aicc = aic + (2*k*(k+1))/(n-k-1) if n-k-1 > 0 else np.inf\n",
    "        \n",
    "        return {\n",
    "            'aic': aic,\n",
    "            'bic': bic,\n",
    "            'aicc': aicc,\n",
    "            'log_likelihood': log_likelihood\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def residual_analysis(residuals, fitted_values):\n",
    "        \"\"\"Perform residual analysis\"\"\"\n",
    "        # Durbin-Watson test for autocorrelation\n",
    "        diff_residuals = np.diff(residuals)\n",
    "        dw_statistic = np.sum(diff_residuals**2) / np.sum(residuals**2)\n",
    "        \n",
    "        # Runs test for randomness\n",
    "        median_residual = np.median(residuals)\n",
    "        runs = np.sum(np.diff(residuals > median_residual) != 0) + 1\n",
    "        \n",
    "        # Shapiro-Wilk test for normality\n",
    "        from scipy import stats\n",
    "        try:\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "        except:\n",
    "            shapiro_stat, shapiro_p = np.nan, np.nan\n",
    "        \n",
    "        return {\n",
    "            'durbin_watson': dw_statistic,\n",
    "            'runs_test': runs,\n",
    "            'shapiro_wilk_stat': shapiro_stat,\n",
    "            'shapiro_wilk_p': shapiro_p,\n",
    "            'mean_residual': np.mean(residuals),\n",
    "            'std_residual': np.std(residuals)\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# BATCH PROCESSING AND AUTOMATION\n",
    "# =============================================================================\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"Batch processing tools for multiple datasets\"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_interface):\n",
    "        self.interface = analysis_interface\n",
    "        self.batch_results = {}\n",
    "        \n",
    "    def process_multiple_files(self, file_list, model_configs):\n",
    "        \"\"\"Process multiple files with the same model configuration\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for i, file_path in enumerate(file_list):\n",
    "            try:\n",
    "                # Load file\n",
    "                if file_path.endswith('.xlsx'):\n",
    "                    df = pd.read_excel(file_path, index_col=0)\n",
    "                elif file_path.endswith('.csv'):\n",
    "                    df = pd.read_csv(file_path, index_col=0)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # Create spectral data object\n",
    "                spectral_data = SpectralData()\n",
    "                wavelengths = df.index.values\n",
    "                timepoints = df.columns.values.astype(float)\n",
    "                data_matrix = df.values\n",
    "                spectral_data.load_matrix(data_matrix, wavelengths, timepoints)\n",
    "                \n",
    "                # Fit data\n",
    "                fitting_engine = FittingEngine()\n",
    "                fit_results = fitting_engine.fit_parallel(spectral_data, model_configs)\n",
    "                \n",
    "                results[file_path] = {\n",
    "                    'spectral_data': spectral_data,\n",
    "                    'fit_results': fit_results,\n",
    "                    'success_rate': len([r for r in fit_results.values() if r['success']]) / len(fit_results)\n",
    "                }\n",
    "                \n",
    "                # Progress update\n",
    "                progress = (i + 1) / len(file_list) * 100\n",
    "                print(f\"Processed {i+1}/{len(file_list)} files ({progress:.1f}%)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {str(e)}\")\n",
    "                results[file_path] = {'error': str(e)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compare_datasets(self, batch_results):\n",
    "        \"\"\"Compare results across multiple datasets\"\"\"\n",
    "        comparison = {}\n",
    "        \n",
    "        # Extract common parameters\n",
    "        all_params = set()\n",
    "        for file_result in batch_results.values():\n",
    "            if 'fit_results' in file_result:\n",
    "                for result in file_result['fit_results'].values():\n",
    "                    if result['success']:\n",
    "                        all_params.update(result['parameters'].keys())\n",
    "        \n",
    "        # Compare parameter statistics\n",
    "        for param in all_params:\n",
    "            param_stats = {}\n",
    "            \n",
    "            for file_path, file_result in batch_results.items():\n",
    "                if 'fit_results' in file_result:\n",
    "                    values = []\n",
    "                    for result in file_result['fit_results'].values():\n",
    "                        if result['success'] and param in result['parameters']:\n",
    "                            values.append(result['parameters'][param].value)\n",
    "                    \n",
    "                    if values:\n",
    "                        param_stats[file_path] = {\n",
    "                            'mean': np.mean(values),\n",
    "                            'std': np.std(values),\n",
    "                            'min': np.min(values),\n",
    "                            'max': np.max(values)\n",
    "                        }\n",
    "            \n",
    "            comparison[param] = param_stats\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "# =============================================================================\n",
    "# MACHINE LEARNING INTEGRATION\n",
    "# =============================================================================\n",
    "\n",
    "class MLAnalysis:\n",
    "    \"\"\"Machine learning tools for spectral analysis\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_initial_parameters(spectral_data, peak_positions, model_type='gaussian'):\n",
    "        \"\"\"Use ML to predict initial fitting parameters\"\"\"\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # This is a simplified example - in practice you'd train on a large dataset\n",
    "        # For now, we'll use heuristic approaches\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for peak_pos in peak_positions:\n",
    "            # Extract local region around peak\n",
    "            peak_idx = np.argmin(np.abs(spectral_data.wavelengths - peak_pos))\n",
    "            region_start = max(0, peak_idx - 20)\n",
    "            region_end = min(len(spectral_data.wavelengths), peak_idx + 20)\n",
    "            \n",
    "            local_wavelengths = spectral_data.wavelengths[region_start:region_end]\n",
    "            local_spectrum = spectral_data.processed_data[region_start:region_end, 0]  # Use first spectrum\n",
    "            \n",
    "            # Simple heuristic predictions\n",
    "            amplitude = np.max(local_spectrum)\n",
    "            center = local_wavelengths[np.argmax(local_spectrum)]\n",
    "            \n",
    "            # Estimate width from FWHM\n",
    "            half_max = amplitude / 2\n",
    "            indices = np.where(local_spectrum >= half_max)[0]\n",
    "            if len(indices) > 1:\n",
    "                fwhm = local_wavelengths[indices[-1]] - local_wavelengths[indices[0]]\n",
    "                if model_type.lower() == 'gaussian':\n",
    "                    sigma = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "                else:\n",
    "                    sigma = fwhm / 2\n",
    "            else:\n",
    "                sigma = 2.0  # Default value\n",
    "            \n",
    "            predictions.append({\n",
    "                'amplitude': amplitude,\n",
    "                'center': center,\n",
    "                'sigma': sigma\n",
    "            })\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    def cluster_spectra(spectral_data, n_clusters=3):\n",
    "        \"\"\"Cluster spectra using unsupervised learning\"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        # Prepare data\n",
    "        data = spectral_data.processed_data.T\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(data)\n",
    "        \n",
    "        # Perform clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "        \n",
    "        return {\n",
    "            'labels': cluster_labels,\n",
    "            'centroids': scaler.inverse_transform(kmeans.cluster_centers_),\n",
    "            'model': kmeans,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZATION AND MAIN INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "# Create and display the main interface\n",
    "print(\"üî¨ Initializing Advanced Spectral Analysis Suite...\")\n",
    "\n",
    "# Initialize the main interface\n",
    "analysis_interface = SpectralAnalysisInterface()\n",
    "\n",
    "# Display the interface\n",
    "analysis_interface.display_interface()\n",
    "\n",
    "# Additional utility functions for Voil√†\n",
    "def create_example_data():\n",
    "    \"\"\"Create example spectral data for testing\"\"\"\n",
    "    # Generate synthetic spectral data\n",
    "    wavelengths = np.linspace(400, 800, 200)\n",
    "    timepoints = np.linspace(0, 100, 50)\n",
    "    \n",
    "    # Create synthetic spectra with evolving peaks\n",
    "    spectra = np.zeros((len(wavelengths), len(timepoints)))\n",
    "    \n",
    "    for i, t in enumerate(timepoints):\n",
    "        # Background\n",
    "        background = 0.1 * np.exp(-(wavelengths - 600)**2 / (2 * 100**2))\n",
    "        \n",
    "        # Evolving peaks\n",
    "        peak1_center = 500 + 20 * np.sin(t * 0.1)\n",
    "        peak1_amplitude = 1.0 + 0.3 * np.cos(t * 0.15)\n",
    "        peak1 = peak1_amplitude * np.exp(-(wavelengths - peak1_center)**2 / (2 * 15**2))\n",
    "        \n",
    "        peak2_center = 650 + 10 * np.cos(t * 0.08)\n",
    "        peak2_amplitude = 0.8 + 0.2 * np.sin(t * 0.12)\n",
    "        peak2 = peak2_amplitude * np.exp(-(wavelengths - peak2_center)**2 / (2 * 20**2))\n",
    "        \n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 0.02, len(wavelengths))\n",
    "        \n",
    "        spectra[:, i] = background + peak1 + peak2 + noise\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(spectra, index=wavelengths, columns=timepoints)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to load example data\n",
    "def load_example_data():\n",
    "    \"\"\"Load example data into the interface\"\"\"\n",
    "    example_df = create_example_data()\n",
    "    \n",
    "    # Simulate loading into the interface\n",
    "    wavelengths = example_df.index.values\n",
    "    timepoints = example_df.columns.values\n",
    "    data_matrix = example_df.values\n",
    "    \n",
    "    analysis_interface.spectral_data.load_matrix(data_matrix, wavelengths, timepoints)\n",
    "    analysis_interface.spectrum_selector.max = len(timepoints) - 1\n",
    "    analysis_interface.fit_range_end.value = len(timepoints) - 1\n",
    "    \n",
    "    analysis_interface.show_message(\"‚úÖ Example data loaded successfully!\", \"success\")\n",
    "    analysis_interface.update_plots()\n",
    "\n",
    "# Add example data button\n",
    "example_button = widgets.Button(\n",
    "    description=\"Load Example Data\",\n",
    "    button_style='info',\n",
    "    icon='flask'\n",
    ")\n",
    "\n",
    "example_button.on_click(lambda x: load_example_data())\n",
    "\n",
    "# Display example button\n",
    "display(widgets.HBox([\n",
    "    widgets.HTML(\"<h3>üß™ Quick Start</h3>\"),\n",
    "    example_button\n",
    "]))\n",
    "\n",
    "# Final status\n",
    "print(\"‚úÖ Advanced Spectral Analysis Suite is ready!\")\n",
    "print(\"\\nüìã Features available:\")\n",
    "print(\"   ‚Ä¢ Multi-format data loading (Excel, CSV)\")\n",
    "print(\"   ‚Ä¢ Advanced preprocessing (smoothing, baseline correction)\")\n",
    "print(\"   ‚Ä¢ Intelligent peak detection\")\n",
    "print(\"   ‚Ä¢ Parallel multi-model fitting\")\n",
    "print(\"   ‚Ä¢ Real-time visualization\")\n",
    "print(\"   ‚Ä¢ Parameter evolution tracking\")\n",
    "print(\"   ‚Ä¢ Quality metrics assessment\")\n",
    "print(\"   ‚Ä¢ Animation creation and export\")\n",
    "print(\"   ‚Ä¢ Comprehensive data export\")\n",
    "print(\"   ‚Ä¢ Session save/load functionality\")\n",
    "print(\"\\nüöÄ Upload your spectral data or click 'Load Example Data' to begin!\")# Advanced Spectral Analysis Suite - Voil√† Interface\n",
    "# Professional laboratory-grade time-resolved spectral analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee1963-aa1a-415b-ad2e-c7298418977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
