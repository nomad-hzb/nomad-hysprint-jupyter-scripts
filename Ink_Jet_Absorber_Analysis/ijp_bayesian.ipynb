{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ca750b-956e-4633-834f-0722a1fa900f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from api_calls import get_ids_in_batch, get_sample_description, get_all_eqe as get_all_ijp\n",
    "import batch_selection\n",
    "import access_token\n",
    "\n",
    "url_base =\"https://nomad-hzb-se.de\"\n",
    "url = f\"{url_base}/nomad-oasis/api/v1\"\n",
    "token = access_token.get_token(url)\n",
    "access_token.log_notebook_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5ee6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ijp_data(try_sample_ids, variation):\n",
    "    print(f\"Fetching data for {len(try_sample_ids)} samples\")\n",
    "    \n",
    "    # Make API call, result has everything in json format\n",
    "    all_ijp = get_all_ijp(url, token, try_sample_ids, eqe_type=\"HySprint_Inkjet_Printing\")\n",
    "    # Make API call, result has everything in json format\n",
    "    all_jv = get_all_ijp(url, token, try_sample_ids, eqe_type=\"HySprint_JVmeasurement\")\n",
    "    \n",
    "    # Check if there's any IJP data\n",
    "    existing_sample_ids = list(all_ijp.keys())\n",
    "    if len(existing_sample_ids) == 0:\n",
    "        return None  # Return None value to indicate no data\n",
    "    \n",
    "    # List to hold all dataframes that will be concatenated\n",
    "    sample_data_list = []\n",
    "    \n",
    "    # Process each sample's data\n",
    "    for sample_id, sample_entries in all_ijp.items():\n",
    "        print(sample_id)\n",
    "        if len(sample_entries) > 1:\n",
    "            assert \"Multiple entries found for sample_id: {}\".format(sample_id)\n",
    "        for entry in sample_entries:\n",
    "            # Extract the data part from the entry (index 0 is data, index 1 is metadata)\n",
    "            ijp_data = entry[0]\n",
    "            \n",
    "            # Create a dictionary to hold flattened data\n",
    "            row_data = {\n",
    "                # Basic sample information\n",
    "                'sample_id': sample_id,\n",
    "                'variation': variation.get(sample_id, ''),\n",
    "                'name': ijp_data.get('name', ''),\n",
    "                'datetime': ijp_data.get('datetime', ''),\n",
    "                'description': ijp_data.get('description', ''),\n",
    "                'location': ijp_data.get('location', ''),\n",
    "                \n",
    "                # Annealing information\n",
    "                'annealing_temperature': ijp_data.get('annealing', {}).get('temperature', None),\n",
    "                'annealing_time': ijp_data.get('annealing', {}).get('time', None),\n",
    "                'annealing_atmosphere': ijp_data.get('annealing', {}).get('atmosphere', ''),\n",
    "                \n",
    "                # Atmosphere information\n",
    "                'relative_humidity': ijp_data.get('atmosphere', {}).get('relative_humidity', None),\n",
    "            }\n",
    "            \n",
    "            # Extract printing properties\n",
    "            properties = ijp_data.get('properties', {})\n",
    "            row_data.update({\n",
    "                'cartridge_pressure': properties.get('cartridge_pressure', None),\n",
    "                'drop_density': properties.get('drop_density', None),\n",
    "                'printed_area': properties.get('printed_area', None),\n",
    "                'substrate_temperature': properties.get('substrate_temperature', None),\n",
    "            })\n",
    "            \n",
    "            # Extract print head properties\n",
    "            print_head = properties.get('print_head_properties', {})\n",
    "            row_data.update({\n",
    "                'print_head_name': print_head.get('print_head_name', ''),\n",
    "                'print_head_temperature': print_head.get('print_head_temperature', None),\n",
    "                'num_active_nozzles': print_head.get('number_of_active_print_nozzles', None),\n",
    "                'nozzle_drop_frequency': print_head.get('print_nozzle_drop_frequency', None),\n",
    "                'nozzle_drop_volume': print_head.get('print_nozzle_drop_volume', None),\n",
    "            })\n",
    "            \n",
    "            # Extract quenching information\n",
    "            quenching = ijp_data.get('quenching', {})\n",
    "            if quenching:\n",
    "                # Extract vacuum properties\n",
    "                vacuum_props = quenching.get('vacuum_properties', {})\n",
    "                if vacuum_props:\n",
    "                    row_data.update({\n",
    "                        'vacuum_pressure': vacuum_props.get('pressure', None),\n",
    "                        'vacuum_start_time': vacuum_props.get('start_time', None),\n",
    "                        'vacuum_duration': vacuum_props.get('duration', None),\n",
    "                        'vacuum_temperature': vacuum_props.get('temperature', None),\n",
    "                    })\n",
    "                \n",
    "                # Extract gas quenching properties\n",
    "                gas_props = quenching.get('gas_quenching_properties', {})\n",
    "                if gas_props:\n",
    "                    row_data.update({\n",
    "                        'quenching_gas': gas_props.get('gas', ''),\n",
    "                        'quenching_duration': gas_props.get('duration', None),\n",
    "                        'quenching_pressure': gas_props.get('pressure', None),\n",
    "                    })\n",
    "                    \n",
    "                # Extract any additional quenching fields at the top level\n",
    "                row_data.update({\n",
    "                    'quenching_comment': quenching.get('comment', ''),\n",
    "                    'quenching_type': quenching.get('m_def', '').split('.')[-1] if 'm_def' in quenching else '',\n",
    "                })\n",
    "            \n",
    "            # Extract layer information\n",
    "            if 'layer' in ijp_data and len(ijp_data['layer']) > 0:\n",
    "                layer = ijp_data['layer'][0]  # Take first layer as example\n",
    "                if \"absorber\" not in layer.get('layer_type', '').lower():\n",
    "                    continue  # Skip if layer material is not an absorber\n",
    "                # Update row_data with layer information\n",
    "                row_data.update({\n",
    "                    'layer_material': layer.get('layer_material', ''),\n",
    "                    'layer_material_name': layer.get('layer_material_name', ''),\n",
    "                    'layer_type': layer.get('layer_type', '')\n",
    "                })\n",
    "            \n",
    "            # Extract solution information\n",
    "            if 'solution' in ijp_data and len(ijp_data['solution']) > 0:\n",
    "                solution = ijp_data['solution'][0]  # Take first solution\n",
    "                solution_details = solution.get('solution_details', {})\n",
    "                \n",
    "                # Extract solvent information\n",
    "                solvents = solution_details.get('solvent', [])\n",
    "                for i, solvent in enumerate(solvents): \n",
    "                    \n",
    "                    solvent_name = solvent[\"chemical_2\"][\"name\"] if \"chemical_2\" in solvent else f'solvent{i+1}'\n",
    "                    # Include name directly in column name instead of separate column\n",
    "                    row_data.update({\n",
    "                        f'solvent_amount_{solvent_name}': solvent.get('amount_relative', None),\n",
    "                        f'solvent_volume_{solvent_name}': solvent.get('chemical_volume', None)\n",
    "                    })\n",
    "                \n",
    "                # Extract solute information\n",
    "                solutes = solution_details.get('solute', [])\n",
    "                for i, solute in enumerate(solutes): \n",
    "                    if 'name' in solute:  # Only process if name exists\n",
    "                        solute_name = solute[\"chemical_2\"][\"name\"] if \"chemical_2\" in solute else f'solute{i+1}'\n",
    "                        # Include name directly in column name instead of separate column\n",
    "                        row_data.update({\n",
    "                            f'solute_concentration_{solute_name}': solute.get('concentration_mol', None)\n",
    "                        })\n",
    "            if not all_jv.get(sample_id):\n",
    "                continue\n",
    "            for jv in all_jv[sample_id]:\n",
    "                jv = jv[0]  # Get the data part of the JV measurement\n",
    "                if \"efficiency\" not in row_data.keys():\n",
    "                    # Initialize efficiency and other JV parameters if not present\n",
    "                    row_data['efficiency'] = []\n",
    "                    row_data['open_circuit_voltage'] = []\n",
    "                    row_data['fill_factor'] = []\n",
    "                    row_data['short_circuit_current_density'] = []\n",
    "                    row_data['series_resistance'] = []\n",
    "                    row_data['shunt_resistance'] = []\n",
    "                row_data['efficiency'].extend([c[\"efficiency\"] for c in  jv[\"jv_curve\"]])\n",
    "                row_data['open_circuit_voltage'].extend([c[\"open_circuit_voltage\"] for c in  jv[\"jv_curve\"]])\n",
    "                row_data['fill_factor'].extend([c[\"fill_factor\"] for c in  jv[\"jv_curve\"]])\n",
    "                row_data['short_circuit_current_density'].extend([c[\"short_circuit_current_density\"] for c in  jv[\"jv_curve\"]])\n",
    "                row_data['series_resistance'].extend([c[\"series_resistance\"] for c in  jv[\"jv_curve\"]])\n",
    "                row_data['shunt_resistance'].extend([c[\"shunt_resistance\"] for c in  jv[\"jv_curve\"]])\n",
    "                \n",
    "            \n",
    "            # Create a DataFrame from the row data and append to our list\n",
    "            sample_df = pd.DataFrame([row_data])\n",
    "            sample_data_list.append(sample_df)\n",
    "    \n",
    "    # Concatenate all sample DataFrames\n",
    "    if sample_data_list:\n",
    "        result_df = pd.concat(sample_data_list, ignore_index=True)\n",
    "        return result_df\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae111d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ace5bea49bf47bfb8ce6871debe7e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Search Batch'), SelectMultiple(description='Batches', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45afad04ba424176a4a938f1a326629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156acd5b8e3b493fb9354ef5f8f3f2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warning_sign = \"\\u26A0\"\n",
    "\n",
    "# Output widgets for different sections\n",
    "out = widgets.Output()\n",
    "dynamic_content = widgets.Output()\n",
    "results_content = widgets.Output(layout={\n",
    "    'max_height': '1000px',\n",
    "    'overflow': 'scroll',\n",
    "})\n",
    "\n",
    "# Global variables\n",
    "data = None\n",
    "original_data = None\n",
    "optimization_history = []\n",
    "current_optimizer = None\n",
    "parameter_widgets = {}\n",
    "target_widget = None\n",
    "\n",
    "# Bayesian optimization imports (add these to your imports in cell 1)\n",
    "try:\n",
    "    from skopt import gp_minimize\n",
    "    from skopt.space import Real, Integer, Categorical\n",
    "    from skopt.utils import use_named_args\n",
    "    from skopt.acquisition import gaussian_ei\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.gaussian_process.kernels import RBF, Matern\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    BAYESIAN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    BAYESIAN_AVAILABLE = False\n",
    "\n",
    "class BayesianOptimizationAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.clean_data = None\n",
    "        self.parameter_columns = []\n",
    "        self.target_column = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.optimization_space = []\n",
    "        self.adequacy_status = None\n",
    "        self.data_metrics = {}\n",
    "        \n",
    "    def validate_dataset(self, df, target_column, parameter_columns):\n",
    "        \"\"\"Validates dataset and returns clean data with metrics\"\"\"\n",
    "        initial_samples = len(df)\n",
    "        \n",
    "        # Remove rows with missing target values\n",
    "        df_clean = df.dropna(subset=[target_column])\n",
    "        \n",
    "        # Remove rows with missing parameter values\n",
    "        df_clean = df_clean.dropna(subset=parameter_columns)\n",
    "        \n",
    "        valid_samples = len(df_clean)\n",
    "        removal_rate = (initial_samples - valid_samples) / initial_samples if initial_samples > 0 else 0\n",
    "        \n",
    "        return df_clean, {\n",
    "            'initial_samples': initial_samples,\n",
    "            'valid_samples': valid_samples,\n",
    "            'removal_rate': removal_rate,\n",
    "            'samples_per_parameter': valid_samples / len(parameter_columns) if parameter_columns else 0\n",
    "        }\n",
    "    \n",
    "    def assess_sample_adequacy(self, n_samples, n_parameters):\n",
    "        \"\"\"Provides recommendations based on sample size\"\"\"\n",
    "        if n_parameters == 0:\n",
    "            return \"ERROR: No parameters selected\"\n",
    "        \n",
    "        ratio = n_samples / n_parameters\n",
    "        \n",
    "        if ratio < 5:\n",
    "            return \"CRITICAL: Insufficient data - optimization not recommended\"\n",
    "        elif ratio < 10:\n",
    "            return \"WARNING: Very limited data - high risk of overfitting\"\n",
    "        elif ratio < 20:\n",
    "            return \"CAUTION: Limited data - use simple models only\"\n",
    "        elif ratio < 50:\n",
    "            return \"ACCEPTABLE: Adequate for basic optimization\"\n",
    "        else:\n",
    "            return \"GOOD: Sufficient data for robust optimization\"\n",
    "    \n",
    "    def prepare_optimization_data(self, df, target_col, param_cols):\n",
    "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "        # Validate dataset\n",
    "        df_clean, metrics = self.validate_dataset(df, target_col, param_cols)\n",
    "        \n",
    "        if metrics['valid_samples'] == 0:\n",
    "            return None, metrics, \"ERROR: No valid samples after cleaning\"\n",
    "        \n",
    "        # Assess sample adequacy\n",
    "        adequacy = self.assess_sample_adequacy(metrics['valid_samples'], len(param_cols))\n",
    "        \n",
    "        # Handle list-type JV parameters by taking mean\n",
    "        jv_params = ['efficiency', 'open_circuit_voltage', 'fill_factor', \n",
    "                    'short_circuit_current_density', 'series_resistance', 'shunt_resistance']\n",
    "        \n",
    "        for param in param_cols + [target_col]:\n",
    "            if param in jv_params and not df_clean.empty:\n",
    "                if isinstance(df_clean[param].iloc[0], list):\n",
    "                    df_clean[param] = df_clean[param].apply(\n",
    "                        lambda x: np.mean(x) if isinstance(x, list) and len(x) > 0 else np.nan\n",
    "                    )\n",
    "        \n",
    "        # Remove any remaining NaN values after mean calculation\n",
    "        df_clean = df_clean.dropna(subset=[target_col] + param_cols)\n",
    "        \n",
    "        # Update metrics after final cleaning\n",
    "        metrics['final_valid_samples'] = len(df_clean)\n",
    "        metrics['final_samples_per_parameter'] = len(df_clean) / len(param_cols) if param_cols else 0\n",
    "        \n",
    "        return df_clean, metrics, adequacy\n",
    "    \n",
    "    def create_optimization_space(self, df, param_cols):\n",
    "        \"\"\"Creates optimization space for scikit-optimize\"\"\"\n",
    "        space = []\n",
    "        \n",
    "        for param in param_cols:\n",
    "            if df[param].dtype in ['int64', 'float64']:\n",
    "                min_val = float(df[param].min())\n",
    "                max_val = float(df[param].max())\n",
    "                \n",
    "                # Add some padding to avoid boundary issues\n",
    "                range_pad = (max_val - min_val) * 0.1\n",
    "                min_val -= range_pad\n",
    "                max_val += range_pad\n",
    "                \n",
    "                if df[param].dtype == 'int64':\n",
    "                    space.append(Integer(int(min_val), int(max_val), name=param))\n",
    "                else:\n",
    "                    space.append(Real(min_val, max_val, name=param))\n",
    "            else:\n",
    "                # Categorical parameter\n",
    "                unique_values = df[param].unique().tolist()\n",
    "                space.append(Categorical(unique_values, name=param))\n",
    "        \n",
    "        return space\n",
    "    \n",
    "    def estimate_convergence_budget(self, n_parameters, complexity_factor=1.0):\n",
    "        \"\"\"Estimates iterations needed for convergence\"\"\"\n",
    "        base_iterations = {\n",
    "            'exploration_phase': 5 * n_parameters,\n",
    "            'exploitation_phase': 10 * n_parameters,\n",
    "            'convergence_buffer': 5 * n_parameters\n",
    "        }\n",
    "        \n",
    "        total_estimate = sum(base_iterations.values()) * complexity_factor\n",
    "        \n",
    "        return {\n",
    "            'minimum_budget': int(total_estimate * 0.5),\n",
    "            'recommended_budget': int(total_estimate),\n",
    "            'maximum_useful': int(total_estimate * 1.5),\n",
    "            'phase_breakdown': base_iterations\n",
    "        }\n",
    "\n",
    "\n",
    "def create_parameter_selection_widgets():\n",
    "    \"\"\"Creates dynamic parameter selection interface\"\"\"\n",
    "    if data is None:\n",
    "        return widgets.HTML(\"No data loaded. Please load data first.\")\n",
    "    \n",
    "    # Get numeric and categorical columns\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # JV parameters (these can be lists but we'll take means)\n",
    "    jv_params = ['efficiency', 'open_circuit_voltage', 'fill_factor', \n",
    "                'short_circuit_current_density', 'series_resistance', 'shunt_resistance']\n",
    "    \n",
    "    # All available parameters\n",
    "    all_params = numeric_cols + categorical_cols + [p for p in jv_params if p in data.columns]\n",
    "    \n",
    "    # Remove non-parameter columns\n",
    "    excluded_cols = ['sample_id', 'name', 'datetime', 'description', 'location', 'variation']\n",
    "    available_params = [col for col in all_params if col not in excluded_cols]\n",
    "    \n",
    "    # Create parameter variation analysis\n",
    "    def analyze_parameter_variations(data, available_params):\n",
    "        \"\"\"Analyzes parameter variations to help users choose optimization parameters\"\"\"\n",
    "        param_variations = {}\n",
    "        \n",
    "        for param in available_params:\n",
    "            if param in data.columns:\n",
    "                # Handle list-type parameters (JV params)\n",
    "                if param in jv_params and not data.empty:\n",
    "                    if isinstance(data[param].iloc[0], list):\n",
    "                        # For list parameters, calculate variation based on means\n",
    "                        means = data[param].apply(lambda x: np.mean(x) if isinstance(x, list) and len(x) > 0 else np.nan)\n",
    "                        unique_count = len(means.dropna().unique())\n",
    "                        param_range = means.max() - means.min() if not means.isna().all() else 0\n",
    "                        std_dev = means.std() if not means.isna().all() else 0\n",
    "                    else:\n",
    "                        unique_count = len(data[param].dropna().unique())\n",
    "                        param_range = data[param].max() - data[param].min() if data[param].dtype in ['int64', 'float64'] else 0\n",
    "                        std_dev = data[param].std() if data[param].dtype in ['int64', 'float64'] else 0\n",
    "                else:\n",
    "                    unique_count = len(data[param].dropna().unique())\n",
    "                    param_range = data[param].max() - data[param].min() if data[param].dtype in ['int64', 'float64'] else 0\n",
    "                    std_dev = data[param].std() if data[param].dtype in ['int64', 'float64'] else 0\n",
    "                \n",
    "                param_variations[param] = {\n",
    "                    'unique_count': unique_count,\n",
    "                    'range': param_range,\n",
    "                    'std_dev': std_dev,\n",
    "                    'data_type': 'Continuous' if data[param].dtype in ['int64', 'float64'] or param in jv_params else 'Categorical'\n",
    "                }\n",
    "        \n",
    "        return param_variations\n",
    "    \n",
    "    # Analyze parameter variations\n",
    "    param_variations = analyze_parameter_variations(data, available_params)\n",
    "    \n",
    "    # Filter parameters with 4+ variations and sort by variation count\n",
    "    varied_params = {k: v for k, v in param_variations.items() if v['unique_count'] >= 4}\n",
    "    sorted_params = sorted(varied_params.items(), key=lambda x: x[1]['unique_count'], reverse=True)\n",
    "    \n",
    "    # Create parameter recommendations widget (collapsed by default)\n",
    "    recommendations_output = widgets.Output()\n",
    "    \n",
    "    def create_recommendations_content():\n",
    "        \"\"\"Creates the parameter recommendations content\"\"\"\n",
    "        with recommendations_output:\n",
    "            recommendations_output.clear_output(wait=True)\n",
    "            \n",
    "            if not sorted_params:\n",
    "                display(Markdown(\"‚ùå No parameters found with sufficient variation for optimization (need >3 unique values).\"))\n",
    "                return\n",
    "            \n",
    "            display(Markdown(\"### üìä Parameter Variation Analysis\"))\n",
    "            display(Markdown(\"Parameters are ranked by the number of unique values (only showing parameters with 4+ unique values):\"))\n",
    "            \n",
    "            # Create recommendations table\n",
    "            recommendations_data = []\n",
    "            for param, info in sorted_params:\n",
    "                recommendation = \"üü¢ Excellent\" if info['unique_count'] > 10 else \\\n",
    "                               \"üü° Good\" if info['unique_count'] > 5 else \\\n",
    "                               \"üü† Fair\"  # All displayed parameters have at least 4 unique values\n",
    "                \n",
    "                range_info = f\"{info['range']:.3f}\" if info['data_type'] == 'Continuous' and info['range'] > 0 else \"N/A\"\n",
    "                std_info = f\"{info['std_dev']:.3f}\" if info['data_type'] == 'Continuous' and info['std_dev'] > 0 else \"N/A\"\n",
    "                \n",
    "                recommendations_data.append({\n",
    "                    'Parameter': param,\n",
    "                    'Unique Values': info['unique_count'],\n",
    "                    'Type': info['data_type'],\n",
    "                    'Range': range_info,\n",
    "                    'Std Dev': std_info,\n",
    "                    'Recommendation': recommendation\n",
    "                })\n",
    "            \n",
    "            recommendations_df = pd.DataFrame(recommendations_data)\n",
    "            display(recommendations_df)\n",
    "            \n",
    "            # Add interpretation guide\n",
    "            display(Markdown(\"\"\"\n",
    "            ### üéØ How to Use This Analysis:\n",
    "            \n",
    "            **Recommendation Colors:**\n",
    "            - üü¢ **Excellent (>10 unique values):** Perfect for optimization, provides fine-grained control\n",
    "            - üü° **Good (6-10 unique values):** Very suitable for optimization\n",
    "            - üü† **Fair (4-5 unique values):** Usable but limited resolution\n",
    "            \n",
    "            **Note:** Parameters with ‚â§3 unique values are excluded as they provide insufficient variation for effective optimization.\n",
    "            \n",
    "            **Selection Tips:**\n",
    "            - **Start with top-ranked parameters** (highest unique values)\n",
    "            - **Mix continuous and categorical** parameters for comprehensive optimization\n",
    "            - **Consider parameter importance** in your experimental process\n",
    "            - **Begin with 2-5 parameters** and expand as you collect more data\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Show top recommendations\n",
    "            top_params = [param for param, _ in sorted_params[:5]]\n",
    "            display(Markdown(\"### üí° **Top 5 Recommended Parameters:**\"))\n",
    "            for i, param in enumerate(top_params, 1):\n",
    "                info = varied_params[param]\n",
    "                print(f\"{i}. {param} ({info['unique_count']} unique values, {info['data_type']})\")\n",
    "    \n",
    "    # Create toggle button for recommendations\n",
    "    toggle_button = widgets.Button(\n",
    "        description='üìä Show Parameter Recommendations',\n",
    "        button_style='info',\n",
    "        icon='chart-bar',\n",
    "        tooltip='Click to see which parameters are best for optimization'\n",
    "    )\n",
    "    \n",
    "    recommendations_visible = [False]  # Use list to make it mutable in nested function\n",
    "    \n",
    "    def toggle_recommendations(b):\n",
    "        \"\"\"Toggles the recommendations section\"\"\"\n",
    "        if recommendations_visible[0]:\n",
    "            # Hide recommendations\n",
    "            recommendations_output.clear_output()\n",
    "            toggle_button.description = 'üìä Show Parameter Recommendations'\n",
    "            toggle_button.icon = 'chart-bar'\n",
    "            recommendations_visible[0] = False\n",
    "        else:\n",
    "            # Show recommendations\n",
    "            create_recommendations_content()\n",
    "            toggle_button.description = 'üìä Hide Parameter Recommendations'\n",
    "            toggle_button.icon = 'eye-slash'\n",
    "            recommendations_visible[0] = True\n",
    "    \n",
    "    toggle_button.on_click(toggle_recommendations)\n",
    "    \n",
    "    # Container for parameter widgets\n",
    "    parameter_container = widgets.VBox()\n",
    "    \n",
    "    # Target variable selection\n",
    "    target_dropdown = widgets.Dropdown(\n",
    "        options=available_params,\n",
    "        value='efficiency' if 'efficiency' in available_params else available_params[0],\n",
    "        description='Target Variable:',\n",
    "        style={'description_width': '150px'},\n",
    "        layout={'width': '400px'},\n",
    "        tooltip='The variable you want to optimize (maximize)'\n",
    "    )\n",
    "    \n",
    "    # Initial parameter selection - prefer parameters with more variation\n",
    "    initial_params = [param for param, _ in sorted_params if param != target_dropdown.value][:3]\n",
    "    if len(initial_params) < 3:\n",
    "        # Fill with any available parameters if not enough varied ones\n",
    "        remaining_params = [p for p in available_params if p != target_dropdown.value and p not in initial_params]\n",
    "        initial_params.extend(remaining_params[:3-len(initial_params)])\n",
    "    \n",
    "    # Parameter selection widgets\n",
    "    param_widgets = []\n",
    "    for i in range(3):  # Start with 3 parameters\n",
    "        param_widget = widgets.Dropdown(\n",
    "            options=available_params,\n",
    "            value=initial_params[i] if i < len(initial_params) else available_params[0],\n",
    "            description=f'Parameter {i+1}:',\n",
    "            style={'description_width': '150px'},\n",
    "            layout={'width': '400px'}\n",
    "        )\n",
    "        param_widgets.append(param_widget)\n",
    "    \n",
    "    # Buttons to add/remove parameters\n",
    "    add_param_button = widgets.Button(\n",
    "        description='Add Parameter',\n",
    "        button_style='success',\n",
    "        icon='plus',\n",
    "        tooltip='Add another parameter to optimize'\n",
    "    )\n",
    "    \n",
    "    remove_param_button = widgets.Button(\n",
    "        description='Remove Parameter',\n",
    "        button_style='warning',\n",
    "        icon='minus',\n",
    "        tooltip='Remove the last parameter'\n",
    "    )\n",
    "    \n",
    "    # Analysis button\n",
    "    analyze_button = widgets.Button(\n",
    "        description='Analyze Data for Optimization',\n",
    "        button_style='primary',\n",
    "        icon='chart-line',\n",
    "        tooltip='Analyze selected parameters and prepare for optimization'\n",
    "    )\n",
    "    \n",
    "    # Output for analysis results\n",
    "    analysis_output = widgets.Output()\n",
    "    \n",
    "    def update_parameter_container():\n",
    "        \"\"\"Updates the parameter container with current widgets\"\"\"\n",
    "        param_box = widgets.VBox(param_widgets)\n",
    "        button_box = widgets.HBox([add_param_button, remove_param_button])\n",
    "        parameter_container.children = [param_box, button_box]\n",
    "    \n",
    "    def on_add_parameter(b):\n",
    "        \"\"\"Adds a new parameter widget\"\"\"\n",
    "        if len(param_widgets) < 15:  # Limit to 15 parameters\n",
    "            new_param = widgets.Dropdown(\n",
    "                options=available_params,\n",
    "                value=available_params[0],\n",
    "                description=f'Parameter {len(param_widgets)+1}:',\n",
    "                style={'description_width': '150px'},\n",
    "                layout={'width': '400px'}\n",
    "            )\n",
    "            param_widgets.append(new_param)\n",
    "            update_parameter_container()\n",
    "    \n",
    "    def on_remove_parameter(b):\n",
    "        \"\"\"Removes the last parameter widget\"\"\"\n",
    "        if len(param_widgets) > 1:  # Keep at least 1 parameter\n",
    "            param_widgets.pop()\n",
    "            update_parameter_container()\n",
    "    \n",
    "    # Create explanations toggle for analysis section\n",
    "    analysis_explanations_toggle = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Show detailed analysis explanations',\n",
    "        style={'description_width': 'initial'},\n",
    "        tooltip='Toggle to show/hide detailed explanations in data analysis'\n",
    "    )\n",
    "    \n",
    "    def on_analyze_data(b):\n",
    "        \"\"\"Analyzes the selected parameters for optimization\"\"\"\n",
    "        with analysis_output:\n",
    "            analysis_output.clear_output(wait=True)\n",
    "            \n",
    "            # Get selected parameters\n",
    "            selected_params = [w.value for w in param_widgets]\n",
    "            target_param = target_dropdown.value\n",
    "            \n",
    "            # Check for duplicates\n",
    "            if len(set(selected_params)) != len(selected_params):\n",
    "                print(f\"{warning_sign} ERROR: Duplicate parameters selected!\")\n",
    "                return\n",
    "            \n",
    "            if target_param in selected_params:\n",
    "                print(f\"{warning_sign} ERROR: Target variable cannot be a parameter!\")\n",
    "                return\n",
    "            \n",
    "            # Create analyzer\n",
    "            analyzer = BayesianOptimizationAnalyzer()\n",
    "            \n",
    "            # Prepare optimization data\n",
    "            clean_data, metrics, adequacy = analyzer.prepare_optimization_data(\n",
    "                data, target_param, selected_params\n",
    "            )\n",
    "            \n",
    "            if clean_data is None:\n",
    "                print(f\"{warning_sign} {adequacy}\")\n",
    "                return\n",
    "            \n",
    "            # Display results\n",
    "            display(Markdown(\"## üìä Data Analysis Results\"))\n",
    "            \n",
    "            # Data quality metrics\n",
    "            display(Markdown(\"### Data Quality\"))\n",
    "            display(Markdown(f\"Initial samples: {metrics['initial_samples']}\"))\n",
    "            display(Markdown(f\"Valid samples after cleaning: {metrics['final_valid_samples']}\"))\n",
    "            display(Markdown(f\"Data removal rate: {metrics['removal_rate']:.1%}\"))\n",
    "            display(Markdown(f\"Samples per parameter: {metrics['final_samples_per_parameter']:.1f}\"))\n",
    "            \n",
    "            # Adequacy assessment\n",
    "            adequacy_color = {\n",
    "                'GOOD': 'üü¢',\n",
    "                'ACCEPTABLE': 'üü°', \n",
    "                'CAUTION': 'üü†',\n",
    "                'WARNING': 'üü†',\n",
    "                'CRITICAL': 'üî¥',\n",
    "                'ERROR': 'üî¥'\n",
    "            }\n",
    "            \n",
    "            adequacy_key = adequacy.split(':')[0]\n",
    "            color = adequacy_color.get(adequacy_key, '‚ö™')\n",
    "            \n",
    "            display(Markdown(\"### üéØ Data Adequacy Assessment\"))\n",
    "            display(Markdown(f\"{color} {adequacy}\"))\n",
    "            \n",
    "            # Show detailed explanations based on toggle\n",
    "            if analysis_explanations_toggle.value:\n",
    "                # Add detailed recommendations based on adequacy\n",
    "                if 'GOOD' in adequacy:\n",
    "                    display(Markdown(\"\"\"\n",
    "                    ‚úÖ **Excellent data quality!** You can proceed with confidence using any optimization strategy.\n",
    "                    Recommended approach: Start with 'balanced' strategy for best results.\n",
    "                    \"\"\"))\n",
    "                elif 'ACCEPTABLE' in adequacy:\n",
    "                    display(Markdown(\"\"\"\n",
    "                    ‚úÖ **Good data quality.** Bayesian optimization should work well.\n",
    "                    Recommended approach: Use 'balanced' strategy and monitor convergence carefully.\n",
    "                    \"\"\"))\n",
    "                elif 'CAUTION' in adequacy:\n",
    "                    display(Markdown(\"\"\"\n",
    "                    ‚ö†Ô∏è **Proceed with caution.** Limited data may affect optimization quality.\n",
    "                    Recommended approach: Use 'explorative' strategy and smaller batch sizes.\n",
    "                    \"\"\"))\n",
    "                elif 'WARNING' in adequacy:\n",
    "                    display(Markdown(\"\"\"\n",
    "                    ‚ö†Ô∏è **Data quality concerns.** Consider collecting more data before optimization.\n",
    "                    If proceeding: Use 'explorative' strategy, small batches, and validate results carefully.\n",
    "                    \"\"\"))\n",
    "            \n",
    "            # Convergence budget estimation\n",
    "            if metrics['final_valid_samples'] > 0:\n",
    "                budget = analyzer.estimate_convergence_budget(len(selected_params))\n",
    "                display(Markdown(\"### üìà Estimated Optimization Budget\"))\n",
    "                \n",
    "                if analysis_explanations_toggle.value:\n",
    "                    budget_explanation = f\"\"\"\n",
    "                    Based on {len(selected_params)} parameters and {metrics['final_valid_samples']} samples:\n",
    "                    \n",
    "                    - **Exploration Phase:** {budget['phase_breakdown']['exploration_phase']} iterations\n",
    "                      - Initial parameter space mapping\n",
    "                      - Identify promising regions\n",
    "                      \n",
    "                    - **Exploitation Phase:** {budget['phase_breakdown']['exploitation_phase']} iterations  \n",
    "                      - Focus on best regions\n",
    "                      - Fine-tune optimal parameters\n",
    "                      \n",
    "                    - **Convergence Buffer:** {budget['phase_breakdown']['convergence_buffer']} iterations\n",
    "                      - Ensure robust convergence\n",
    "                      - Validation experiments\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    display(Markdown(budget_explanation))\n",
    "                \n",
    "                display(Markdown(f\"üí° **Recommended total budget:** {budget['recommended_budget']} iterations\"))\n",
    "                display(Markdown(f\"‚ö° **Minimum effective budget:** {budget['minimum_budget']} iterations\"))\n",
    "                display(Markdown(f\"üîù **Maximum useful budget:** {budget['maximum_useful']} iterations\"))\n",
    "                \n",
    "                if analysis_explanations_toggle.value:\n",
    "                    # Cost estimation\n",
    "                    display(Markdown(\"### üí∞ Resource Planning\"))\n",
    "                    cost_per_exp = 2  # Assume 2 hours per experiment\n",
    "                    total_cost = budget['recommended_budget'] * cost_per_exp\n",
    "                    \n",
    "                    display(Markdown(f\"\"\"\n",
    "                    **Estimated Resource Requirements:**\n",
    "                    - Time per experiment: ~{cost_per_exp} hours\n",
    "                    - Total optimization time: ~{total_cost} hours\n",
    "                    - Recommended batch size: {min(max(3, metrics['final_valid_samples'] // 20), 10)} experiments\n",
    "                    - Number of optimization rounds: ~{budget['recommended_budget'] // min(max(3, metrics['final_valid_samples'] // 20), 10)}\n",
    "                    \"\"\"))\n",
    "            \n",
    "            # Parameter statistics\n",
    "            display(Markdown(\"### üìä Parameter Statistics\"))\n",
    "            param_stats = clean_data[selected_params].describe()\n",
    "            display(param_stats)\n",
    "            \n",
    "            if analysis_explanations_toggle.value:\n",
    "                # Show parameter ranges and types\n",
    "                display(Markdown(\"### üéöÔ∏è Parameter Ranges\"))\n",
    "                for param in selected_params:\n",
    "                    param_type = \"Continuous\" if clean_data[param].dtype in ['float64', 'int64'] else \"Categorical\"\n",
    "                    if param_type == \"Continuous\":\n",
    "                        param_range = f\"{clean_data[param].min():.3f} to {clean_data[param].max():.3f}\"\n",
    "                    else:\n",
    "                        param_range = f\"{len(clean_data[param].unique())} categories: {list(clean_data[param].unique())}\"\n",
    "                    display(Markdown(f\"‚Ä¢ **{param}** ({param_type}): {param_range}\"))\n",
    "            \n",
    "            # Target variable statistics\n",
    "            display(Markdown(f\"### üéØ Target Variable Statistics ({target_param})\"))\n",
    "            target_stats = clean_data[target_param].describe()\n",
    "            display(target_stats)\n",
    "            \n",
    "            if analysis_explanations_toggle.value:\n",
    "                # Show target variable distribution info\n",
    "                target_range = clean_data[target_param].max() - clean_data[target_param].min()\n",
    "                target_std = clean_data[target_param].std()\n",
    "                display(Markdown(f\"üìà **Range:** {target_range:.3f}\"))\n",
    "                display(Markdown(f\"üìä **Standard Deviation:** {target_std:.3f}\"))\n",
    "                display(Markdown(f\"üéØ **Optimization Goal:** Maximize {target_param}\"))\n",
    "                \n",
    "                # Show correlations\n",
    "                display(Markdown(\"### üîó Parameter Correlations\"))\n",
    "                correlation_matrix = clean_data[selected_params + [target_param]].corr()\n",
    "                \n",
    "                # Find strongest correlations with target\n",
    "                target_corr = correlation_matrix[target_param].abs().sort_values(ascending=False)[1:]  # Exclude self-correlation\n",
    "                \n",
    "                display(Markdown(\"**Strongest correlations with target variable:**\"))\n",
    "                for param, corr in target_corr.head(3).items():\n",
    "                    strength = \"Strong\" if corr > 0.7 else \"Moderate\" if corr > 0.4 else \"Weak\"\n",
    "                    display(Markdown(f\"‚Ä¢ **{param}**: {corr:.3f} ({strength})\"))\n",
    "                \n",
    "                if target_corr.max() < 0.3:\n",
    "                    display(Markdown(\"‚ö†Ô∏è **Note:** Low correlations detected. This suggests complex, non-linear relationships that Bayesian optimization can help uncover.\"))\n",
    "            \n",
    "            # Store results globally for optimization\n",
    "            global current_analyzer, optimization_ready\n",
    "            current_analyzer = analyzer\n",
    "            current_analyzer.clean_data = clean_data\n",
    "            current_analyzer.parameter_columns = selected_params\n",
    "            current_analyzer.target_column = target_param\n",
    "            current_analyzer.data_metrics = metrics\n",
    "            current_analyzer.adequacy_status = adequacy\n",
    "            \n",
    "            # Create optimization space\n",
    "            current_analyzer.optimization_space = analyzer.create_optimization_space(\n",
    "                clean_data, selected_params\n",
    "            )\n",
    "            \n",
    "            optimization_ready = True\n",
    "            \n",
    "            # Show optimization interface if data is adequate\n",
    "            if 'CRITICAL' not in adequacy and 'ERROR' not in adequacy:\n",
    "                display(Markdown(\"---\"))\n",
    "                display(create_optimization_interface())\n",
    "            else:\n",
    "                display(Markdown(\"### ‚ö†Ô∏è Optimization Not Recommended\"))\n",
    "                display(Markdown(\"Please collect more data or select fewer parameters before proceeding.\"))\n",
    "    \n",
    "    # Connect event handlers\n",
    "    add_param_button.on_click(on_add_parameter)\n",
    "    remove_param_button.on_click(on_remove_parameter)\n",
    "    analyze_button.on_click(on_analyze_data)\n",
    "    \n",
    "    # Initialize parameter container\n",
    "    update_parameter_container()\n",
    "    \n",
    "    # Create main layout\n",
    "    main_layout = widgets.VBox([\n",
    "        widgets.HTML(\"\"\"\n",
    "        <div style='background-color: #f0f8ff; padding: 20px; border-radius: 10px; margin-bottom: 20px;'>\n",
    "            <h2>üéØ Bayesian Optimization Setup</h2>\n",
    "            <p><strong>What is Bayesian Optimization?</strong></p>\n",
    "            <p>Bayesian optimization is an intelligent approach to finding optimal experimental parameters. \n",
    "            Unlike random testing, it learns from each experiment to suggest the most promising parameters \n",
    "            for your next tests.</p>\n",
    "            \n",
    "            <p><strong>How it works:</strong></p>\n",
    "            <ol>\n",
    "                <li><strong>Learn:</strong> Analyzes your existing experimental data</li>\n",
    "                <li><strong>Predict:</strong> Builds a model of how parameters affect your target variable</li>\n",
    "                <li><strong>Optimize:</strong> Suggests new experiments most likely to improve results</li>\n",
    "                <li><strong>Adapt:</strong> Updates predictions based on new experimental results</li>\n",
    "            </ol>\n",
    "            \n",
    "            <p><strong>Benefits:</strong></p>\n",
    "            <ul>\n",
    "                <li>üéØ <strong>Efficient:</strong> Finds optimal parameters with fewer experiments</li>\n",
    "                <li>üìä <strong>Smart:</strong> Balances exploration of new regions with exploitation of promising areas</li>\n",
    "                <li>üîÑ <strong>Adaptive:</strong> Improves suggestions as you collect more data</li>\n",
    "                <li>üí° <strong>Insightful:</strong> Reveals complex relationships between parameters</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"),\n",
    "        \n",
    "        widgets.HTML(\"\"\"\n",
    "        <h3>Step 1: Select Variables</h3>\n",
    "        <p>Choose the target variable you want to optimize (maximize) and the parameters you want to vary:</p>\n",
    "        \"\"\"),\n",
    "        \n",
    "        widgets.HTML(\"\"\"\n",
    "        <div style='background-color: #fff3e0; padding: 15px; border-radius: 8px; margin-bottom: 15px;'>\n",
    "            <h4>üí° Selection Tips:</h4>\n",
    "            <ul>\n",
    "                <li><strong>Target Variable:</strong> Choose the most important outcome (e.g., efficiency, performance)</li>\n",
    "                <li><strong>Parameters:</strong> Select variables you can control in experiments</li>\n",
    "                <li><strong>Parameter Count:</strong> Start with 2-5 parameters, add more as you collect data</li>\n",
    "                <li><strong>Data Quality:</strong> Ensure parameters have meaningful variation in your dataset</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"),\n",
    "        \n",
    "        target_dropdown,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        toggle_button,\n",
    "        recommendations_output,\n",
    "        widgets.HTML(\"<br><b>Optimization Parameters:</b>\"),\n",
    "        widgets.HTML(\"\"\"\n",
    "        <p><em>Add/remove parameters dynamically. Start with the most important ones.</em></p>\n",
    "        \"\"\"),\n",
    "        parameter_container,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        analysis_explanations_toggle,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        analyze_button,\n",
    "        analysis_output\n",
    "    ])\n",
    "    \n",
    "    return main_layout\n",
    "\n",
    "\n",
    "def create_optimization_interface():\n",
    "    \"\"\"Creates the optimization interface\"\"\"\n",
    "    if not BAYESIAN_AVAILABLE:\n",
    "        return widgets.HTML(\"\"\"\n",
    "        <div style='color: red; font-weight: bold;'>\n",
    "        ‚ö†Ô∏è Bayesian optimization libraries not available. \n",
    "        Please install: pip install scikit-optimize\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    \n",
    "    # Get metrics for recommendations\n",
    "    n_samples = current_analyzer.data_metrics['final_valid_samples']\n",
    "    n_params = len(current_analyzer.parameter_columns)\n",
    "    max_iterations = current_analyzer.estimate_convergence_budget(n_params)\n",
    "    \n",
    "    # Batch size recommendations\n",
    "    recommended_batch = min(max(3, n_samples // 20), 10)  # 3-10 based on data size\n",
    "    \n",
    "    # Optimization strategy selection\n",
    "    strategy_dropdown = widgets.Dropdown(\n",
    "        options=['balanced', 'explorative', 'exploitative'],\n",
    "        value='balanced',\n",
    "        description='Strategy:',\n",
    "        style={'description_width': '150px'},\n",
    "        layout={'width': '300px'}\n",
    "    )\n",
    "    \n",
    "    # Batch size selection\n",
    "    batch_size = widgets.IntSlider(\n",
    "        min=1,\n",
    "        max=min(20, max(5, n_samples // 5)),\n",
    "        value=recommended_batch,\n",
    "        description='Batch Size:',\n",
    "        style={'description_width': '150px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    # Number of iterations\n",
    "    iterations_slider = widgets.IntSlider(\n",
    "        min=max_iterations['minimum_budget'],\n",
    "        max=max_iterations['maximum_useful'],\n",
    "        value=max_iterations['recommended_budget'],\n",
    "        description='Max Iterations:',\n",
    "        style={'description_width': '150px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    # Create explanations toggle functionality\n",
    "    def create_explanations_toggle():\n",
    "        \"\"\"Creates checkbox to toggle detailed explanations\"\"\"\n",
    "        show_explanations = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Show detailed explanations',\n",
    "            style={'description_width': 'initial'},\n",
    "            tooltip='Toggle to show/hide detailed explanations and tips'\n",
    "        )\n",
    "        \n",
    "        def toggle_explanations(change):\n",
    "            \"\"\"Toggles visibility of explanation sections\"\"\"\n",
    "            show = change['new']\n",
    "            \n",
    "            # Update all conditional explanation widgets\n",
    "            conditional_strategy_info.layout.display = 'block' if show else 'none'\n",
    "            conditional_batch_info.layout.display = 'block' if show else 'none'\n",
    "            conditional_iterations_info.layout.display = 'block' if show else 'none'\n",
    "            conditional_advanced_options.layout.display = 'block' if show else 'none'\n",
    "        \n",
    "        show_explanations.observe(toggle_explanations, names='value')\n",
    "        return show_explanations\n",
    "    \n",
    "    # Create conditional explanation widgets (hidden by default)\n",
    "    conditional_strategy_info = widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 15px;'>\n",
    "        <h4>üéØ Optimization Strategies</h4>\n",
    "        <ul>\n",
    "            <li><strong>Balanced (Recommended):</strong> Uses Expected Improvement (EI) acquisition function. \n",
    "                Balances exploration of unknown regions with exploitation of promising areas. \n",
    "                Best for most experimental scenarios.</li>\n",
    "            <li><strong>Explorative:</strong> Uses Upper Confidence Bound (UCB) with high exploration parameter. \n",
    "                Prioritizes exploring the entire parameter space. Good when you suspect multiple optima \n",
    "                or have limited prior knowledge.</li>\n",
    "            <li><strong>Exploitative:</strong> Uses Probability of Improvement (PI) acquisition function. \n",
    "                Focuses on refining around the best known regions. Use when you're confident about \n",
    "                the general location of the optimum.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    conditional_strategy_info.layout.display = 'none'  # Hidden by default\n",
    "    \n",
    "    conditional_batch_info = widgets.HTML(f\"\"\"\n",
    "    <div style='background-color: #e8f5e8; padding: 12px; border-radius: 6px; margin-bottom: 10px;'>\n",
    "        <h4>üìä Batch Size Recommendations</h4>\n",
    "        <p><strong>Recommended for your data: {recommended_batch} experiments</strong></p>\n",
    "        <ul>\n",
    "            <li><strong>Small batches (1-3):</strong> More sequential learning, better for expensive experiments</li>\n",
    "            <li><strong>Medium batches (4-8):</strong> Good balance of efficiency and learning (recommended)</li>\n",
    "            <li><strong>Large batches (9+):</strong> Faster screening, but less adaptive learning</li>\n",
    "        </ul>\n",
    "        <p><em>Rule of thumb: Use ~5% of your total samples as batch size, minimum 3, maximum 10.</em></p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    conditional_batch_info.layout.display = 'none'  # Hidden by default\n",
    "    \n",
    "    conditional_iterations_info = widgets.HTML(f\"\"\"\n",
    "    <div style='background-color: #fff3e0; padding: 12px; border-radius: 6px; margin-bottom: 10px;'>\n",
    "        <h4>üîÑ Iteration Budget Guidelines</h4>\n",
    "        <p><strong>For {n_params} parameters:</strong></p>\n",
    "        <ul>\n",
    "            <li><strong>Minimum effective:</strong> {max_iterations['minimum_budget']} iterations \n",
    "                (basic parameter space coverage)</li>\n",
    "            <li><strong>Recommended:</strong> {max_iterations['recommended_budget']} iterations \n",
    "                (good balance of exploration and convergence)</li>\n",
    "            <li><strong>Maximum useful:</strong> {max_iterations['maximum_useful']} iterations \n",
    "                (diminishing returns beyond this point)</li>\n",
    "        </ul>\n",
    "        <p><em>Remember: You can always run optimization in stages and evaluate progress!</em></p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    conditional_iterations_info.layout.display = 'none'  # Hidden by default\n",
    "    \n",
    "    conditional_advanced_options = widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #f0f8ff; padding: 12px; border-radius: 6px; margin-bottom: 15px;'>\n",
    "        <h4>‚öôÔ∏è Advanced Tips</h4>\n",
    "        <ul>\n",
    "            <li><strong>Start Conservative:</strong> Begin with fewer iterations and expand based on results</li>\n",
    "            <li><strong>Resource Planning:</strong> Each iteration = batch_size √ó experimental_cost</li>\n",
    "            <li><strong>Stopping Criteria:</strong> Monitor improvement rate - stop if no significant gains</li>\n",
    "            <li><strong>Validation:</strong> Reserve 10-20% of suggested experiments for validation</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    conditional_advanced_options.layout.display = 'none'  # Hidden by default\n",
    "    \n",
    "    # Optimization button\n",
    "    optimize_button = widgets.Button(\n",
    "        description='üöÄ Generate Experiment Suggestions',\n",
    "        button_style='primary',\n",
    "        icon='flask',\n",
    "        tooltip='Generate optimized experimental design based on your settings',\n",
    "        layout={'width': '300px', 'height': '40px'}\n",
    "    )\n",
    "    \n",
    "    # Results output\n",
    "    optimization_output = widgets.Output()\n",
    "    \n",
    "    def on_optimize_clicked(b):\n",
    "        \"\"\"Handles optimization button click\"\"\"\n",
    "        with optimization_output:\n",
    "            optimization_output.clear_output(wait=True)\n",
    "            \n",
    "            display(Markdown(\"# üß™ Experimental Design Generation\"))\n",
    "            \n",
    "            # Display selected configuration\n",
    "            display(Markdown(\"## üìã Configuration Summary\"))\n",
    "            config_summary = f\"\"\"\n",
    "            - **Strategy:** {strategy_dropdown.value.title()}\n",
    "            - **Batch Size:** {batch_size.value} experiments\n",
    "            - **Max Iterations:** {iterations_slider.value}\n",
    "            - **Total Experimental Budget:** {batch_size.value * iterations_slider.value} experiments\n",
    "            - **Data Quality:** {current_analyzer.adequacy_status}\n",
    "            \"\"\"\n",
    "            display(Markdown(config_summary))\n",
    "            \n",
    "            # Show progress\n",
    "            display(Markdown(\"## üîÑ Generating Suggestions...\"))\n",
    "            display(Markdown(\"Initializing Bayesian optimization...\"))\n",
    "            \n",
    "            try:\n",
    "                # Prepare data for optimization\n",
    "                X = current_analyzer.clean_data[current_analyzer.parameter_columns].values\n",
    "                y = current_analyzer.clean_data[current_analyzer.target_column].values\n",
    "                \n",
    "                display(Markdown(f\"Training on {len(X)} samples with {len(current_analyzer.parameter_columns)} parameters\"))\n",
    "                display(Markdown(f\"Target variable range: {y.min():.3f} to {y.max():.3f}\"))\n",
    "                \n",
    "                # Generate suggestions using Bayesian optimization\n",
    "                suggestions = generate_experiment_suggestions(\n",
    "                    current_analyzer.optimization_space, \n",
    "                    X, \n",
    "                    y, \n",
    "                    batch_size.value, \n",
    "                    strategy_dropdown.value\n",
    "                )\n",
    "                \n",
    "                # Find single optimum\n",
    "                optimal_params, predicted_performance = find_single_optimum(\n",
    "                    current_analyzer.optimization_space,\n",
    "                    X,\n",
    "                    y,\n",
    "                    strategy_dropdown.value\n",
    "                )\n",
    "                \n",
    "                display(Markdown(\"‚úÖ Optimization complete!\"))\n",
    "                \n",
    "                # Display results\n",
    "                display_experiment_suggestions(suggestions, strategy_dropdown.value)\n",
    "                \n",
    "                # Display single optimum\n",
    "                display_single_optimum(optimal_params, predicted_performance)\n",
    "                \n",
    "            except Exception as e:\n",
    "                display(Markdown(f\"‚ùå Error during optimization: {str(e)}\"))\n",
    "                display(Markdown(\"\"\"\n",
    "                ### Troubleshooting Tips:\n",
    "                - Check that all selected parameters have valid numeric ranges\n",
    "                - Ensure target variable has sufficient variation\n",
    "                - Try reducing the number of parameters if you have limited data\n",
    "                \"\"\"))\n",
    "    \n",
    "    optimize_button.on_click(on_optimize_clicked)\n",
    "    \n",
    "    # Create interface layout\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>‚öôÔ∏è Optimization Configuration</h3>\"),\n",
    "        \n",
    "        # Add explanations toggle\n",
    "        widgets.HTML(\"<div style='margin-bottom: 15px;'>\"),\n",
    "        create_explanations_toggle(),\n",
    "        widgets.HTML(\"</div>\"),\n",
    "        \n",
    "        # Conditional strategy info\n",
    "        conditional_strategy_info,\n",
    "        widgets.HTML(\"<h4>Select Strategy:</h4>\"),\n",
    "        strategy_dropdown,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        \n",
    "        # Conditional batch info\n",
    "        conditional_batch_info,\n",
    "        widgets.HTML(\"<h4>Configure Batch Size:</h4>\"),\n",
    "        batch_size,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        \n",
    "        # Conditional iterations info\n",
    "        conditional_iterations_info,\n",
    "        widgets.HTML(\"<h4>Set Iteration Budget:</h4>\"),\n",
    "        iterations_slider,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        \n",
    "        # Conditional advanced options\n",
    "        conditional_advanced_options,\n",
    "        optimize_button\n",
    "    ])\n",
    "    \n",
    "    return widgets.VBox([controls, optimization_output])\n",
    "\n",
    "\n",
    "def find_single_optimum(space, X, y, strategy='balanced'):\n",
    "    \"\"\"Finds single optimal parameter set using Bayesian optimization\"\"\"\n",
    "    from skopt import gp_minimize\n",
    "    from skopt.utils import use_named_args\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    # Use same prediction method as batch optimization\n",
    "    nn_model = NearestNeighbors(n_neighbors=min(5, len(X)), metric='euclidean')\n",
    "    nn_model.fit(X)\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        param_array = np.array([params[dim.name] for dim in space]).reshape(1, -1)\n",
    "        distances, indices = nn_model.kneighbors(param_array)\n",
    "        weights = 1 / (distances[0] + 1e-6)\n",
    "        weights = weights / weights.sum()\n",
    "        predicted_performance = np.average(y[indices[0]], weights=weights)\n",
    "        return -predicted_performance\n",
    "    \n",
    "    # Configure acquisition function\n",
    "    acq_func_map = {\n",
    "        'balanced': 'EI',\n",
    "        'explorative': 'UCB',\n",
    "        'exploitative': 'PI'\n",
    "    }\n",
    "    \n",
    "    # Run optimization\n",
    "    result = gp_minimize(\n",
    "        func=objective,\n",
    "        dimensions=space,\n",
    "        n_calls=50,\n",
    "        n_initial_points=min(10, len(X)),\n",
    "        acq_func=acq_func_map.get(strategy, 'EI'),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Return best parameters\n",
    "    optimal_params = dict(zip([dim.name for dim in space], result.x))\n",
    "    predicted_performance = -result.fun\n",
    "    \n",
    "    return optimal_params, predicted_performance\n",
    "\n",
    "\n",
    "def generate_experiment_suggestions(space, X, y, batch_size, strategy):\n",
    "    \"\"\"Generates experiment suggestions using Bayesian optimization\"\"\"\n",
    "    from skopt import gp_minimize\n",
    "    from skopt.utils import use_named_args\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    # Create a more sophisticated objective function based on existing data\n",
    "    # Using k-nearest neighbors to predict performance of new parameter combinations\n",
    "    nn_model = NearestNeighbors(n_neighbors=min(5, len(X)), metric='euclidean')\n",
    "    nn_model.fit(X)\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        # Convert parameters to array\n",
    "        param_array = np.array([params[dim.name] for dim in space]).reshape(1, -1)\n",
    "        \n",
    "        # Find nearest neighbors and predict performance\n",
    "        distances, indices = nn_model.kneighbors(param_array)\n",
    "        \n",
    "        # Weight by inverse distance (closer neighbors have more influence)\n",
    "        weights = 1 / (distances[0] + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # Predict performance as weighted average of neighbors\n",
    "        predicted_performance = np.average(y[indices[0]], weights=weights)\n",
    "        \n",
    "        # Return negative because skopt minimizes\n",
    "        return -predicted_performance\n",
    "    \n",
    "    # Configure acquisition function based on strategy\n",
    "    acq_func_map = {\n",
    "        'balanced': 'EI',      # Expected Improvement\n",
    "        'explorative': 'UCB',   # Upper Confidence Bound  \n",
    "        'exploitative': 'PI'    # Probability of Improvement\n",
    "    }\n",
    "    \n",
    "    acq_func = acq_func_map.get(strategy, 'EI')\n",
    "    \n",
    "    # Run optimization to get suggestions\n",
    "    n_calls = min(batch_size * 3, 50)  # Generate more points to select diverse batch\n",
    "    \n",
    "    result = gp_minimize(\n",
    "        func=objective,\n",
    "        dimensions=space,\n",
    "        n_calls=n_calls,\n",
    "        n_initial_points=min(10, len(X)),\n",
    "        acq_func=acq_func,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Select diverse batch from results\n",
    "    suggestions = []\n",
    "    selected_points = []\n",
    "    \n",
    "    # Sort by performance (best first)\n",
    "    sorted_indices = np.argsort(result.func_vals)\n",
    "    \n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        if len(suggestions) >= batch_size:\n",
    "            break\n",
    "            \n",
    "        params = result.x_iters[idx]\n",
    "        \n",
    "        # Check diversity (avoid points too close to already selected ones)\n",
    "        if selected_points:\n",
    "            min_distance = min([np.linalg.norm(np.array(params) - np.array(sp)) \n",
    "                               for sp in selected_points])\n",
    "            if min_distance < 0.1:  # Skip if too close to existing point\n",
    "                continue\n",
    "        \n",
    "        selected_points.append(params)\n",
    "        \n",
    "        # Calculate confidence based on model uncertainty\n",
    "        confidence_score = abs(result.func_vals[idx])\n",
    "        if confidence_score > np.percentile(result.func_vals, 75):\n",
    "            confidence = 'High'\n",
    "        elif confidence_score > np.percentile(result.func_vals, 50):\n",
    "            confidence = 'Medium'\n",
    "        else:\n",
    "            confidence = 'Low'\n",
    "        \n",
    "        suggestion = {\n",
    "            'experiment_id': f'exp_{len(suggestions)+1:03d}',\n",
    "            'parameters': dict(zip([dim.name for dim in space], params)),\n",
    "            'expected_improvement': abs(result.func_vals[idx]),\n",
    "            'confidence': confidence,\n",
    "            'priority': len(suggestions) + 1\n",
    "        }\n",
    "        suggestions.append(suggestion)\n",
    "    \n",
    "    return suggestions\n",
    "\n",
    "\n",
    "def display_experiment_suggestions(suggestions, strategy):\n",
    "    \"\"\"Displays experiment suggestions in a user-friendly format\"\"\"\n",
    "    # Create DataFrame for display\n",
    "    exp_data = []\n",
    "    for exp in suggestions:\n",
    "        row = {\n",
    "            'Experiment_ID': exp['experiment_id'],\n",
    "            'Priority': exp['priority'],\n",
    "            'Expected_Improvement': f\"{exp['expected_improvement']:.4f}\",\n",
    "            'Confidence': exp.get('confidence', 'Medium'),\n",
    "            **exp['parameters']\n",
    "        }\n",
    "        exp_data.append(row)\n",
    "    \n",
    "    df_suggestions = pd.DataFrame(exp_data)\n",
    "    \n",
    "    # Create results explanations toggle\n",
    "    results_explanations_toggle = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Show detailed results explanations',\n",
    "        style={'description_width': 'initial'},\n",
    "        tooltip='Toggle to show/hide detailed explanations for optimization results'\n",
    "    )\n",
    "    \n",
    "    results_explanations_output = widgets.Output()\n",
    "    \n",
    "    def toggle_results_explanations(change):\n",
    "        \"\"\"Toggles detailed results explanations\"\"\"\n",
    "        with results_explanations_output:\n",
    "            results_explanations_output.clear_output(wait=True)\n",
    "            \n",
    "            if change['new']:  # Show explanations\n",
    "                # Display strategy explanation\n",
    "                strategy_explanations = {\n",
    "                    'balanced': \"Using Expected Improvement (EI) - balancing exploration and exploitation\",\n",
    "                    'explorative': \"Using Upper Confidence Bound (UCB) - focusing on unexplored regions\",\n",
    "                    'exploitative': \"Using Probability of Improvement (PI) - focusing on promising areas\"\n",
    "                }\n",
    "                \n",
    "                display(Markdown(f\"**Strategy Applied:** {strategy_explanations[strategy]}\"))\n",
    "                \n",
    "                # Add interpretation guide\n",
    "                display(Markdown(\"\"\"\n",
    "                ### üìñ How to Interpret Results:\n",
    "                \n",
    "                **Priority:** Lower numbers = higher priority. Run experiments in this order for best results.\n",
    "                \n",
    "                **Expected Improvement:** Higher values indicate experiments more likely to improve your target variable.\n",
    "                \n",
    "                **Parameter Values:** Specific settings for each experiment. These are optimized based on your historical data.\n",
    "                \n",
    "                **Confidence Levels:**\n",
    "                - **High:** Strong evidence this experiment will be valuable\n",
    "                - **Medium:** Moderate confidence based on available data  \n",
    "                - **Low:** Exploratory experiment in uncertain regions\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Success probability estimates\n",
    "                display(Markdown(\"### üéØ Success Predictions\"))\n",
    "                high_priority = len([exp for exp in suggestions if exp['priority'] <= 3])\n",
    "                success_estimate = min(80, max(30, 60 + (current_analyzer.data_metrics['samples_per_parameter'] * 2)))\n",
    "                \n",
    "                display(Markdown(f\"\"\"\n",
    "                - **High Priority Experiments (Top 3):** ~{success_estimate}% chance of improvement\n",
    "                - **Medium Priority Experiments:** ~{success_estimate-15}% chance of improvement  \n",
    "                - **Lower Priority Experiments:** ~{success_estimate-30}% chance of improvement\n",
    "                \n",
    "                *Success rates estimated based on your data quality and historical performance*\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Resource planning\n",
    "                display(Markdown(\"### üìä Resource Planning\"))\n",
    "                total_experiments = len(suggestions)\n",
    "                estimated_time = total_experiments * 2  # Assume 2 hours per experiment\n",
    "                \n",
    "                display(Markdown(f\"\"\"\n",
    "                **Current Batch:** {total_experiments} experiments  \n",
    "                **Estimated Time:** ~{estimated_time} hours (assuming 2h per experiment)  \n",
    "                **Material Requirements:** Plan reagents for {total_experiments} samples plus 10% buffer  \n",
    "                **Documentation:** Prepare {total_experiments} experiment sheets with parameter settings  \n",
    "                \"\"\"))\n",
    "                \n",
    "                # Add workflow guidance\n",
    "                display(Markdown(\"\"\"\n",
    "                ### üîÑ Recommended Workflow\n",
    "                1. **Start with high-priority experiments** (Priority 1-3) to get quick wins\n",
    "                2. **Record all results** including failed experiments (crucial for learning!)\n",
    "                3. **Update your dataset** with new experimental results\n",
    "                4. **Re-run optimization** after every 3-5 experiments for adaptive learning\n",
    "                5. **Monitor convergence** - stop when improvements become minimal\n",
    "                \n",
    "                ### ‚ö†Ô∏è Important Notes\n",
    "                - Don't skip experiments - each one provides valuable information\n",
    "                - Document experimental conditions carefully\n",
    "                - Consider running duplicate experiments for validation\n",
    "                - Update the optimization model regularly as you collect more data\n",
    "                \"\"\"))\n",
    "    \n",
    "    results_explanations_toggle.observe(toggle_results_explanations, names='value')\n",
    "    \n",
    "    # Display main results\n",
    "    display(Markdown(\"## üìä Optimization Results\"))\n",
    "    \n",
    "    # Display suggestions table\n",
    "    display(Markdown(\"### üìã Suggested Experiments (In Order of Priority)\"))\n",
    "    display(df_suggestions)\n",
    "    \n",
    "    # Display toggle and explanations\n",
    "    display(results_explanations_toggle)\n",
    "    display(results_explanations_output)\n",
    "    \n",
    "    # Add download link functionality\n",
    "    display(Markdown(\"### üíæ Export and Next Steps\"))\n",
    "    display(widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #e8f5e8; padding: 15px; border-radius: 8px;'>\n",
    "        <h4>üìÅ Export Options</h4>\n",
    "        <p>Copy the table above to your experimental protocol or save as CSV for further analysis.</p>\n",
    "        \n",
    "        <h4>üî¨ Quick Start Guide</h4>\n",
    "        <ol>\n",
    "            <li><strong>Copy parameter values</strong> from the table above</li>\n",
    "            <li><strong>Set up experiments</strong> using the exact parameter combinations</li>\n",
    "            <li><strong>Run experiments in priority order</strong> for best results</li>\n",
    "            <li><strong>Record all outcomes</strong> and add to your dataset</li>\n",
    "            <li><strong>Return for next batch</strong> after completing 3-5 experiments</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "\n",
    "def display_single_optimum(optimal_params, predicted_performance):\n",
    "    \"\"\"Displays the single optimal parameter set\"\"\"\n",
    "    display(Markdown(\"## üéØ Single Optimal Parameter Set\"))\n",
    "    \n",
    "    # Create single optimum explanations toggle\n",
    "    single_optimum_explanations_toggle = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Show single optimum explanations',\n",
    "        style={'description_width': 'initial'},\n",
    "        tooltip='Toggle to show/hide detailed explanations for single optimum approach'\n",
    "    )\n",
    "    \n",
    "    single_optimum_explanations_output = widgets.Output()\n",
    "    \n",
    "    def toggle_single_optimum_explanations(change):\n",
    "        \"\"\"Toggles single optimum explanations\"\"\"\n",
    "        with single_optimum_explanations_output:\n",
    "            single_optimum_explanations_output.clear_output(wait=True)\n",
    "            \n",
    "            if change['new']:  # Show explanations\n",
    "                display(Markdown(\"\"\"\n",
    "                ### üî¨ How to Use This Result:\n",
    "                \n",
    "                **Traditional Bayesian Optimization Approach:**\n",
    "                - Use these exact parameter values for your next experiment\n",
    "                - This represents the algorithm's best guess for optimal performance\n",
    "                - Run this experiment and add the result to your dataset\n",
    "                - Re-run optimization to get the next optimal point\n",
    "                \n",
    "                **Comparison with Batch Approach:**\n",
    "                - **Single Optimum:** Conservative, sequential approach\n",
    "                - **Batch Suggestions:** Efficient, parallel approach for faster learning\n",
    "                - **Recommendation:** Use batch approach for faster optimization, single optimum for validation\n",
    "                \n",
    "                ### üéØ When to Use Single Optimum:\n",
    "                - **Limited resources:** When you can only run one experiment at a time\n",
    "                - **High-cost experiments:** When each experiment is expensive\n",
    "                - **Validation:** To confirm batch optimization results\n",
    "                - **Conservative approach:** When you want to minimize experimental risk\n",
    "                \"\"\"))\n",
    "    \n",
    "    single_optimum_explanations_toggle.observe(toggle_single_optimum_explanations, names='value')\n",
    "    \n",
    "    display(Markdown(f\"\"\"\n",
    "    **Predicted Performance:** {predicted_performance:.4f}\n",
    "    \n",
    "    This represents the single best parameter combination based on Bayesian optimization analysis.\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Create optimal parameters table\n",
    "    optimal_data = []\n",
    "    for param, value in optimal_params.items():\n",
    "        # Format value based on type\n",
    "        if isinstance(value, float):\n",
    "            formatted_value = f\"{value:.4f}\"\n",
    "        elif isinstance(value, int):\n",
    "            formatted_value = str(value)\n",
    "        else:\n",
    "            formatted_value = str(value)\n",
    "        \n",
    "        optimal_data.append({\n",
    "            'Parameter': param,\n",
    "            'Optimal Value': formatted_value\n",
    "        })\n",
    "    \n",
    "    optimal_df = pd.DataFrame(optimal_data)\n",
    "    display(optimal_df)\n",
    "    \n",
    "    # Display toggle and explanations\n",
    "    display(single_optimum_explanations_toggle)\n",
    "    display(single_optimum_explanations_output)\n",
    "    \n",
    "    # Add copy-friendly format\n",
    "    display(Markdown(\"### üìã Copy-Friendly Format:\"))\n",
    "    copy_text = \", \".join([f\"{param}={value:.4f}\" if isinstance(value, float) else f\"{param}={value}\" \n",
    "                          for param, value in optimal_params.items()])\n",
    "    display(widgets.HTML(f\"<code>{copy_text}</code>\"))\n",
    "\n",
    "\n",
    "def on_load_data_clicked(batch_ids_selector):\n",
    "    \"\"\"Handles data loading with optimization preparation\"\"\"\n",
    "    global data, original_data, optimization_ready\n",
    "    dynamic_content.clear_output()\n",
    "    \n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print(\"Loading Data...\")\n",
    "        \n",
    "        try:\n",
    "            # Load data (your existing code)\n",
    "            try_sample_ids = get_ids_in_batch(url, token, batch_ids_selector.value)\n",
    "            identifiers = get_sample_description(url, token, list(try_sample_ids))\n",
    "            data = get_ijp_data(try_sample_ids, identifiers)\n",
    "            \n",
    "            # Check if data was found\n",
    "            if data is None:\n",
    "                out.clear_output()\n",
    "                print(\"The batches selected don't contain any relevant measurements\")\n",
    "                return\n",
    "            \n",
    "            # Store original data\n",
    "            original_data = data.copy()\n",
    "            optimization_ready = False\n",
    "            \n",
    "            out.clear_output()\n",
    "            print(\"Data Loaded Successfully!\")\n",
    "            print(f\"Loaded {len(data)} samples with {len(data.columns)} parameters\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            out.clear_output()\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return\n",
    "    \n",
    "    # Create optimization interface\n",
    "    with dynamic_content:\n",
    "        dynamic_content.clear_output(wait=True)\n",
    "        \n",
    "        if data is not None:\n",
    "            # Display comprehensive data overview\n",
    "            display(Markdown(\"# üî¨ Bayesian Optimization Interface\"))\n",
    "            \n",
    "            # Data summary with insights\n",
    "            display(Markdown(\"## üìä Data Overview\"))\n",
    "            \n",
    "            # Calculate data insights\n",
    "            numeric_cols = len(data.select_dtypes(include=[np.number]).columns)\n",
    "            categorical_cols = len(data.select_dtypes(include=['object']).columns)\n",
    "            jv_params = ['efficiency', 'open_circuit_voltage', 'fill_factor', \n",
    "                        'short_circuit_current_density', 'series_resistance', 'shunt_resistance']\n",
    "            jv_available = len([col for col in jv_params if col in data.columns])\n",
    "            \n",
    "            # Data quality assessment\n",
    "            missing_data_pct = (data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100\n",
    "            \n",
    "            data_summary = f\"\"\"\n",
    "            **Dataset Characteristics:**\n",
    "            - üìà **Total Samples:** {len(data)}\n",
    "            - üî¢ **Numeric Parameters:** {numeric_cols}\n",
    "            - üìù **Categorical Parameters:** {categorical_cols}\n",
    "            - ‚ö° **JV Performance Metrics:** {jv_available} available\n",
    "            - üéØ **Data Completeness:** {100-missing_data_pct:.1f}%\n",
    "            \n",
    "            **Optimization Readiness:**\n",
    "            - ‚úÖ **Ready for optimization** if you have >10 samples per parameter\n",
    "            - ‚ö†Ô∏è **Proceed with caution** if you have 5-10 samples per parameter\n",
    "            - ‚ùå **Collect more data** if you have <5 samples per parameter\n",
    "            \"\"\"\n",
    "            \n",
    "            display(Markdown(data_summary))\n",
    "            \n",
    "            # Show parameter selection interface\n",
    "            display(create_parameter_selection_widgets())\n",
    "        else:\n",
    "            display(Markdown(\"‚ùå No data available. Please select valid batches containing experimental data.\"))\n",
    "            \n",
    "            # Help section for data loading\n",
    "            display(Markdown(\"\"\"\n",
    "            ### üîç Troubleshooting Data Loading\n",
    "            \n",
    "            If no data is showing:\n",
    "            1. **Check batch selection:** Ensure selected batches contain experimental data\n",
    "            2. **Verify data format:** Data should include both process parameters and performance metrics\n",
    "            3. **Check data completeness:** Samples with missing critical data are automatically filtered\n",
    "            \n",
    "            **Required data structure:**\n",
    "            - Process parameters (temperature, pressure, concentrations, etc.)\n",
    "            - Performance metrics (efficiency, voltage, current, etc.)\n",
    "            - Sample identifiers for tracking\n",
    "            \"\"\"))\n",
    "\n",
    "\n",
    "# Initialize global variables\n",
    "optimization_ready = False\n",
    "current_analyzer = None\n",
    "\n",
    "# Main interface\n",
    "if not BAYESIAN_AVAILABLE:\n",
    "    display(widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px;'>\n",
    "        <h3>‚ö†Ô∏è Missing Dependencies</h3>\n",
    "        <p>To use Bayesian optimization, please install the required packages:</p>\n",
    "        <code>pip install scikit-optimize</code>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "display(batch_selection.create_batch_selection(url, token, on_load_data_clicked))\n",
    "display(out)\n",
    "display(dynamic_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e49760-6b92-49ba-9dee-b3fa0cb06a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
